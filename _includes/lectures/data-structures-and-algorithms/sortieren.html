
{::nomarkdown}
<div class="lwarp-contents">
{% raw %}
<div class="hidden" >

\(\newcommand{\footnotename}{footnote}\)

\(\def \LWRfootnote {1}\)

\(\newcommand {\footnote }[2][\LWRfootnote ]{{}^{\mathrm {#1}}}\)

\(\newcommand {\footnotemark }[1][\LWRfootnote ]{{}^{\mathrm {#1}}}\)

\(\newcommand \ensuremath [1]{#1}\)

\(\newcommand {\LWRframebox }[2][]{\fbox {#2}} \newcommand {\framebox }[1][]{\LWRframebox } \)

\(\newcommand {\setlength }[2]{}\)

\(\newcommand {\addtolength }[2]{}\)

\(\newcommand {\setcounter }[2]{}\)

\(\newcommand {\addtocounter }[2]{}\)

\(\newcommand {\cline }[1]{}\)

\(\newcommand {\directlua }[1]{\text {(directlua)}}\)

\(\newcommand {\luatexdirectlua }[1]{\text {(directlua)}}\)

\(\newcommand {\protect }{}\)

\(\def \LWRabsorbnumber #1 {}\)

\(\def \LWRabsorbquotenumber &quot;#1 {}\)

\(\def \mathchar {\ifnextchar &quot;\LWRabsorbquotenumber \LWRabsorbnumber }\)

\(\def \mathcode #1={\mathchar }\)

\(\let \delcode \mathcode \)

\(\let \delimiter \mathchar \)

\(\let \LWRref \ref \)

\(\renewcommand {\ref }{\ifstar \LWRref \LWRref }\)

\(\newcommand {\intertext }[1]{\text {#1}\notag \\}\)

\(\newcommand {\mathllap }[2][]{{#1#2}}\)

\(\newcommand {\mathrlap }[2][]{{#1#2}}\)

\(\newcommand {\mathclap }[2][]{{#1#2}}\)

\(\newcommand {\mathmbox }[1]{#1}\)

\(\newcommand {\clap }[1]{#1}\)

\(\newcommand {\LWRmathmakebox }[2][]{#2}\)

\(\newcommand {\mathmakebox }[1][]{\LWRmathmakebox }\)

\(\newcommand {\cramped }[2][]{{#1#2}}\)

\(\newcommand {\crampedllap }[2][]{{#1#2}}\)

\(\newcommand {\crampedrlap }[2][]{{#1#2}}\)

\(\newcommand {\crampedclap }[2][]{{#1#2}}\)

\(\newenvironment {crampedsubarray}[1]{}{}\)

\(\newcommand {\crampedsubstack }{}\)

\(\newcommand {\smashoperator }[2][]{#2\limits }\)

\(\newcommand {\adjustlimits }{}\)

\(\newcommand {\SwapAboveDisplaySkip }{}\)

\(\require {extpfeil}\)

\(\Newextarrow \xleftrightarrow {10,10}{0x2194}\)

\(\Newextarrow \xLeftarrow {10,10}{0x21d0}\)

\(\Newextarrow \xhookleftarrow {10,10}{0x21a9}\)

\(\Newextarrow \xmapsto {10,10}{0x21a6}\)

\(\Newextarrow \xRightarrow {10,10}{0x21d2}\)

\(\Newextarrow \xLeftrightarrow {10,10}{0x21d4}\)

\(\Newextarrow \xhookrightarrow {10,10}{0x21aa}\)

\(\Newextarrow \xrightharpoondown {10,10}{0x21c1}\)

\(\Newextarrow \xleftharpoondown {10,10}{0x21bd}\)

\(\Newextarrow \xrightleftharpoons {10,10}{0x21cc}\)

\(\Newextarrow \xrightharpoonup {10,10}{0x21c0}\)

\(\Newextarrow \xleftharpoonup {10,10}{0x21bc}\)

\(\Newextarrow \xleftrightharpoons {10,10}{0x21cb}\)

\(\newcommand {\LWRdounderbracket }[3]{\underset {#3}{\underline {#1}}}\)

\(\newcommand {\LWRunderbracket }[2][]{\LWRdounderbracket {#2}}\)

\(\newcommand {\underbracket }[1][]{\LWRunderbracket }\)

\(\newcommand {\LWRdooverbracket }[3]{\overset {#3}{\overline {#1}}}\)

\(\newcommand {\LWRoverbracket }[2][]{\LWRdooverbracket {#2}}\)

\(\newcommand {\overbracket }[1][]{\LWRoverbracket }\)

\(\newcommand {\LaTeXunderbrace }[1]{\underbrace {#1}}\)

\(\newcommand {\LaTeXoverbrace }[1]{\overbrace {#1}}\)

\(\newenvironment {matrix*}[1][]{\begin {matrix}}{\end {matrix}}\)

\(\newenvironment {pmatrix*}[1][]{\begin {pmatrix}}{\end {pmatrix}}\)

\(\newenvironment {bmatrix*}[1][]{\begin {bmatrix}}{\end {bmatrix}}\)

\(\newenvironment {Bmatrix*}[1][]{\begin {Bmatrix}}{\end {Bmatrix}}\)

\(\newenvironment {vmatrix*}[1][]{\begin {vmatrix}}{\end {vmatrix}}\)

\(\newenvironment {Vmatrix*}[1][]{\begin {Vmatrix}}{\end {Vmatrix}}\)

\(\newenvironment {smallmatrix*}[1][]{\begin {matrix}}{\end {matrix}}\)

\(\newenvironment {psmallmatrix*}[1][]{\begin {pmatrix}}{\end {pmatrix}}\)

\(\newenvironment {bsmallmatrix*}[1][]{\begin {bmatrix}}{\end {bmatrix}}\)

\(\newenvironment {Bsmallmatrix*}[1][]{\begin {Bmatrix}}{\end {Bmatrix}}\)

\(\newenvironment {vsmallmatrix*}[1][]{\begin {vmatrix}}{\end {vmatrix}}\)

\(\newenvironment {Vsmallmatrix*}[1][]{\begin {Vmatrix}}{\end {Vmatrix}}\)

\(\newenvironment {psmallmatrix}[1][]{\begin {pmatrix}}{\end {pmatrix}}\)

\(\newenvironment {bsmallmatrix}[1][]{\begin {bmatrix}}{\end {bmatrix}}\)

\(\newenvironment {Bsmallmatrix}[1][]{\begin {Bmatrix}}{\end {Bmatrix}}\)

\(\newenvironment {vsmallmatrix}[1][]{\begin {vmatrix}}{\end {vmatrix}}\)

\(\newenvironment {Vsmallmatrix}[1][]{\begin {Vmatrix}}{\end {Vmatrix}}\)

\(\newcommand {\LWRmultlined }[1][]{\begin {multline*}}\)

\(\newenvironment {multlined}[1][]{\LWRmultlined }{\end {multline*}}\)

\(\let \LWRorigshoveleft \shoveleft \)

\(\renewcommand {\shoveleft }[1][]{\LWRorigshoveleft }\)

\(\let \LWRorigshoveright \shoveright \)

\(\renewcommand {\shoveright }[1][]{\LWRorigshoveright }\)

\(\newenvironment {dcases}{\begin {cases}}{\end {cases}}\)

\(\newenvironment {dcases*}{\begin {cases}}{\end {cases}}\)

\(\newenvironment {rcases}{\begin {cases}}{\end {cases}}\)

\(\newenvironment {rcases*}{\begin {cases}}{\end {cases}}\)

\(\newenvironment {drcases}{\begin {cases}}{\end {cases}}\)

\(\newenvironment {drcases*}{\begin {cases}}{\end {cases}}\)

\(\newenvironment {cases*}{\begin {cases}}{\end {cases}}\)

\(\newcommand {\MoveEqLeft }[1][]{}\)

\(\def \LWRAboxed #1&amp;#2&amp;#3!|!{\fbox {\(#1\)}&amp;\fbox {\(#2\)}} \newcommand {\Aboxed }[1]{\LWRAboxed #1&amp;&amp;!|!} \)

\( \newcommand {\LWRABLines }[1][\Updownarrow ]{#1 \notag \\}\newcommand {\ArrowBetweenLines }{\ifstar \LWRABLines \LWRABLines } \)

\(\newcommand {\shortintertext }[1]{\text {#1}\notag \\}\)

\(\newcommand {\vdotswithin }[1]{\hspace {.5em}\vdots }\)

\(\newcommand {\LWRshortvdotswithinstar }[1]{\vdots \hspace {.5em} &amp; \\}\)

\(\newcommand {\LWRshortvdotswithinnostar }[1]{&amp; \hspace {.5em}\vdots \\}\)

\(\newcommand {\shortvdotswithin }{\ifstar \LWRshortvdotswithinstar \LWRshortvdotswithinnostar }\)

\(\newcommand {\MTFlushSpaceAbove }{}\)

\(\newcommand {\MTFlushSpaceBelow }{\\}\)

\(\newcommand \lparen {(}\)

\(\newcommand \rparen {)}\)

\(\newcommand {\ordinarycolon }{:}\)

\(\newcommand {\vcentcolon }{\mathrel {\mathop \ordinarycolon }}\)

\(\newcommand \dblcolon {\vcentcolon \vcentcolon }\)

\(\newcommand \coloneqq {\vcentcolon =}\)

\(\newcommand \Coloneqq {\dblcolon =}\)

\(\newcommand \coloneq {\vcentcolon {-}}\)

\(\newcommand \Coloneq {\dblcolon {-}}\)

\(\newcommand \eqqcolon {=\vcentcolon }\)

\(\newcommand \Eqqcolon {=\dblcolon }\)

\(\newcommand \eqcolon {\mathrel {-}\vcentcolon }\)

\(\newcommand \Eqcolon {\mathrel {-}\dblcolon }\)

\(\newcommand \colonapprox {\vcentcolon \approx }\)

\(\newcommand \Colonapprox {\dblcolon \approx }\)

\(\newcommand \colonsim {\vcentcolon \sim }\)

\(\newcommand \Colonsim {\dblcolon \sim }\)

\(\newcommand {\nuparrow }{\mathrel {\cancel {\uparrow }}}\)

\(\newcommand {\ndownarrow }{\mathrel {\cancel {\downarrow }}}\)

\(\newcommand {\bigtimes }{\mathop {\Large \times }\limits }\)

\(\newcommand {\prescript }[3]{{}^{#1}_{#2}#3}\)

\(\newenvironment {lgathered}{\begin {gathered}}{\end {gathered}}\)

\(\newenvironment {rgathered}{\begin {gathered}}{\end {gathered}}\)

\(\newcommand {\splitfrac }[2]{{}^{#1}_{#2}}\)

\(\let \splitdfrac \splitfrac \)

\(\newcommand {\LWRoverlaysymbols }[2]{\mathord {\smash {\mathop {#2\strut }\limits ^{\smash {\lower 3ex{#1}}}}\strut }}\)

\(\newcommand{\alphaup}{\unicode{x03B1}}\)

\(\newcommand{\betaup}{\unicode{x03B2}}\)

\(\newcommand{\gammaup}{\unicode{x03B3}}\)

\(\newcommand{\digammaup}{\unicode{x03DD}}\)

\(\newcommand{\deltaup}{\unicode{x03B4}}\)

\(\newcommand{\epsilonup}{\unicode{x03F5}}\)

\(\newcommand{\varepsilonup}{\unicode{x03B5}}\)

\(\newcommand{\zetaup}{\unicode{x03B6}}\)

\(\newcommand{\etaup}{\unicode{x03B7}}\)

\(\newcommand{\thetaup}{\unicode{x03B8}}\)

\(\newcommand{\varthetaup}{\unicode{x03D1}}\)

\(\newcommand{\iotaup}{\unicode{x03B9}}\)

\(\newcommand{\kappaup}{\unicode{x03BA}}\)

\(\newcommand{\varkappaup}{\unicode{x03F0}}\)

\(\newcommand{\lambdaup}{\unicode{x03BB}}\)

\(\newcommand{\muup}{\unicode{x03BC}}\)

\(\newcommand{\nuup}{\unicode{x03BD}}\)

\(\newcommand{\xiup}{\unicode{x03BE}}\)

\(\newcommand{\omicronup}{\unicode{x03BF}}\)

\(\newcommand{\piup}{\unicode{x03C0}}\)

\(\newcommand{\varpiup}{\unicode{x03D6}}\)

\(\newcommand{\rhoup}{\unicode{x03C1}}\)

\(\newcommand{\varrhoup}{\unicode{x03F1}}\)

\(\newcommand{\sigmaup}{\unicode{x03C3}}\)

\(\newcommand{\varsigmaup}{\unicode{x03C2}}\)

\(\newcommand{\tauup}{\unicode{x03C4}}\)

\(\newcommand{\upsilonup}{\unicode{x03C5}}\)

\(\newcommand{\phiup}{\unicode{x03D5}}\)

\(\newcommand{\varphiup}{\unicode{x03C6}}\)

\(\newcommand{\chiup}{\unicode{x03C7}}\)

\(\newcommand{\psiup}{\unicode{x03C8}}\)

\(\newcommand{\omegaup}{\unicode{x03C9}}\)

\(\newcommand{\Alphaup}{\unicode{x0391}}\)

\(\newcommand{\Betaup}{\unicode{x0392}}\)

\(\newcommand{\Gammaup}{\unicode{x0393}}\)

\(\newcommand{\Digammaup}{\unicode{x03DC}}\)

\(\newcommand{\Deltaup}{\unicode{x0394}}\)

\(\newcommand{\Epsilonup}{\unicode{x0395}}\)

\(\newcommand{\Zetaup}{\unicode{x0396}}\)

\(\newcommand{\Etaup}{\unicode{x0397}}\)

\(\newcommand{\Thetaup}{\unicode{x0398}}\)

\(\newcommand{\Varthetaup}{\unicode{x03F4}}\)

\(\newcommand{\Iotaup}{\unicode{x0399}}\)

\(\newcommand{\Kappaup}{\unicode{x039A}}\)

\(\newcommand{\Lambdaup}{\unicode{x039B}}\)

\(\newcommand{\Muup}{\unicode{x039C}}\)

\(\newcommand{\Nuup}{\unicode{x039D}}\)

\(\newcommand{\Xiup}{\unicode{x039E}}\)

\(\newcommand{\Omicronup}{\unicode{x039F}}\)

\(\newcommand{\Piup}{\unicode{x03A0}}\)

\(\newcommand{\Varpiup}{\unicode{x03D6}}\)

\(\newcommand{\Rhoup}{\unicode{x03A1}}\)

\(\newcommand{\Sigmaup}{\unicode{x03A3}}\)

\(\newcommand{\Tauup}{\unicode{x03A4}}\)

\(\newcommand{\Upsilonup}{\unicode{x03A5}}\)

\(\newcommand{\Phiup}{\unicode{x03A6}}\)

\(\newcommand{\Chiup}{\unicode{x03A7}}\)

\(\newcommand{\Psiup}{\unicode{x03A8}}\)

\(\newcommand{\Omegaup}{\unicode{x03A9}}\)

\(\newcommand{\alphait}{\unicode{x1D6FC}}\)

\(\newcommand{\betait}{\unicode{x1D6FD}}\)

\(\newcommand{\gammait}{\unicode{x1D6FE}}\)

\(\newcommand{\digammait}{\mathit{\unicode{x03DD}}}\)

\(\newcommand{\deltait}{\unicode{x1D6FF}}\)

\(\newcommand{\epsilonit}{\unicode{x1D716}}\)

\(\newcommand{\varepsilonit}{\unicode{x1D700}}\)

\(\newcommand{\zetait}{\unicode{x1D701}}\)

\(\newcommand{\etait}{\unicode{x1D702}}\)

\(\newcommand{\thetait}{\unicode{x1D703}}\)

\(\newcommand{\varthetait}{\unicode{x1D717}}\)

\(\newcommand{\iotait}{\unicode{x1D704}}\)

\(\newcommand{\kappait}{\unicode{x1D705}}\)

\(\newcommand{\varkappait}{\unicode{x1D718}}\)

\(\newcommand{\lambdait}{\unicode{x1D706}}\)

\(\newcommand{\muit}{\unicode{x1D707}}\)

\(\newcommand{\nuit}{\unicode{x1D708}}\)

\(\newcommand{\xiit}{\unicode{x1D709}}\)

\(\newcommand{\omicronit}{\unicode{x1D70A}}\)

\(\newcommand{\piit}{\unicode{x1D70B}}\)

\(\newcommand{\varpiit}{\unicode{x1D71B}}\)

\(\newcommand{\rhoit}{\unicode{x1D70C}}\)

\(\newcommand{\varrhoit}{\unicode{x1D71A}}\)

\(\newcommand{\sigmait}{\unicode{x1D70E}}\)

\(\newcommand{\varsigmait}{\unicode{x1D70D}}\)

\(\newcommand{\tauit}{\unicode{x1D70F}}\)

\(\newcommand{\upsilonit}{\unicode{x1D710}}\)

\(\newcommand{\phiit}{\unicode{x1D719}}\)

\(\newcommand{\varphiit}{\unicode{x1D711}}\)

\(\newcommand{\chiit}{\unicode{x1D712}}\)

\(\newcommand{\psiit}{\unicode{x1D713}}\)

\(\newcommand{\omegait}{\unicode{x1D714}}\)

\(\newcommand{\Alphait}{\unicode{x1D6E2}}\)

\(\newcommand{\Betait}{\unicode{x1D6E3}}\)

\(\newcommand{\Gammait}{\unicode{x1D6E4}}\)

\(\newcommand{\Digammait}{\mathit{\unicode{x03DC}}}\)

\(\newcommand{\Deltait}{\unicode{x1D6E5}}\)

\(\newcommand{\Epsilonit}{\unicode{x1D6E6}}\)

\(\newcommand{\Zetait}{\unicode{x1D6E7}}\)

\(\newcommand{\Etait}{\unicode{x1D6E8}}\)

\(\newcommand{\Thetait}{\unicode{x1D6E9}}\)

\(\newcommand{\Varthetait}{\unicode{x1D6F3}}\)

\(\newcommand{\Iotait}{\unicode{x1D6EA}}\)

\(\newcommand{\Kappait}{\unicode{x1D6EB}}\)

\(\newcommand{\Lambdait}{\unicode{x1D6EC}}\)

\(\newcommand{\Muit}{\unicode{x1D6ED}}\)

\(\newcommand{\Nuit}{\unicode{x1D6EE}}\)

\(\newcommand{\Xiit}{\unicode{x1D6EF}}\)

\(\newcommand{\Omicronit}{\unicode{x1D6F0}}\)

\(\newcommand{\Piit}{\unicode{x1D6F1}}\)

\(\newcommand{\Rhoit}{\unicode{x1D6F2}}\)

\(\newcommand{\Sigmait}{\unicode{x1D6F4}}\)

\(\newcommand{\Tauit}{\unicode{x1D6F5}}\)

\(\newcommand{\Upsilonit}{\unicode{x1D6F6}}\)

\(\newcommand{\Phiit}{\unicode{x1D6F7}}\)

\(\newcommand{\Chiit}{\unicode{x1D6F8}}\)

\(\newcommand{\Psiit}{\unicode{x1D6F9}}\)

\(\newcommand{\Omegait}{\unicode{x1D6FA}}\)

\(\let \digammaup \Digammaup \)

\(\renewcommand {\digammait }{\mathit {\digammaup }}\)

\(\newcommand {\smallin }{\unicode {x220A}}\)

\(\newcommand {\smallowns }{\unicode {x220D}}\)

\(\newcommand {\notsmallin }{\LWRoverlaysymbols {/}{\unicode {x220A}}}\)

\(\newcommand {\notsmallowns }{\LWRoverlaysymbols {/}{\unicode {x220D}}}\)

\(\newcommand {\rightangle }{\unicode {x221F}}\)

\(\newcommand {\intclockwise }{\unicode {x2231}}\)

\(\newcommand {\ointclockwise }{\unicode {x2232}}\)

\(\newcommand {\ointctrclockwise }{\unicode {x2233}}\)

\(\newcommand {\oiint }{\unicode {x222F}}\)

\(\newcommand {\oiiint }{\unicode {x2230}}\)

\(\newcommand {\ddag }{\unicode {x2021}}\)

\(\newcommand {\P }{\unicode {x00B6}}\)

\(\newcommand {\copyright }{\unicode {x00A9}}\)

\(\newcommand {\dag }{\unicode {x2020}}\)

\(\newcommand {\pounds }{\unicode {x00A3}}\)

\(\newcommand {\iddots }{\unicode {x22F0}}\)

\(\newcommand {\utimes }{\overline {\times }}\)

\(\newcommand {\dtimes }{\underline {\times }}\)

\(\newcommand {\udtimes }{\overline {\underline {\times }}}\)

\(\newcommand {\leftwave }{\left \{}\)

\(\newcommand {\rightwave }{\right \}}\)

\(\newcommand {\toprule }[1][]{\hline }\)

\(\let \midrule \toprule \)

\(\let \bottomrule \toprule \)

\(\newcommand {\cmidrule }[2][]{}\)

\(\newcommand {\morecmidrules }{}\)

\(\newcommand {\specialrule }[3]{\hline }\)

\(\newcommand {\addlinespace }[1][]{}\)

\(\newcommand {\LWRsubmultirow }[2][]{#2}\)

\(\newcommand {\LWRmultirow }[2][]{\LWRsubmultirow }\)

\(\newcommand {\multirow }[2][]{\LWRmultirow }\)

\(\newcommand {\mrowcell }{}\)

\(\newcommand {\mcolrowcell }{}\)

\(\newcommand {\STneed }[1]{}\)

\( \newcommand {\multicolumn }[3]{#3}\)

\(\newcommand {\tothe }[1]{^{#1}}\)

\(\newcommand {\raiseto }[2]{{#2}^{#1}}\)

\(\newcommand {\ang }[2][]{(\mathrm {#2})\degree }\)

\(\newcommand {\num }[2][]{\mathrm {#2}}\)

\(\newcommand {\si }[2][]{\mathrm {#2}}\)

\(\newcommand {\LWRSI }[2][]{\mathrm {#1\LWRSInumber \,#2}}\)

\(\newcommand {\SI }[2][]{\def \LWRSInumber {#2}\LWRSI }\)

\(\newcommand {\numlist }[2][]{\mathrm {#2}}\)

\(\newcommand {\numrange }[3][]{\mathrm {#2\,\unicode {x2013}\,#3}}\)

\(\newcommand {\SIlist }[3][]{\mathrm {#2\,#3}}\)

\(\newcommand {\SIrange }[4][]{\mathrm {#2\,#4\,\unicode {x2013}\,#3\,#4}}\)

\(\newcommand {\tablenum }[2][]{\mathrm {#2}}\)

\(\newcommand {\ampere }{\mathrm {A}}\)

\(\newcommand {\candela }{\mathrm {cd}}\)

\(\newcommand {\kelvin }{\mathrm {K}}\)

\(\newcommand {\kilogram }{\mathrm {kg}}\)

\(\newcommand {\metre }{\mathrm {m}}\)

\(\newcommand {\mole }{\mathrm {mol}}\)

\(\newcommand {\second }{\mathrm {s}}\)

\(\newcommand {\becquerel }{\mathrm {Bq}}\)

\(\newcommand {\degreeCelsius }{\unicode {x2103}}\)

\(\newcommand {\coulomb }{\mathrm {C}}\)

\(\newcommand {\farad }{\mathrm {F}}\)

\(\newcommand {\gray }{\mathrm {Gy}}\)

\(\newcommand {\hertz }{\mathrm {Hz}}\)

\(\newcommand {\henry }{\mathrm {H}}\)

\(\newcommand {\joule }{\mathrm {J}}\)

\(\newcommand {\katal }{\mathrm {kat}}\)

\(\newcommand {\lumen }{\mathrm {lm}}\)

\(\newcommand {\lux }{\mathrm {lx}}\)

\(\newcommand {\newton }{\mathrm {N}}\)

\(\newcommand {\ohm }{\mathrm {\Omega }}\)

\(\newcommand {\pascal }{\mathrm {Pa}}\)

\(\newcommand {\radian }{\mathrm {rad}}\)

\(\newcommand {\siemens }{\mathrm {S}}\)

\(\newcommand {\sievert }{\mathrm {Sv}}\)

\(\newcommand {\steradian }{\mathrm {sr}}\)

\(\newcommand {\tesla }{\mathrm {T}}\)

\(\newcommand {\volt }{\mathrm {V}}\)

\(\newcommand {\watt }{\mathrm {W}}\)

\(\newcommand {\weber }{\mathrm {Wb}}\)

\(\newcommand {\day }{\mathrm {d}}\)

\(\newcommand {\degree }{\mathrm {^\circ }}\)

\(\newcommand {\hectare }{\mathrm {ha}}\)

\(\newcommand {\hour }{\mathrm {h}}\)

\(\newcommand {\litre }{\mathrm {l}}\)

\(\newcommand {\liter }{\mathrm {L}}\)

\(\newcommand {\arcminute }{^\prime }\)
\(\newcommand {\minute }{\mathrm {min}}\)

\(\newcommand {\arcsecond }{^{\prime \prime }}\)

\(\newcommand {\tonne }{\mathrm {t}}\)

\(\newcommand {\astronomicalunit }{au}\)

\(\newcommand {\atomicmassunit }{u}\)

\(\newcommand {\bohr }{\mathit {a}_0}\)

\(\newcommand {\clight }{\mathit {c}_0}\)

\(\newcommand {\dalton }{\mathrm {D}_\mathrm {a}}\)

\(\newcommand {\electronmass }{\mathit {m}_{\mathrm {e}}}\)

\(\newcommand {\electronvolt }{\mathrm {eV}}\)

\(\newcommand {\elementarycharge }{\mathit {e}}\)

\(\newcommand {\hartree }{\mathit {E}_{\mathrm {h}}}\)

\(\newcommand {\planckbar }{\mathit {\unicode {x210F}}}\)

\(\newcommand {\angstrom }{\mathrm {\unicode {x212B}}}\)

\(\let \LWRorigbar \bar \)

\(\newcommand {\bar }{\mathrm {bar}}\)

\(\newcommand {\barn }{\mathrm {b}}\)

\(\newcommand {\bel }{\mathrm {B}}\)

\(\newcommand {\decibel }{\mathrm {dB}}\)

\(\newcommand {\knot }{\mathrm {kn}}\)

\(\newcommand {\mmHg }{\mathrm {mmHg}}\)

\(\newcommand {\nauticalmile }{\mathrm {M}}\)

\(\newcommand {\neper }{\mathrm {Np}}\)

\(\newcommand {\yocto }{\mathrm {y}}\)

\(\newcommand {\zepto }{\mathrm {z}}\)

\(\newcommand {\atto }{\mathrm {a}}\)

\(\newcommand {\femto }{\mathrm {f}}\)

\(\newcommand {\pico }{\mathrm {p}}\)

\(\newcommand {\nano }{\mathrm {n}}\)

\(\newcommand {\micro }{\mathrm {\unicode {x00B5}}}\)

\(\newcommand {\milli }{\mathrm {m}}\)

\(\newcommand {\centi }{\mathrm {c}}\)

\(\newcommand {\deci }{\mathrm {d}}\)

\(\newcommand {\deca }{\mathrm {da}}\)

\(\newcommand {\hecto }{\mathrm {h}}\)

\(\newcommand {\kilo }{\mathrm {k}}\)

\(\newcommand {\mega }{\mathrm {M}}\)

\(\newcommand {\giga }{\mathrm {G}}\)

\(\newcommand {\tera }{\mathrm {T}}\)

\(\newcommand {\peta }{\mathrm {P}}\)

\(\newcommand {\exa }{\mathrm {E}}\)

\(\newcommand {\zetta }{\mathrm {Z}}\)

\(\newcommand {\yotta }{\mathrm {Y}}\)

\(\newcommand {\percent }{\mathrm {\%}}\)

\(\newcommand {\meter }{\mathrm {m}}\)

\(\newcommand {\metre }{\mathrm {m}}\)

\(\newcommand {\gram }{\mathrm {g}}\)

\(\newcommand {\kg }{\kilo \gram }\)

\(\newcommand {\of }[1]{_{\mathrm {#1}}}\)

\(\newcommand {\squared }{^2}\)

\(\newcommand {\square }[1]{\mathrm {#1}^2}\)

\(\newcommand {\cubed }{^3}\)

\(\newcommand {\cubic }[1]{\mathrm {#1}^3}\)

\(\newcommand {\per }{/}\)

\(\newcommand {\celsius }{\unicode {x2103}}\)

\(\newcommand {\fg }{\femto \gram }\)

\(\newcommand {\pg }{\pico \gram }\)

\(\newcommand {\ng }{\nano \gram }\)

\(\newcommand {\ug }{\micro \gram }\)

\(\newcommand {\mg }{\milli \gram }\)

\(\newcommand {\g }{\gram }\)

\(\newcommand {\kg }{\kilo \gram }\)

\(\newcommand {\amu }{\mathrm {u}}\)

\(\newcommand {\nm }{\nano \metre }\)

\(\newcommand {\um }{\micro \metre }\)

\(\newcommand {\mm }{\milli \metre }\)

\(\newcommand {\cm }{\centi \metre }\)

\(\newcommand {\dm }{\deci \metre }\)

\(\newcommand {\m }{\metre }\)

\(\newcommand {\km }{\kilo \metre }\)

\(\newcommand {\as }{\atto \second }\)

\(\newcommand {\fs }{\femto \second }\)

\(\newcommand {\ps }{\pico \second }\)

\(\newcommand {\ns }{\nano \second }\)

\(\newcommand {\us }{\micro \second }\)

\(\newcommand {\ms }{\milli \second }\)

\(\newcommand {\s }{\second }\)

\(\newcommand {\fmol }{\femto \mol }\)

\(\newcommand {\pmol }{\pico \mol }\)

\(\newcommand {\nmol }{\nano \mol }\)

\(\newcommand {\umol }{\micro \mol }\)

\(\newcommand {\mmol }{\milli \mol }\)

\(\newcommand {\mol }{\mol }\)

\(\newcommand {\kmol }{\kilo \mol }\)

\(\newcommand {\pA }{\pico \ampere }\)

\(\newcommand {\nA }{\nano \ampere }\)

\(\newcommand {\uA }{\micro \ampere }\)

\(\newcommand {\mA }{\milli \ampere }\)

\(\newcommand {\A }{\ampere }\)

\(\newcommand {\kA }{\kilo \ampere }\)

\(\newcommand {\ul }{\micro \litre }\)

\(\newcommand {\ml }{\milli \litre }\)

\(\newcommand {\l }{\litre }\)

\(\newcommand {\hl }{\hecto \litre }\)

\(\newcommand {\uL }{\micro \liter }\)

\(\newcommand {\mL }{\milli \liter }\)

\(\newcommand {\L }{\liter }\)

\(\newcommand {\hL }{\hecto \liter }\)

\(\newcommand {\mHz }{\milli \hertz }\)

\(\newcommand {\Hz }{\hertz }\)

\(\newcommand {\kHz }{\kilo \hertz }\)

\(\newcommand {\MHz }{\mega \hertz }\)

\(\newcommand {\GHz }{\giga \hertz }\)

\(\newcommand {\THz }{\tera \hertz }\)

\(\newcommand {\mN }{\milli \newton }\)

\(\newcommand {\N }{\newton }\)

\(\newcommand {\kN }{\kilo \newton }\)

\(\newcommand {\MN }{\mega \newton }\)

\(\newcommand {\Pa }{\pascal }\)

\(\newcommand {\kPa }{\kilo \pascal }\)

\(\newcommand {\MPa }{\mega \pascal }\)

\(\newcommand {\GPa }{\giga \pascal }\)

\(\newcommand {\mohm }{\milli \ohm }\)

\(\newcommand {\kohm }{\kilo \ohm }\)

\(\newcommand {\Mohm }{\mega \ohm }\)

\(\newcommand {\pV }{\pico \volt }\)

\(\newcommand {\nV }{\nano \volt }\)

\(\newcommand {\uV }{\micro \volt }\)

\(\newcommand {\mV }{\milli \volt }\)

\(\newcommand {\V }{\volt }\)

\(\newcommand {\kV }{\kilo \volt }\)

\(\newcommand {\W }{\watt }\)

\(\newcommand {\uW }{\micro \watt }\)

\(\newcommand {\mW }{\milli \watt }\)

\(\newcommand {\kW }{\kilo \watt }\)

\(\newcommand {\MW }{\mega \watt }\)

\(\newcommand {\GW }{\giga \watt }\)

\(\newcommand {\J }{\joule }\)

\(\newcommand {\uJ }{\micro \joule }\)

\(\newcommand {\mJ }{\milli \joule }\)

\(\newcommand {\kJ }{\kilo \joule }\)

\(\newcommand {\eV }{\electronvolt }\)

\(\newcommand {\meV }{\milli \electronvolt }\)

\(\newcommand {\keV }{\kilo \electronvolt }\)

\(\newcommand {\MeV }{\mega \electronvolt }\)

\(\newcommand {\GeV }{\giga \electronvolt }\)

\(\newcommand {\TeV }{\tera \electronvolt }\)

\(\newcommand {\kWh }{\kilo \watt \hour }\)

\(\newcommand {\F }{\farad }\)

\(\newcommand {\fF }{\femto \farad }\)

\(\newcommand {\pF }{\pico \farad }\)

\(\newcommand {\K }{\mathrm {K}}\)

\(\newcommand {\dB }{\mathrm {dB}}\)

\(\newcommand {\kibi }{\mathrm {Ki}}\)

\(\newcommand {\mebi }{\mathrm {Mi}}\)

\(\newcommand {\gibi }{\mathrm {Gi}}\)

\(\newcommand {\tebi }{\mathrm {Ti}}\)

\(\newcommand {\pebi }{\mathrm {Pi}}\)

\(\newcommand {\exbi }{\mathrm {Ei}}\)

\(\newcommand {\zebi }{\mathrm {Zi}}\)

\(\newcommand {\yobi }{\mathrm {Yi}}\)

\(\require {mhchem}\)

\(\require {cancel}\)

\(\newcommand {\fint }{âĺŊ}\)

\(\newcommand {\hdots }{\cdots }\)

\(\newcommand {\mathnormal }[1]{#1}\)

\(\newcommand {\vecs }[2]{\vec {#1}_{#2}}\)

\(\newcommand {\code }[1]{\lstinline [basicstyle=\ttfamily ]{#1}}\)

\(\renewcommand {\O }{\ensuremath {\mathcal {O}}}\)

\(\newcommand {\source }{\ensuremath {\operatorname {source}}}\)

\(\newcommand {\target }{\ensuremath {\operatorname {target}}}\)

\(\renewcommand {\num }{\ensuremath {\operatorname {num}}}\)

\(\newcommand {\indeg }{\ensuremath {\operatorname {indeg}}}\)

\(\newcommand {\mycap }{\ensuremath {\operatorname {cap}}}\)

\(\newcommand {\cost }{\ensuremath {\operatorname {cost}}}\)

\(\newcommand {\pot }{\ensuremath {\operatorname {pot}}}\)

\(\newcommand {\ccost }{\ensuremath {\operatorname {ccost}}}\)

\(\newcommand {\dcost }{\ensuremath {\operatorname {dcost}}}\)

\(\newcommand {\icost }{\ensuremath {\operatorname {icost}}}\)

\(\newcommand {\qed }{\hfill $\Box $}\)

\(\newcommand {\fracsize }[1]{{\large #1}}\)

\(\newcommand {\matrixsize }[1]{{\scriptsize #1}}\)

\(\newcommand {\name }[1]{\textsc {#1}}\)

\(\newcommand {\smallpmatrix }[1]{\left (\begin {smallmatrix}#1\end {smallmatrix}\right )}\)

\(\newcommand {\matlab }{{\fontfamily {bch}\scshape \selectfont {}Matlab}}\)

\(\newcommand {\innerproduct }[1]{\left \langle {#1}\right \rangle }\)

\(\newcommand {\norm }[1]{\left \Vert {#1}\right \Vert }\)

\(\renewcommand {\natural }{\mathbb {N}}\)

\(\newcommand {\integer }{\mathbb {Z}}\)

\(\newcommand {\rational }{\mathbb {Q}}\)

\(\newcommand {\real }{\mathbb {R}}\)

\(\newcommand {\complex }{\mathbb {C}}\)

\(\renewcommand {\d }{\mathop {}\!\mathrm {d}}\)

\(\newcommand {\dr }{\d {}r}\)

\(\newcommand {\ds }{\d {}s}\)

\(\newcommand {\dt }{\d {}t}\)

\(\newcommand {\du }{\d {}u}\)

\(\newcommand {\dv }{\d {}v}\)

\(\newcommand {\dw }{\d {}w}\)

\(\newcommand {\dx }{\d {}x}\)

\(\newcommand {\dy }{\d {}y}\)

\(\newcommand {\dz }{\d {}z}\)

\(\newcommand {\dsigma }{\d {}\sigma }\)

\(\newcommand {\dphi }{\d {}\phi }\)

\(\newcommand {\dvarphi }{\d {}\varphi }\)

\(\newcommand {\dtau }{\d {}\tau }\)

\(\newcommand {\dxi }{\d {}\xi }\)

\(\newcommand {\dtheta }{\d {}\theta }\)

\(\newcommand {\tp }{\mathrm {T}}\)

</div>

<style type="text/css">
.lwarp-contents li.list-item-f0::marker {
  content:'•\00a0\00a0';
}
.lwarp-contents li.list-item-f1::marker {
  content:'•\00a0\00a0';
}
.lwarp-contents li.list-item-f2::marker {
  content:'•\00a0\00a0';
}
</style>
<p>

</p>


<h2 id="sortierproblem-und-aufwandsanalyse">Sortierproblem und Aufwandsanalyse</h2>

</p>

<p>
Gegeben sei eine Menge \(S = \{A[1], \ldots , A[n]\}\) aus einem total geordneten Universum. Gesucht ist eine Permutation \(\pi \) von \(\{1, \ldots , n\}\), sodass \(A[\pi (1)] \le \dotsb \le
A[\pi (n)]\) ist.
</p>
<p>
Zum Beispiel ist fu&#x0308;r \(S = \{2, 7, 1, 3, 5\} \subseteq \mathbb {N}\) das gesuchte \(\pi \) gegeben durch \(\begin {pmatrix}1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\ 3 &amp; 1
&amp; 4 &amp; 5 &amp; 2\end {pmatrix}\).
</p>
<p>
Den „lexikalischen Vergleich“ kann man definieren durch \(w_1 x r &lt; w_1 y r \;\Leftrightarrow \; x &lt; y\) mit \(x, y \in \Sigma \), \(w_1, r \in \Sigma ^\ast \).
</p>
<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
<b>Aufwand</b>: <em>Platz</em>, der beno&#x0308;tigt wird, um \(\pi \) zu berechnen; &#x2003;&#x2003;<em>Anzahl der Arbeitsschritte</em>;<br />
<em>Zeit</em> fu&#x0308;r die Berechnung von \(\pi \) auf einer Maschine mit \(p\) Prozessoren (= Anzahl der Arbeitsschritte fu&#x0308;r \(p = 1\)); <em>Anzahl der I/O-Operationen</em> (wichtig beim Sortieren
großer Datenmengen).
</p>
<p>
<b>Bedingungen</b>, unter denen der Aufwand abgescha&#x0308;tzt werden soll:
</p>
<ul style="list-style-type:none">

<li class="list-item-f0"><p><b>Worst-Case-Analyse</b>: Eingabe \(S\) kann beliebig permutiert sein, interessant ist obere Schranke, die immer gilt
</p>
</li>
<li class="list-item-f1"><p><b>probabilistische Analyse</b>: Eingabe stammt aus einer Wahrscheinlichkeitsverteilung u&#x0308;ber alle Eingaben, Ziel ist Verfahren, das eine gute (erwartete) Laufzeit erzielt
</p>
</li>
<li class="list-item-f2"><p><b>randomisierte Algorithmen</b>: Es kann nu&#x0308;tzlich sein, dass Algorithmen den weiteren Fortgang vom Ergebnis eines Zufallsgenerators abha&#x0308;ngig machen. Es interessiert uns die <em>erwartete</em>
Laufzeit bei beliebiger Eingabe.
</p>
</li>
</ul>


<h2 id="bubblesort">Bubblesort</h2>

</p>
<table>
<tr>
<td class="tdp">
<div class="minipage" style="vertical-align:middle ; justify-content:flex-start ; ">
<pre class="programlisting">
i := n
while (i &gt;1) do
   j := 1
   while (j &lt;i) do
      if A[j] &gt;A[j + 1]
         swap(A[j], A[j + 1])
      j := j + 1
   od
   i := i - 1
od
</pre>


</div>
</td>
<td class="tdp">
<div class="minipage" style="vertical-align:middle ; justify-content:flex-start ; ">
<p>
Im ersten Durchlauf wandert das gro&#x0308;ßte Element ganz nach hinten, im zweiten Durchlauf wandert das zweitgro&#x0308;ßte Element an die vorletzte Position usw.
</p>
<p>
<em>Beobachtung</em>: Die Menge der Elemente in \(A[1], \ldots , A[n]\) bleibt wa&#x0308;hrend des Algorithmus gleich.
</p>
<p>
<em>Lemma</em>: Fu&#x0308;r ein festes \(i\) ist \(A[i] = \max _{j = 1, \ldots , i} A[j]\) am Ende der a&#x0308;ußeren Schleife.
</p>
<p>
<em>Satz</em>: Nach der Durchfu&#x0308;hrung liegt \(A[\;]\) in sortierter Reihenfolge vor.
</p>


</div>
</td>
</tr>
</table>
<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
<b>Problem bei der Laufzeitanalyse</b>: Die <em>Implementierungssprache</em> sowie der <em>Rechner</em>, auf dem der Algorithmus ausgefu&#x0308;hrt wird, haben erheblichen Einfluss auf die Zeit, die dieser zur
Ausfu&#x0308;hrung braucht. Daher ist die Zeitmessung nicht geeignet, um die Laufzeit/Qualita&#x0308;t eines Algorithmus zu bestimmen.<br />
Besser scheint es, die Anzahl der aufgefu&#x0308;hrten <b>Instruktionen</b> beim Lo&#x0308;sen eines bestimmten Problems zu za&#x0308;hlen. Dabei nimmt man an, dass eine Instruktion <em>konstante Zeit</em> (\(1\)
Zeiteinheit) beno&#x0308;tigt. Was ist jedoch eine Instruktion? Ist <span class="inlineprogramlisting"></span>swap eine oder drei Instruktionen, oder noch mehr in Assembler?
</p>
<p>
Die Anzahl der Instruktionen ha&#x0308;ngt zudem von der CPU-Architektur ab. Zur Analyse eines Algorithmus will man eine invariante Gro&#x0308;ße bzgl. Sprache und CPU-Architektur wa&#x0308;hlen.<br />
Dazu za&#x0308;hlt man nur die Anzahl der <b>Vergleiche</b>, die durchgefu&#x0308;hrt werden.
</p>
<p>
Man nimmt an, dass die Beschreibung (insbesondere die La&#x0308;nge) des Algorithmus unabha&#x0308;ngig von der Eingabe ist. Sei \(C\) die <b>Anzahl an Instruktionen</b> in der Beschreibung (nicht im Ablauf) des
Algorithmus.<br />
\(C\) ha&#x0308;ngt zwar von Sprache/CPU-Architektur ab, ist aber konstant.
</p>
<p>
<b>Behauptung</b>: Wenn der Algorithmus terminiert, tritt bei der Ausfu&#x0308;hrung spa&#x0308;testens nach jeweils \(C\) Instruktionen ein Vergleich auf.
</p>
<p>
<b>Beweis</b>: Sobald \(&gt; C\) Instruktionen ausgefu&#x0308;hrt wurden, wurde mindestens eine Instruktion mehrfach ausgefu&#x0308;hrt. Falls zwischen der ersten und zweiten Ausfu&#x0308;hrung kein Vergleich
ausgefu&#x0308;hrt wurde, gibt es keine Mo&#x0308;glichkeit den Kontrollfluss dazwischen zu a&#x0308;ndern und es kommt zu einer Endlosschleife. &#x2003;&#x2003;
</p>
<p>
Wenn man nur die Vergleiche za&#x0308;hlt, kann man also die „Laufzeit“ (Anzahl der ausgefu&#x0308;hrten Instruktionen) bis auf einen konstanten Fehler abscha&#x0308;tzen, denn es gilt \(n_{\text {Ins}} \le C
\cdot n_{\text {Vgl}}\).
</p>
<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
Bei Bubblesort betra&#x0308;gt die Gesamtzahl an Vergleichen \(\le n^2 + n\). Daher betra&#x0308;gt die Anzahl ausgefu&#x0308;hrter Instruktionen \(\le C \cdot (n^2 + n)\), wobei \(C\) von
Sprache/Implementierung abha&#x0308;ngt.
</p>
<p>
Die <b>\(\O \)-Notation</b> erlaubt es nun, Konstanten und dominierte Terme wegzulassen:<br />
\(\O (f(n)) = \{g: \mathbb {N} \rightarrow \mathbb {R} \;|\; \exists _{C &gt; 0} \exists _{n_0 \in \mathbb {N}} \forall _{n \ge n_0}\; g(n) \le C \cdot
f(n)\}\). Bspw. ist \(\O (n^2)\) die Menge der Funktionen, die fu&#x0308;r hinreichend große \(n\) nicht schneller wachsen als \(n^2\).
</p>
<p>
Bubblesort hat also Worst-Case-Laufzeit \(\O (n^2)\) (bzw. keine schlechtere Laufzeit). Es macht einen großen Unterschied, ob Algorithmen Laufzeiten mit \(\O (n)\), \(\O (n \log n)\) oder \(\O (n^2)\) haben.
</p>


<h2 id="mergesort">Mergesort</h2>

</p>

<p>
Mergesort sortiert eine Datenreihe, indem sie so weit halbiert wird, bis sie nur noch aus ein- und zweielementigen Tupeln besteht. Diese werden sortiert und dann wieder in sortierter Reihenfolge verschmolzen (engl.
<em>merge</em>).<br />
Um eine Sequenz \(a_1, \ldots , a_{\lceil n/2 \rceil }, a_{\lceil n/2 \rceil + 1}, \ldots , a_n\) zu sortieren, werden zuna&#x0308;chst \(a_1, \ldots , a_{\lceil n/2 \rceil
}\) und \(a_{\lceil n/2 \rceil + 1}, \ldots , a_n\) sortiert und dann miteinander vermischt.<br />
Mergesort handelt nach dem <b>Divide-&amp;-Conquer-Paradigma</b> (<em>teile und herrsche</em>).
</p>
<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
<b>Laufzeitaufwand von Mergesort</b>: Der Gesamtlaufzeit \(T(n)\), um eine Liste mit \(n\) Elementen zu mischen, la&#x0308;sst sich ausdru&#x0308;cken als \(T(n) = 2 \cdot T(\frac {n}{2}) + n\), wobei
\(T(2) = 1\). Eine solche rekursive Formel wu&#x0308;rde sich mit dem <em>Master-Theorem</em> analytisch lo&#x0308;sen lassen.
</p>
<p>
Intuitiv nimmt man an, dass \(n = 2^k\) (sonst erweitert man die Eingabe um Dummyzahlen, was die Problemgro&#x0308;ße nur um konstanten Faktor vera&#x0308;ndert). Um zwei Folgen der La&#x0308;nge \(\frac
{n}{2^i}\) zu mischen, sind \(2 \cdot \frac {n}{2^i}\) Vergleiche no&#x0308;tig. Im Laufe des Algorithmus tauchen \(2^i\) Folgen der La&#x0308;nge \(\frac {n}{2^i}\) auf, also \(\frac {1}{2}
\cdot 2^i\) Paare. Daher ist der Aufwand zum Mischen aller Folgen der La&#x0308;nge \(\frac {n}{2^i}\) gleich \(\frac {1}{2} \cdot 2^i \cdot 2 \cdot \frac {n}{2^i} = n\). Es treten \(\sim
\log _2 n\) viele verschiedene Teilfolgenla&#x0308;ngen auf, daher ist der Gesamtaufwand \(\O (n \log n)\).
</p>
<p>
Mergesort ist ein <b>optimales Sortierverfahren</b>.<br />
Man kann zeigen, dass das Sortierproblem nicht schneller als \(\O (n \log n)\) zu lo&#x0308;sen ist (zumindest nicht mit vergleichsbasierten, deterministischen Algorithmen, siehe unten).
</p>


<h2 id="insertionsort">Insertionsort</h2>

</p>
<pre class="programlisting">
Insertionsort(A, n)
   for j = 1 to n - 1 do
      key := A[j]
      i := j - 1
      while (i &gt;= 0 and A[i] &gt;key) do
         A[i + 1] := A[i]
         i := i - 1
      od
      A[i + 1] := key
   od
</pre>


<p>
<b>Beschreibung</b>:<br />
Um eine Liste \(A[0], \ldots , A[n - 1]\) mit \(n\) Elementen zu sortieren, geht Insertionsort im \(j\)-ten Schritt davon aus, dass die Liste \(A[0], \ldots , A[j - 1]\) schon sortiert ist (\(1 \le j \le n
- 1\)).<br />
Der <span class="inlineprogramlisting"></span>key \(= A[j]\) wird dann an der richtigen Stelle in dieser Liste eingefu&#x0308;gt, sodass die Liste \(A[0], \ldots , A[j - 1], A[j]\) sortiert ist.
Dazu werden die gro&#x0308;ßeren Elemente (als der <span class="inlineprogramlisting"></span>key) allesamt „nach rechts geschoben“ und <span class="inlineprogramlisting"></span>key
eingefu&#x0308;gt (engl. <em>insert</em>).
</p>
<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
<b>Best-Case</b>: Insertionsort hat ein asymptotisches Laufzeitverhalten von \(\O (n)\) im Best-Case. Dieser tritt ein, falls die Liste anfangs schon sortiert ist.
</p>
<p>
<b>Worst-Case</b>: Insertionsort hat ein asymptotisches Laufzeitverhalten von \(\O (n^2)\) im Worst-Case. Dieser tritt ein, falls die Liste anfangs falsch herum sortiert ist.
</p>


<h2 id="heapsort">Heapsort</h2>

</p>

<p>
<b>Heapsort</b> basiert auf der Datenstruktur <em>Heap</em> und funktioniert wie folgt: Fu&#x0308;ge zuna&#x0308;chst alle \(n\) Elemente in den Heap ein, entferne dann \(n\)-mal das Maximum aus dem Heap und
gebe es aus.
</p>
<p>
<b>Heap</b>: Ein Heap (organisierter Haufen) ist ein Baum mit ausgezeichneter Wurzel, wobei die zu organisierenden Elemente in den Knoten des Baums stehen.<br />
Dabei gilt die sog. <b>Heap-Eigenschaft</b>: Das Element jedes Knotens ist immer gro&#x0308;ßer/gleich den Elementen der Kinder des Knotens.
</p>
<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
Wir fordern <b>bina&#x0308;re, balancierte Heaps</b>, bei denen nur „rechts unten“ Bla&#x0308;tter fehlen. Man kann solche Heaps mit \(n\) Knoten in einem Array \(A[0], \ldots , A[n - 1]\) schichtweise in
einem Array speichern, welches die vollsta&#x0308;ndige Stuktur des Heaps widerspiegelt. Dabei steht die Wurzel an Stelle \(0\) des Arrays. Der Vaterknoten eines Knotens mit Position \(i\) steht an Position \(\lfloor \frac
{i - 1}{2} \rfloor \). Der linke bzw. rechte Kindknoten eines Knotens mit Position \(i\) steht an Position \(2i + 1\) bzw. \(2i + 2\). Nur Knoten mit Position \(i \le \lfloor \frac {n}{2} \rfloor -
1\) und \(i \le \lfloor \frac {n}{2} \rfloor - 2\) haben ein linkes oder rechtes Kind.
</p>
<p>
Umgekehrt repra&#x0308;sentiert ein Array mit \(n\) Elementen \(V[0], \ldots , V[n - 1]\) einen Heap, falls<br />
\(V[i] \ge V[2i + 1]\) fu&#x0308;r alle \(i = 0, \ldots , \lfloor \frac {n}{2} \rfloor - 1\) und \(V[i] \ge V[2i + 2]\) fu&#x0308;r alle \(i = 0, \ldots , \lfloor \frac
{n}{2} \rfloor - 2\)<br />
(d.&#x202f;h. Heap-Eigenschaft ist erfu&#x0308;llt). Dabei steht in \(V[0]\) das gro&#x0308;ßte Element und jede Folge von Werten von einem Knoten absteigend zu einem Blatt ist monoton fallend.
</p>
<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
<b><span class="inlineprogramlisting"></span>heapify</b>: <span class="inlineprogramlisting"></span>heapify kann mit einer Voraussetzung die Heap-Eigenschaft eines Baums von
einem gewissen Index an wiederherstellen.
</p>
<p>
<b>Auf bau von <span class="inlineprogramlisting"></span>heapify</b>: Als Eingabe erwartet <span class="inlineprogramlisting"></span>heapify ein Array \(V[\;]\) und einen Index
\(top \in \{0, \ldots , n - 1\}\) mit der Annahme, dass fu&#x0308;r alle \(i = top + 1, \ldots , n - 1\) mit \(2i + 1 &lt; n\) bzw. \(2i + 2 &lt; n\) gilt, dass \(V[i] \ge V[2i + 1]\)
bzw. \(V[i] \ge V[2i + 2]\) (d.&#x202f;h. die Heap-Eigenschaft ist fu&#x0308;r alle Indizes \(i = top + 1, \ldots , n - 1\) erfu&#x0308;llt).<br />
Die Ausgabe ist ein nur in den Indizes \(top, \ldots , n - 1\) vera&#x0308;ndertes Array, bei dem die Heap-Eigenschaft fu&#x0308;r alle Indizes \(i = top, \ldots , n - 1\) erfu&#x0308;llt ist.
</p>
<p>
<b>Funktionsweise von <span class="inlineprogramlisting"></span>heapify</b>: Betrachte die Kinder des Knotens. Sind beide kleiner/gleich dem Knoten, dann ist <span
class="inlineprogramlisting"></span>heapify beendet. Ansonsten tausche den Inhalt des Knotens mit dem gro&#x0308;ßten Inhalt seiner beiden Kinder und betrachte dieses Kind rekursiv.
</p>
<p>
<b>Laufzeit von <span class="inlineprogramlisting"></span>heapify</b>: Eine mo&#x0308;gliche Verletzung der Heap-Eigenschaft wandert immer eine Tiefe nach unten. Somit ergibt sich eine Laufzeit von
\(\O (\log n)\).
</p>
<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
<b>Operationen des Heaps</b>: Hinzufu&#x0308;gen eines Elements zum Heap (<span class="inlineprogramlisting"></span>insert), Entfernen des Maximums aus dem Heap, welches immer in der Wurzel
steht (<span class="inlineprogramlisting"></span>remove_max), A&#x0308;ndern eines Elements im Heap (<span class="inlineprogramlisting"></span>change_key).
</p>
<p>
<b>Funktionsweise von <span class="inlineprogramlisting"></span>remove_max</b>: Entferne zuna&#x0308;chst das Element aus der Wurzel und gebe es zuru&#x0308;ck. Danach stelle durch Kopieren des
Inhalts des „letzten“ Blatts in die Wurzel und anschließendes Anwenden von <span class="inlineprogramlisting"></span>heapify auf der Wurzel die Heap-Eigenschaft wieder her.
</p>
<p>
<b>Funktionsweise von <span class="inlineprogramlisting"></span>insert</b>: Fu&#x0308;ge neues Blatt am „Ende“ des Heaps ein. Danach pru&#x0308;fe, ob die Heap-Eigenschaft zum Vaterknoten
verletzt ist. Falls ja, tausche mit Vaterknoten und u&#x0308;berpru&#x0308;fe diesen rekursiv, falls nein, ist die Prozedur beendet und der Baum wieder ein Heap.
</p>
<p>
<b>Kosten von <span class="inlineprogramlisting"></span>remove_max und <span class="inlineprogramlisting"></span>insert</b>: \(\O (\log n)\)
</p>
<p>
<b>Funktionsweise <span class="inlineprogramlisting"></span>change_key</b>: <span class="inlineprogramlisting"></span>change_key a&#x0308;ndert den Wert eines Knotens im
Heap. Wird der Schlu&#x0308;ssel erho&#x0308;ht, so muss mit dem Vaterknoten verglichen, ggf. getauscht und rekursiv der Vaterknoten u&#x0308;berpru&#x0308;ft werden. Wird der Schlu&#x0308;ssel verringert, so muss
<span class="inlineprogramlisting"></span>heapify auf den Knoten aufgerufen werden. Die Laufzeit von <span class="inlineprogramlisting"></span>change_key betra&#x0308;gt also in
jedem Fall \(\O (\log n)\).
</p>
<p>
<b>Theorem</b>: Ein bina&#x0308;rer Heap unterstu&#x0308;tzt <span class="inlineprogramlisting"></span>insert, <span class="inlineprogramlisting"></span>remove_max sowie
<span class="inlineprogramlisting"></span>change_key jeweils in \(\O (\log n)\). Ein Heap mit \(n\) Elementen kann auch in \(\O (n)\) konstruiert werden.
</p>
<p>
<b>Anmerkung</b>: Es gibt spezialisierte Heaps, die manche Operationen besser ko&#x0308;nnen. Ist z.&#x202f;B. bekannt, dass bei <span class="inlineprogramlisting"></span>change_key der Wert immer
nur erho&#x0308;ht wird und die Maxima wa&#x0308;hrend der Lebenszeit des Heaps monoton fallen, so gibt es spezielle Fibonacci-Heaps, die <span class="inlineprogramlisting"></span>change_key in
amortisiert \(\O (1)\) ausfu&#x0308;hren ko&#x0308;nnen.
</p>
<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
<b>Mo&#x0308;glichkeiten fu&#x0308;r Konstruktion des Heaps</b>: Entweder fu&#x0308;hrt man \(n\) <span class="inlineprogramlisting"></span>insert-Operationen aus oder man schreibt die zu
organisierenden Daten zuerst beliebig in \(V\) und stellt dann die Heap-Struktur wieder her. Die erste Variante hat eine Laufzeit von \(\O (n \log n)\).
</p>
<p>
<b>Konstruktion des Heaps in \(\O (n)\)</b>: Mit der zweiten Variante kann man den Heap in \(\O (n)\) konstruieren. Zuna&#x0308;chst schreibt man die Daten in beliebiger Reihenfolge in den Baum. Dann ruft man
<span class="inlineprogramlisting"></span>heapify fu&#x0308;r jeden Knoten auf, von hinten nach vorne beginnend mit dem „letzten“.<br />
Eine simple Laufzeitanalyse ergibt ein \(\O (n \log n)\)-Verhalten (\(n\)-mal <span class="inlineprogramlisting"></span>heapify). Man kann jedoch beobachten, dass <span
class="inlineprogramlisting"></span>heapify fu&#x0308;r untere Knoten erheblich schneller ist wie fu&#x0308;r obere.
</p>
<p>
<b>amortisierte Laufzeitanalyse</b>: Bei dieser Art von Laufzeitanalyse von Operationenfolgen betrachtet man nicht die maximalen Kosten jedes einzelnen Schritts, sondern man beru&#x0308;cksichtigt verschiedene Laufzeiten
bei unterschiedlichen Aufrufen. Somit kann sich im gesamten Worst-Case-Verhalten eine bessere Laufzeitschranke ergeben.
</p>
<p>
Ein Knoten der Ho&#x0308;he \(h\) hat Kosten \(h\) (max. Aufrufe aller <span class="inlineprogramlisting"></span>heapifys fu&#x0308;r den Knoten). Lege auf jeden Knoten seine Kosten in Form von
Mu&#x0308;nzen. Die Gesamtzahl an Mu&#x0308;nzen im Baum entspricht dann der Gesamtlaufzeit aller <span class="inlineprogramlisting"></span>heapifys. Geschickte Za&#x0308;hlung: Verteile die
Mu&#x0308;nzen jedes Knotens auf dem Pfad zu einem Blatt, der zuna&#x0308;chst einmal „links“, dann immer „rechts“ fu&#x0308;hrt (auf jede Kante eine Mu&#x0308;nze legen). Man kann beobachten, dass die Pfade disjunkt
sind. Somit liegt auf jeder Kante maximal eine Mu&#x0308;nze und die Gesamtanzahl an Mu&#x0308;nzen im Baum ist kleiner/gleich wie die Anzahl an Kanten \(n - 1\) (falls der Baum \(n\) Knoten hat). Also ist die
Gesamtlaufzeit aller <span class="inlineprogramlisting"></span>heapifys \(\O (n)\).
</p>


<h2 id="quicksort">Quicksort</h2>

</p>

<p>
<b>Quicksort</b> funktioniert wie Mergesort gema&#x0308;ß „Teile &amp; Herrsche“. Der große Unterschied besteht jedoch darin, dass Quicksort hier randomisiert ist, d.&#x202f;h. der Algorithmus „wu&#x0308;rfelt“ und
macht das weitere Vorgehen vom Ergebnis des Zufallsexperiments abha&#x0308;ngig. Man will allerdings garantieren, dass am Ende immer das richtige Ergebnis herauskommt. Die Laufzeitanalyse ergibt dabei einen Erwartungswert
fu&#x0308;r die Laufzeit, der unabha&#x0308;ngig von der Eingabe ist.
</p>
<pre class="programlisting">
Quicksort(A[1 ... n])
   waehle ein A[p] mit p in {1, ..., n} zufaellig gleichverteilt (u.a.r.)

    rearrangiere A in A_L A[p] A_R, wobei fuer alle a in A_L gilt, dass
    a &lt;= A[p], sowie fuer alle a in A_R gilt, dass a &gt;A[p]

    Quicksort(A_L)
    Quicksort(A_R)
</pre>


<p>
Dabei steht u.a.r. fu&#x0308;r <em>uniformly at random</em> und bedeutet „gleichverteilt“. <span class="inlineprogramlisting">A[p</span>] heißt auch <b>Pivotelement</b>. Fu&#x0308;r die
Rearrangierung sind \(n - 1\) Vergleiche notwendig.
</p>
<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
<b>Laufzeitanalyse</b>: Angenommen, es wird zufa&#x0308;llig immer das kleinste Element als Pivotelement gewa&#x0308;hlt. Dann ist \(A_L\) immer leer und der na&#x0308;chste Aufruf muss \(n - 1\) Elemente
sortieren. Dies ergibt eine Laufzeit von \(\O (n^2)\). Jedoch sollte dieser Fall fast nie eintreten, weil die \(A[p]\) immer zufa&#x0308;llig gewa&#x0308;hlt werden.
</p>
<p>
Fu&#x0308;r die randomisierte Laufzeitanalyse beno&#x0308;tigt man ein paar grundlegende Definitionen:
</p>
<p>
<b>reelle Zufallvariable</b>: Eine Funktion, die jedem Ergebnis eines Zufallsexperiments eine reelle Zahl zuweist. Beispiel Wu&#x0308;rfeln mit zwei Wu&#x0308;rfel: Dann ist \(x_{ij} = i + j\) eine Zufallsvariable,
wobei \(ij\) das Ergebnis bedeutet, bei dem der erste Wu&#x0308;rfel \(i\) Augen und der zweite \(j\) Augen zeigt.
</p>
<p>
<b>Erwartungswert</b>: Ein gewichteter Durchschnitt aller auftretenden Werte der Zufallsvariable gema&#x0308;ß der Wahrscheinlichkeit, wobei der Erwartungswert einer bestimmten Zufallsvariable zugewiesen wird. Somit
gibt der Erwartungswert die durchschnittlich zu erwartenden Kosten etc. an. Beispiel Wu&#x0308;rfeln mit zwei Wu&#x0308;rfel: Sei \(X\) die Summe der Augenzahlen beider Wu&#x0308;rfel, dann ist der Erwartungswert
\(E(X) = 2 \cdot \frac {1}{36} + 3 \cdot \frac {2}{36} + \dotsb + 11 \cdot \frac {2}{36} + 12 \cdot \frac {1}{36} = 7\).<br />
Der Erwartungswert der Summe von Zufallsvariablen ist die Summe der Erwartungswerte.
</p>
<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
Im Folgenden wird gezeigt, dass die erwartete Laufzeit unabha&#x0308;ngig von der Eingabe \(\O (n \log n)\) ist. Man kann auch zeigen, dass es sehr unwahrscheinlich ist, dass die Laufzeit stark vom Erwartungswert
abweicht.
</p>
<p>
<b>Beweis</b>: Seien \(s_1, \dotsc , s_n\) die zu sortierenden Elemente gema&#x0308;ß der Ordnung, d&#x202f;h. \(s_i \le s_{i+1}\) fu&#x0308;r \(i = 1, \dotsc , n - 1\). Definiere die
Zufallvariable \(x_{ij} = \begin {cases}1 &amp; s_i, s_j \text { werden wÃd’hrend des kompletten Quicksort miteinander verglichen} \\ 0 &amp; \text {sonst}\end
{cases}\). Beachte, dass \(s_i\) und \(s_j\) ho&#x0308;chstens einmal miteinander verglichen werden ko&#x0308;nnen. Dann betra&#x0308;gt die Gesamtlaufzeit \(\sum _{i &lt; j} x_{ij}\) (Gesamtzahl der
Vergleiche, \(x_{ij} = x_{ji}\) nicht doppelt za&#x0308;hlen), wobei u&#x0308;ber \(i, j = 1, \dotsc , n\) summiert wird.<br />
Die erwartete Laufzeit betra&#x0308;gt somit \(E(\sum _{i &lt; j} x_{ij}) = \sum _{i &lt; j} E(x_{ij})\).
</p>
<p>
Was ist \(E(x_{ij})\)? Sei \(p_{ij}\) die Wahrscheinlichkeit, dass \(s_i\) und \(s_j\) wa&#x0308;hrend des kompletten Quicksort miteinander verglichen werden, dann ist \(E(x_{ij}) = 1 \cdot p_{ij} + 0
\cdot (1 - p_{ij}) = p_{ij}\) (nach Wahrscheinlichkeit gewichteter Durchschnitt der Werte, die \(x_{ij}\) annehmen kann).
</p>
<p>
Was ist nun \(p_{ij}\)? Man kann den Ablauf von Quicksort als Bina&#x0308;rbaum darstellen, wobei jeder Knoten ein Pivotelement darstellt und das linke bzw. rechte Kind dem Pivotelement von \(A_L\) bzw. \(A_R\)
entspricht. Schreibe nun die Knoten in diesem Baum als Permutation in Levelorder (Breitensuche: Ebene fu&#x0308;r Ebene von oben nach unten, dort links nach rechts) auf.
</p>
<p>
Wenn \(s_i\) mit \(s_j\) verglichen wird, dann befindet sich kein Element \(s_k\) mit \(s_i &lt; s_k &lt; s_j\) vor \(s_i\) und \(s_j\) in der Permutation, da sonst dieses \(s_k\) als Pivotelement \(s_i\) in
\(A_L\) und \(s_j\) in \(A_R\) sortiert ha&#x0308;tte (somit wa&#x0308;ren die beiden nicht verglichen worden). Umgekehrt verha&#x0308;lt es sich genau so.<br />
Betrachtet man die Elemente \(s_i, s_{i+1}, \dotsc , s_{j-1}, s_j\), so tritt jedes mit gleicher Wahrscheinlichkeit als erstes dieser Elemente in der Permutation auf. Die Wahrscheinlichkeit, dass kein \(s_k\) mit
\(s_i &lt; s_k &lt; s_j\) vor \(s_i\) und \(s_j\) auftritt, ist gleichbedeutend mit der Wahrscheinlichkeit, dass \(s_i\) oder \(s_j\) als erstes Element auftritt. Also ist \(p_{ij} = \frac {2}{j - i + 1}\),
da es \(j - i + 1\) Elemente in dieser Liste gibt.
</p>
<p>
Also ist \(\sum _{i &lt; j} E(x_{ij}) = \sum _{i &lt; j} p_{ij} = \sum _{i &lt; j} \frac {2}{j - i + 1} = \sum _{i=1}^n (1 + \sum _{j=i+2}^n \frac {2}{j - i +
1}) = \sum _{i=1}^n (1 + \sum _{j=1}^{n-i-1} \frac {2}{j})\)<br />
\(= n + 2 \cdot \sum _{i=1}^n \sum _{j=1}^{n-i-1} \frac {1}{j} \le n + 2 \cdot \sum _{i=1}^n \sum _{j=1}^{n} \frac {1}{j} \le n + 2 \cdot \sum _{i=1}^n \log
n \in \O (n \log n)\). &#x2003;&#x2003;
</p>


<h2 id="grenze-von-vergleichsbasiertem-sortieren">Grenze von vergleichsbasiertem Sortieren</h2>

</p>

<p>
Gibt es Sortieralgorithmen, die eine bessere Schranke als \(\O (n \log n)\) besitzen? Zuna&#x0308;chst muss ein Sortierverfahren stets alle Elemente der Eingabe betrachten. Andernfalls ko&#x0308;nnte man in einem nicht
betrachteten Element eine Zahl „verstecken“, die der berechneten Sortierung widerspricht. Daher beno&#x0308;tigt jeder Sortieralgorithmus mindestens \(\Omega (n)\).
</p>
<p>
<b>Behauptung</b>: Jeder vergleichsbasierte deterministische Sortieralgorithmus muss im Worst-Case \(\Omega (n \log n)\) Zeit aufwenden.
</p>
<p>
<b>Beweis</b>: Man kann die Ausfu&#x0308;hrung eines deterministischen Algorithmus als Folge von Vergleichen auffassen. Wegen des Determinismus fu&#x0308;hrt der Algorithmus je nach Ausgang eines Vergleichs einen
bestimmten na&#x0308;chsten Vergleich aus (oder terminiert). Somit la&#x0308;sst sich der Ablauf als Bina&#x0308;rbaum darstellen (wahrer/falscher Vergleich). Der Algorithmus stoppt nach einer gewissen Anzahl an
Vergleichen und gibt eine Permutation der Eingabe aus. Dies entspricht einem Blatt in diesem Baum. Verschiedene Permutationen (derselben Eingabe) mu&#x0308;ssen in verschiedenen Bla&#x0308;ttern des Baums enden, sonst
wa&#x0308;re fu&#x0308;r eine Eingabe die Ausgabe falsch. Es gibt \(n!\) verschiedene Permutationen und ein Bina&#x0308;rbaum der Ho&#x0308;he \(h\) hat ho&#x0308;chstens \(2^h\) viele Bla&#x0308;tter. Es muss
wegen des vorherigen Satzes mindestens so viele Bla&#x0308;tter wie Permutationen geben. Also gilt \(2^h \ge n!\) bzw. \(h \ge \log n! \ge \log \left (\frac {n}{e}\right )^n = n \cdot \log
\frac {n}{e} \in \Omega (n \log n)\) (<span class="textsc" >Stirling</span>-Formel). Die Ho&#x0308;he des Baums entspricht der Anzahl an Vergleichen im Worst-Case, also ist die Worst-Case-Laufzeit
\(\Omega (n \log n)\). &#x2003;&#x2003;
</p>
<p>
Der Beweis gilt nur fu&#x0308;r deterministische Algorithmen (also eigentlich nicht fu&#x0308;r randomisierte Algorithmen wie Quicksort). Man kann allerdings zeigen, dass randomisiertes Sortieren ebenfalls erwartet \(\Omega
(n \log n)\) Zeit braucht.
</p>
<p>
Nimmt man an, die zu sortierenden Objekte sind Zahlen beschra&#x0308;nkter Gro&#x0308;ße, so gibt es (nicht vergleichsbasierte) Sortierverfahren, die die \(\Omega (n \log n)\)-Schranke schlagen (z.&#x202f;B.
Countingsort, Radixsort).
</p>

{% endraw %}
</div>
{:/nomarkdown}
