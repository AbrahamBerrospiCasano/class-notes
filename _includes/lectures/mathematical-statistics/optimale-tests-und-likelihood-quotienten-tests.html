
{::nomarkdown}
<div class="lwarp-contents">
{% raw %}
<div class="hidden" >

\(\newcommand{\footnotename}{footnote}\)

\(\def \LWRfootnote {1}\)

\(\newcommand {\footnote }[2][\LWRfootnote ]{{}^{\mathrm {#1}}}\)

\(\newcommand {\footnotemark }[1][\LWRfootnote ]{{}^{\mathrm {#1}}}\)

\(\newcommand \ensuremath [1]{#1}\)

\(\newcommand {\LWRframebox }[2][]{\fbox {#2}} \newcommand {\framebox }[1][]{\LWRframebox } \)

\(\newcommand {\setlength }[2]{}\)

\(\newcommand {\addtolength }[2]{}\)

\(\newcommand {\setcounter }[2]{}\)

\(\newcommand {\addtocounter }[2]{}\)

\(\newcommand {\cline }[1]{}\)

\(\newcommand {\directlua }[1]{\text {(directlua)}}\)

\(\newcommand {\luatexdirectlua }[1]{\text {(directlua)}}\)

\(\newcommand {\protect }{}\)

\(\def \LWRabsorbnumber #1 {}\)

\(\def \LWRabsorbquotenumber &quot;#1 {}\)

\(\def \mathchar {\ifnextchar &quot;\LWRabsorbquotenumber \LWRabsorbnumber }\)

\(\def \mathcode #1={\mathchar }\)

\(\let \delcode \mathcode \)

\(\let \delimiter \mathchar \)

\(\let \LWRref \ref \)

\(\renewcommand {\ref }{\ifstar \LWRref \LWRref }\)

\(\newcommand {\intertext }[1]{\text {#1}\notag \\}\)

\(\newcommand {\mathllap }[2][]{{#1#2}}\)

\(\newcommand {\mathrlap }[2][]{{#1#2}}\)

\(\newcommand {\mathclap }[2][]{{#1#2}}\)

\(\newcommand {\mathmbox }[1]{#1}\)

\(\newcommand {\clap }[1]{#1}\)

\(\newcommand {\LWRmathmakebox }[2][]{#2}\)

\(\newcommand {\mathmakebox }[1][]{\LWRmathmakebox }\)

\(\newcommand {\cramped }[2][]{{#1#2}}\)

\(\newcommand {\crampedllap }[2][]{{#1#2}}\)

\(\newcommand {\crampedrlap }[2][]{{#1#2}}\)

\(\newcommand {\crampedclap }[2][]{{#1#2}}\)

\(\newenvironment {crampedsubarray}[1]{}{}\)

\(\newcommand {\crampedsubstack }{}\)

\(\newcommand {\smashoperator }[2][]{#2\limits }\)

\(\newcommand {\adjustlimits }{}\)

\(\newcommand {\SwapAboveDisplaySkip }{}\)

\(\require {extpfeil}\)

\(\Newextarrow \xleftrightarrow {10,10}{0x2194}\)

\(\Newextarrow \xLeftarrow {10,10}{0x21d0}\)

\(\Newextarrow \xhookleftarrow {10,10}{0x21a9}\)

\(\Newextarrow \xmapsto {10,10}{0x21a6}\)

\(\Newextarrow \xRightarrow {10,10}{0x21d2}\)

\(\Newextarrow \xLeftrightarrow {10,10}{0x21d4}\)

\(\Newextarrow \xhookrightarrow {10,10}{0x21aa}\)

\(\Newextarrow \xrightharpoondown {10,10}{0x21c1}\)

\(\Newextarrow \xleftharpoondown {10,10}{0x21bd}\)

\(\Newextarrow \xrightleftharpoons {10,10}{0x21cc}\)

\(\Newextarrow \xrightharpoonup {10,10}{0x21c0}\)

\(\Newextarrow \xleftharpoonup {10,10}{0x21bc}\)

\(\Newextarrow \xleftrightharpoons {10,10}{0x21cb}\)

\(\newcommand {\LWRdounderbracket }[3]{\underset {#3}{\underline {#1}}}\)

\(\newcommand {\LWRunderbracket }[2][]{\LWRdounderbracket {#2}}\)

\(\newcommand {\underbracket }[1][]{\LWRunderbracket }\)

\(\newcommand {\LWRdooverbracket }[3]{\overset {#3}{\overline {#1}}}\)

\(\newcommand {\LWRoverbracket }[2][]{\LWRdooverbracket {#2}}\)

\(\newcommand {\overbracket }[1][]{\LWRoverbracket }\)

\(\newcommand {\LaTeXunderbrace }[1]{\underbrace {#1}}\)

\(\newcommand {\LaTeXoverbrace }[1]{\overbrace {#1}}\)

\(\newenvironment {matrix*}[1][]{\begin {matrix}}{\end {matrix}}\)

\(\newenvironment {pmatrix*}[1][]{\begin {pmatrix}}{\end {pmatrix}}\)

\(\newenvironment {bmatrix*}[1][]{\begin {bmatrix}}{\end {bmatrix}}\)

\(\newenvironment {Bmatrix*}[1][]{\begin {Bmatrix}}{\end {Bmatrix}}\)

\(\newenvironment {vmatrix*}[1][]{\begin {vmatrix}}{\end {vmatrix}}\)

\(\newenvironment {Vmatrix*}[1][]{\begin {Vmatrix}}{\end {Vmatrix}}\)

\(\newenvironment {smallmatrix*}[1][]{\begin {matrix}}{\end {matrix}}\)

\(\newenvironment {psmallmatrix*}[1][]{\begin {pmatrix}}{\end {pmatrix}}\)

\(\newenvironment {bsmallmatrix*}[1][]{\begin {bmatrix}}{\end {bmatrix}}\)

\(\newenvironment {Bsmallmatrix*}[1][]{\begin {Bmatrix}}{\end {Bmatrix}}\)

\(\newenvironment {vsmallmatrix*}[1][]{\begin {vmatrix}}{\end {vmatrix}}\)

\(\newenvironment {Vsmallmatrix*}[1][]{\begin {Vmatrix}}{\end {Vmatrix}}\)

\(\newenvironment {psmallmatrix}[1][]{\begin {pmatrix}}{\end {pmatrix}}\)

\(\newenvironment {bsmallmatrix}[1][]{\begin {bmatrix}}{\end {bmatrix}}\)

\(\newenvironment {Bsmallmatrix}[1][]{\begin {Bmatrix}}{\end {Bmatrix}}\)

\(\newenvironment {vsmallmatrix}[1][]{\begin {vmatrix}}{\end {vmatrix}}\)

\(\newenvironment {Vsmallmatrix}[1][]{\begin {Vmatrix}}{\end {Vmatrix}}\)

\(\newcommand {\LWRmultlined }[1][]{\begin {multline*}}\)

\(\newenvironment {multlined}[1][]{\LWRmultlined }{\end {multline*}}\)

\(\let \LWRorigshoveleft \shoveleft \)

\(\renewcommand {\shoveleft }[1][]{\LWRorigshoveleft }\)

\(\let \LWRorigshoveright \shoveright \)

\(\renewcommand {\shoveright }[1][]{\LWRorigshoveright }\)

\(\newenvironment {dcases}{\begin {cases}}{\end {cases}}\)

\(\newenvironment {dcases*}{\begin {cases}}{\end {cases}}\)

\(\newenvironment {rcases}{\begin {cases}}{\end {cases}}\)

\(\newenvironment {rcases*}{\begin {cases}}{\end {cases}}\)

\(\newenvironment {drcases}{\begin {cases}}{\end {cases}}\)

\(\newenvironment {drcases*}{\begin {cases}}{\end {cases}}\)

\(\newenvironment {cases*}{\begin {cases}}{\end {cases}}\)

\(\newcommand {\MoveEqLeft }[1][]{}\)

\(\def \LWRAboxed #1&amp;#2&amp;#3!|!{\fbox {\(#1\)}&amp;\fbox {\(#2\)}} \newcommand {\Aboxed }[1]{\LWRAboxed #1&amp;&amp;!|!} \)

\( \newcommand {\LWRABLines }[1][\Updownarrow ]{#1 \notag \\}\newcommand {\ArrowBetweenLines }{\ifstar \LWRABLines \LWRABLines } \)

\(\newcommand {\shortintertext }[1]{\text {#1}\notag \\}\)

\(\newcommand {\vdotswithin }[1]{\hspace {.5em}\vdots }\)

\(\newcommand {\LWRshortvdotswithinstar }[1]{\vdots \hspace {.5em} &amp; \\}\)

\(\newcommand {\LWRshortvdotswithinnostar }[1]{&amp; \hspace {.5em}\vdots \\}\)

\(\newcommand {\shortvdotswithin }{\ifstar \LWRshortvdotswithinstar \LWRshortvdotswithinnostar }\)

\(\newcommand {\MTFlushSpaceAbove }{}\)

\(\newcommand {\MTFlushSpaceBelow }{\\}\)

\(\newcommand \lparen {(}\)

\(\newcommand \rparen {)}\)

\(\newcommand {\ordinarycolon }{:}\)

\(\newcommand {\vcentcolon }{\mathrel {\mathop \ordinarycolon }}\)

\(\newcommand \dblcolon {\vcentcolon \vcentcolon }\)

\(\newcommand \coloneqq {\vcentcolon =}\)

\(\newcommand \Coloneqq {\dblcolon =}\)

\(\newcommand \coloneq {\vcentcolon {-}}\)

\(\newcommand \Coloneq {\dblcolon {-}}\)

\(\newcommand \eqqcolon {=\vcentcolon }\)

\(\newcommand \Eqqcolon {=\dblcolon }\)

\(\newcommand \eqcolon {\mathrel {-}\vcentcolon }\)

\(\newcommand \Eqcolon {\mathrel {-}\dblcolon }\)

\(\newcommand \colonapprox {\vcentcolon \approx }\)

\(\newcommand \Colonapprox {\dblcolon \approx }\)

\(\newcommand \colonsim {\vcentcolon \sim }\)

\(\newcommand \Colonsim {\dblcolon \sim }\)

\(\newcommand {\nuparrow }{\mathrel {\cancel {\uparrow }}}\)

\(\newcommand {\ndownarrow }{\mathrel {\cancel {\downarrow }}}\)

\(\newcommand {\bigtimes }{\mathop {\Large \times }\limits }\)

\(\newcommand {\prescript }[3]{{}^{#1}_{#2}#3}\)

\(\newenvironment {lgathered}{\begin {gathered}}{\end {gathered}}\)

\(\newenvironment {rgathered}{\begin {gathered}}{\end {gathered}}\)

\(\newcommand {\splitfrac }[2]{{}^{#1}_{#2}}\)

\(\let \splitdfrac \splitfrac \)

\(\newcommand {\LWRoverlaysymbols }[2]{\mathord {\smash {\mathop {#2\strut }\limits ^{\smash {\lower 3ex{#1}}}}\strut }}\)

\(\newcommand{\alphaup}{\unicode{x03B1}}\)

\(\newcommand{\betaup}{\unicode{x03B2}}\)

\(\newcommand{\gammaup}{\unicode{x03B3}}\)

\(\newcommand{\digammaup}{\unicode{x03DD}}\)

\(\newcommand{\deltaup}{\unicode{x03B4}}\)

\(\newcommand{\epsilonup}{\unicode{x03F5}}\)

\(\newcommand{\varepsilonup}{\unicode{x03B5}}\)

\(\newcommand{\zetaup}{\unicode{x03B6}}\)

\(\newcommand{\etaup}{\unicode{x03B7}}\)

\(\newcommand{\thetaup}{\unicode{x03B8}}\)

\(\newcommand{\varthetaup}{\unicode{x03D1}}\)

\(\newcommand{\iotaup}{\unicode{x03B9}}\)

\(\newcommand{\kappaup}{\unicode{x03BA}}\)

\(\newcommand{\varkappaup}{\unicode{x03F0}}\)

\(\newcommand{\lambdaup}{\unicode{x03BB}}\)

\(\newcommand{\muup}{\unicode{x03BC}}\)

\(\newcommand{\nuup}{\unicode{x03BD}}\)

\(\newcommand{\xiup}{\unicode{x03BE}}\)

\(\newcommand{\omicronup}{\unicode{x03BF}}\)

\(\newcommand{\piup}{\unicode{x03C0}}\)

\(\newcommand{\varpiup}{\unicode{x03D6}}\)

\(\newcommand{\rhoup}{\unicode{x03C1}}\)

\(\newcommand{\varrhoup}{\unicode{x03F1}}\)

\(\newcommand{\sigmaup}{\unicode{x03C3}}\)

\(\newcommand{\varsigmaup}{\unicode{x03C2}}\)

\(\newcommand{\tauup}{\unicode{x03C4}}\)

\(\newcommand{\upsilonup}{\unicode{x03C5}}\)

\(\newcommand{\phiup}{\unicode{x03D5}}\)

\(\newcommand{\varphiup}{\unicode{x03C6}}\)

\(\newcommand{\chiup}{\unicode{x03C7}}\)

\(\newcommand{\psiup}{\unicode{x03C8}}\)

\(\newcommand{\omegaup}{\unicode{x03C9}}\)

\(\newcommand{\Alphaup}{\unicode{x0391}}\)

\(\newcommand{\Betaup}{\unicode{x0392}}\)

\(\newcommand{\Gammaup}{\unicode{x0393}}\)

\(\newcommand{\Digammaup}{\unicode{x03DC}}\)

\(\newcommand{\Deltaup}{\unicode{x0394}}\)

\(\newcommand{\Epsilonup}{\unicode{x0395}}\)

\(\newcommand{\Zetaup}{\unicode{x0396}}\)

\(\newcommand{\Etaup}{\unicode{x0397}}\)

\(\newcommand{\Thetaup}{\unicode{x0398}}\)

\(\newcommand{\Varthetaup}{\unicode{x03F4}}\)

\(\newcommand{\Iotaup}{\unicode{x0399}}\)

\(\newcommand{\Kappaup}{\unicode{x039A}}\)

\(\newcommand{\Lambdaup}{\unicode{x039B}}\)

\(\newcommand{\Muup}{\unicode{x039C}}\)

\(\newcommand{\Nuup}{\unicode{x039D}}\)

\(\newcommand{\Xiup}{\unicode{x039E}}\)

\(\newcommand{\Omicronup}{\unicode{x039F}}\)

\(\newcommand{\Piup}{\unicode{x03A0}}\)

\(\newcommand{\Varpiup}{\unicode{x03D6}}\)

\(\newcommand{\Rhoup}{\unicode{x03A1}}\)

\(\newcommand{\Sigmaup}{\unicode{x03A3}}\)

\(\newcommand{\Tauup}{\unicode{x03A4}}\)

\(\newcommand{\Upsilonup}{\unicode{x03A5}}\)

\(\newcommand{\Phiup}{\unicode{x03A6}}\)

\(\newcommand{\Chiup}{\unicode{x03A7}}\)

\(\newcommand{\Psiup}{\unicode{x03A8}}\)

\(\newcommand{\Omegaup}{\unicode{x03A9}}\)

\(\newcommand{\alphait}{\unicode{x1D6FC}}\)

\(\newcommand{\betait}{\unicode{x1D6FD}}\)

\(\newcommand{\gammait}{\unicode{x1D6FE}}\)

\(\newcommand{\digammait}{\mathit{\unicode{x03DD}}}\)

\(\newcommand{\deltait}{\unicode{x1D6FF}}\)

\(\newcommand{\epsilonit}{\unicode{x1D716}}\)

\(\newcommand{\varepsilonit}{\unicode{x1D700}}\)

\(\newcommand{\zetait}{\unicode{x1D701}}\)

\(\newcommand{\etait}{\unicode{x1D702}}\)

\(\newcommand{\thetait}{\unicode{x1D703}}\)

\(\newcommand{\varthetait}{\unicode{x1D717}}\)

\(\newcommand{\iotait}{\unicode{x1D704}}\)

\(\newcommand{\kappait}{\unicode{x1D705}}\)

\(\newcommand{\varkappait}{\unicode{x1D718}}\)

\(\newcommand{\lambdait}{\unicode{x1D706}}\)

\(\newcommand{\muit}{\unicode{x1D707}}\)

\(\newcommand{\nuit}{\unicode{x1D708}}\)

\(\newcommand{\xiit}{\unicode{x1D709}}\)

\(\newcommand{\omicronit}{\unicode{x1D70A}}\)

\(\newcommand{\piit}{\unicode{x1D70B}}\)

\(\newcommand{\varpiit}{\unicode{x1D71B}}\)

\(\newcommand{\rhoit}{\unicode{x1D70C}}\)

\(\newcommand{\varrhoit}{\unicode{x1D71A}}\)

\(\newcommand{\sigmait}{\unicode{x1D70E}}\)

\(\newcommand{\varsigmait}{\unicode{x1D70D}}\)

\(\newcommand{\tauit}{\unicode{x1D70F}}\)

\(\newcommand{\upsilonit}{\unicode{x1D710}}\)

\(\newcommand{\phiit}{\unicode{x1D719}}\)

\(\newcommand{\varphiit}{\unicode{x1D711}}\)

\(\newcommand{\chiit}{\unicode{x1D712}}\)

\(\newcommand{\psiit}{\unicode{x1D713}}\)

\(\newcommand{\omegait}{\unicode{x1D714}}\)

\(\newcommand{\Alphait}{\unicode{x1D6E2}}\)

\(\newcommand{\Betait}{\unicode{x1D6E3}}\)

\(\newcommand{\Gammait}{\unicode{x1D6E4}}\)

\(\newcommand{\Digammait}{\mathit{\unicode{x03DC}}}\)

\(\newcommand{\Deltait}{\unicode{x1D6E5}}\)

\(\newcommand{\Epsilonit}{\unicode{x1D6E6}}\)

\(\newcommand{\Zetait}{\unicode{x1D6E7}}\)

\(\newcommand{\Etait}{\unicode{x1D6E8}}\)

\(\newcommand{\Thetait}{\unicode{x1D6E9}}\)

\(\newcommand{\Varthetait}{\unicode{x1D6F3}}\)

\(\newcommand{\Iotait}{\unicode{x1D6EA}}\)

\(\newcommand{\Kappait}{\unicode{x1D6EB}}\)

\(\newcommand{\Lambdait}{\unicode{x1D6EC}}\)

\(\newcommand{\Muit}{\unicode{x1D6ED}}\)

\(\newcommand{\Nuit}{\unicode{x1D6EE}}\)

\(\newcommand{\Xiit}{\unicode{x1D6EF}}\)

\(\newcommand{\Omicronit}{\unicode{x1D6F0}}\)

\(\newcommand{\Piit}{\unicode{x1D6F1}}\)

\(\newcommand{\Rhoit}{\unicode{x1D6F2}}\)

\(\newcommand{\Sigmait}{\unicode{x1D6F4}}\)

\(\newcommand{\Tauit}{\unicode{x1D6F5}}\)

\(\newcommand{\Upsilonit}{\unicode{x1D6F6}}\)

\(\newcommand{\Phiit}{\unicode{x1D6F7}}\)

\(\newcommand{\Chiit}{\unicode{x1D6F8}}\)

\(\newcommand{\Psiit}{\unicode{x1D6F9}}\)

\(\newcommand{\Omegait}{\unicode{x1D6FA}}\)

\(\let \digammaup \Digammaup \)

\(\renewcommand {\digammait }{\mathit {\digammaup }}\)

\(\newcommand {\smallin }{\unicode {x220A}}\)

\(\newcommand {\smallowns }{\unicode {x220D}}\)

\(\newcommand {\notsmallin }{\LWRoverlaysymbols {/}{\unicode {x220A}}}\)

\(\newcommand {\notsmallowns }{\LWRoverlaysymbols {/}{\unicode {x220D}}}\)

\(\newcommand {\rightangle }{\unicode {x221F}}\)

\(\newcommand {\intclockwise }{\unicode {x2231}}\)

\(\newcommand {\ointclockwise }{\unicode {x2232}}\)

\(\newcommand {\ointctrclockwise }{\unicode {x2233}}\)

\(\newcommand {\oiint }{\unicode {x222F}}\)

\(\newcommand {\oiiint }{\unicode {x2230}}\)

\(\newcommand {\ddag }{\unicode {x2021}}\)

\(\newcommand {\P }{\unicode {x00B6}}\)

\(\newcommand {\copyright }{\unicode {x00A9}}\)

\(\newcommand {\dag }{\unicode {x2020}}\)

\(\newcommand {\pounds }{\unicode {x00A3}}\)

\(\newcommand {\iddots }{\unicode {x22F0}}\)

\(\newcommand {\utimes }{\overline {\times }}\)

\(\newcommand {\dtimes }{\underline {\times }}\)

\(\newcommand {\udtimes }{\overline {\underline {\times }}}\)

\(\newcommand {\leftwave }{\left \{}\)

\(\newcommand {\rightwave }{\right \}}\)

\(\newcommand {\toprule }[1][]{\hline }\)

\(\let \midrule \toprule \)

\(\let \bottomrule \toprule \)

\(\newcommand {\cmidrule }[2][]{}\)

\(\newcommand {\morecmidrules }{}\)

\(\newcommand {\specialrule }[3]{\hline }\)

\(\newcommand {\addlinespace }[1][]{}\)

\(\newcommand {\LWRsubmultirow }[2][]{#2}\)

\(\newcommand {\LWRmultirow }[2][]{\LWRsubmultirow }\)

\(\newcommand {\multirow }[2][]{\LWRmultirow }\)

\(\newcommand {\mrowcell }{}\)

\(\newcommand {\mcolrowcell }{}\)

\(\newcommand {\STneed }[1]{}\)

\( \newcommand {\multicolumn }[3]{#3}\)

\(\newcommand {\tothe }[1]{^{#1}}\)

\(\newcommand {\raiseto }[2]{{#2}^{#1}}\)

\(\newcommand {\ang }[2][]{(\mathrm {#2})\degree }\)

\(\newcommand {\num }[2][]{\mathrm {#2}}\)

\(\newcommand {\si }[2][]{\mathrm {#2}}\)

\(\newcommand {\LWRSI }[2][]{\mathrm {#1\LWRSInumber \,#2}}\)

\(\newcommand {\SI }[2][]{\def \LWRSInumber {#2}\LWRSI }\)

\(\newcommand {\numlist }[2][]{\mathrm {#2}}\)

\(\newcommand {\numrange }[3][]{\mathrm {#2\,\unicode {x2013}\,#3}}\)

\(\newcommand {\SIlist }[3][]{\mathrm {#2\,#3}}\)

\(\newcommand {\SIrange }[4][]{\mathrm {#2\,#4\,\unicode {x2013}\,#3\,#4}}\)

\(\newcommand {\tablenum }[2][]{\mathrm {#2}}\)

\(\newcommand {\ampere }{\mathrm {A}}\)

\(\newcommand {\candela }{\mathrm {cd}}\)

\(\newcommand {\kelvin }{\mathrm {K}}\)

\(\newcommand {\kilogram }{\mathrm {kg}}\)

\(\newcommand {\metre }{\mathrm {m}}\)

\(\newcommand {\mole }{\mathrm {mol}}\)

\(\newcommand {\second }{\mathrm {s}}\)

\(\newcommand {\becquerel }{\mathrm {Bq}}\)

\(\newcommand {\degreeCelsius }{\unicode {x2103}}\)

\(\newcommand {\coulomb }{\mathrm {C}}\)

\(\newcommand {\farad }{\mathrm {F}}\)

\(\newcommand {\gray }{\mathrm {Gy}}\)

\(\newcommand {\hertz }{\mathrm {Hz}}\)

\(\newcommand {\henry }{\mathrm {H}}\)

\(\newcommand {\joule }{\mathrm {J}}\)

\(\newcommand {\katal }{\mathrm {kat}}\)

\(\newcommand {\lumen }{\mathrm {lm}}\)

\(\newcommand {\lux }{\mathrm {lx}}\)

\(\newcommand {\newton }{\mathrm {N}}\)

\(\newcommand {\ohm }{\mathrm {\Omega }}\)

\(\newcommand {\pascal }{\mathrm {Pa}}\)

\(\newcommand {\radian }{\mathrm {rad}}\)

\(\newcommand {\siemens }{\mathrm {S}}\)

\(\newcommand {\sievert }{\mathrm {Sv}}\)

\(\newcommand {\steradian }{\mathrm {sr}}\)

\(\newcommand {\tesla }{\mathrm {T}}\)

\(\newcommand {\volt }{\mathrm {V}}\)

\(\newcommand {\watt }{\mathrm {W}}\)

\(\newcommand {\weber }{\mathrm {Wb}}\)

\(\newcommand {\day }{\mathrm {d}}\)

\(\newcommand {\degree }{\mathrm {^\circ }}\)

\(\newcommand {\hectare }{\mathrm {ha}}\)

\(\newcommand {\hour }{\mathrm {h}}\)

\(\newcommand {\litre }{\mathrm {l}}\)

\(\newcommand {\liter }{\mathrm {L}}\)

\(\newcommand {\arcminute }{^\prime }\)
\(\newcommand {\minute }{\mathrm {min}}\)

\(\newcommand {\arcsecond }{^{\prime \prime }}\)

\(\newcommand {\tonne }{\mathrm {t}}\)

\(\newcommand {\astronomicalunit }{au}\)

\(\newcommand {\atomicmassunit }{u}\)

\(\newcommand {\bohr }{\mathit {a}_0}\)

\(\newcommand {\clight }{\mathit {c}_0}\)

\(\newcommand {\dalton }{\mathrm {D}_\mathrm {a}}\)

\(\newcommand {\electronmass }{\mathit {m}_{\mathrm {e}}}\)

\(\newcommand {\electronvolt }{\mathrm {eV}}\)

\(\newcommand {\elementarycharge }{\mathit {e}}\)

\(\newcommand {\hartree }{\mathit {E}_{\mathrm {h}}}\)

\(\newcommand {\planckbar }{\mathit {\unicode {x210F}}}\)

\(\newcommand {\angstrom }{\mathrm {\unicode {x212B}}}\)

\(\let \LWRorigbar \bar \)

\(\newcommand {\bar }{\mathrm {bar}}\)

\(\newcommand {\barn }{\mathrm {b}}\)

\(\newcommand {\bel }{\mathrm {B}}\)

\(\newcommand {\decibel }{\mathrm {dB}}\)

\(\newcommand {\knot }{\mathrm {kn}}\)

\(\newcommand {\mmHg }{\mathrm {mmHg}}\)

\(\newcommand {\nauticalmile }{\mathrm {M}}\)

\(\newcommand {\neper }{\mathrm {Np}}\)

\(\newcommand {\yocto }{\mathrm {y}}\)

\(\newcommand {\zepto }{\mathrm {z}}\)

\(\newcommand {\atto }{\mathrm {a}}\)

\(\newcommand {\femto }{\mathrm {f}}\)

\(\newcommand {\pico }{\mathrm {p}}\)

\(\newcommand {\nano }{\mathrm {n}}\)

\(\newcommand {\micro }{\mathrm {\unicode {x00B5}}}\)

\(\newcommand {\milli }{\mathrm {m}}\)

\(\newcommand {\centi }{\mathrm {c}}\)

\(\newcommand {\deci }{\mathrm {d}}\)

\(\newcommand {\deca }{\mathrm {da}}\)

\(\newcommand {\hecto }{\mathrm {h}}\)

\(\newcommand {\kilo }{\mathrm {k}}\)

\(\newcommand {\mega }{\mathrm {M}}\)

\(\newcommand {\giga }{\mathrm {G}}\)

\(\newcommand {\tera }{\mathrm {T}}\)

\(\newcommand {\peta }{\mathrm {P}}\)

\(\newcommand {\exa }{\mathrm {E}}\)

\(\newcommand {\zetta }{\mathrm {Z}}\)

\(\newcommand {\yotta }{\mathrm {Y}}\)

\(\newcommand {\percent }{\mathrm {\%}}\)

\(\newcommand {\meter }{\mathrm {m}}\)

\(\newcommand {\metre }{\mathrm {m}}\)

\(\newcommand {\gram }{\mathrm {g}}\)

\(\newcommand {\kg }{\kilo \gram }\)

\(\newcommand {\of }[1]{_{\mathrm {#1}}}\)

\(\newcommand {\squared }{^2}\)

\(\newcommand {\square }[1]{\mathrm {#1}^2}\)

\(\newcommand {\cubed }{^3}\)

\(\newcommand {\cubic }[1]{\mathrm {#1}^3}\)

\(\newcommand {\per }{/}\)

\(\newcommand {\celsius }{\unicode {x2103}}\)

\(\newcommand {\fg }{\femto \gram }\)

\(\newcommand {\pg }{\pico \gram }\)

\(\newcommand {\ng }{\nano \gram }\)

\(\newcommand {\ug }{\micro \gram }\)

\(\newcommand {\mg }{\milli \gram }\)

\(\newcommand {\g }{\gram }\)

\(\newcommand {\kg }{\kilo \gram }\)

\(\newcommand {\amu }{\mathrm {u}}\)

\(\newcommand {\nm }{\nano \metre }\)

\(\newcommand {\um }{\micro \metre }\)

\(\newcommand {\mm }{\milli \metre }\)

\(\newcommand {\cm }{\centi \metre }\)

\(\newcommand {\dm }{\deci \metre }\)

\(\newcommand {\m }{\metre }\)

\(\newcommand {\km }{\kilo \metre }\)

\(\newcommand {\as }{\atto \second }\)

\(\newcommand {\fs }{\femto \second }\)

\(\newcommand {\ps }{\pico \second }\)

\(\newcommand {\ns }{\nano \second }\)

\(\newcommand {\us }{\micro \second }\)

\(\newcommand {\ms }{\milli \second }\)

\(\newcommand {\s }{\second }\)

\(\newcommand {\fmol }{\femto \mol }\)

\(\newcommand {\pmol }{\pico \mol }\)

\(\newcommand {\nmol }{\nano \mol }\)

\(\newcommand {\umol }{\micro \mol }\)

\(\newcommand {\mmol }{\milli \mol }\)

\(\newcommand {\mol }{\mol }\)

\(\newcommand {\kmol }{\kilo \mol }\)

\(\newcommand {\pA }{\pico \ampere }\)

\(\newcommand {\nA }{\nano \ampere }\)

\(\newcommand {\uA }{\micro \ampere }\)

\(\newcommand {\mA }{\milli \ampere }\)

\(\newcommand {\A }{\ampere }\)

\(\newcommand {\kA }{\kilo \ampere }\)

\(\newcommand {\ul }{\micro \litre }\)

\(\newcommand {\ml }{\milli \litre }\)

\(\newcommand {\l }{\litre }\)

\(\newcommand {\hl }{\hecto \litre }\)

\(\newcommand {\uL }{\micro \liter }\)

\(\newcommand {\mL }{\milli \liter }\)

\(\newcommand {\L }{\liter }\)

\(\newcommand {\hL }{\hecto \liter }\)

\(\newcommand {\mHz }{\milli \hertz }\)

\(\newcommand {\Hz }{\hertz }\)

\(\newcommand {\kHz }{\kilo \hertz }\)

\(\newcommand {\MHz }{\mega \hertz }\)

\(\newcommand {\GHz }{\giga \hertz }\)

\(\newcommand {\THz }{\tera \hertz }\)

\(\newcommand {\mN }{\milli \newton }\)

\(\newcommand {\N }{\newton }\)

\(\newcommand {\kN }{\kilo \newton }\)

\(\newcommand {\MN }{\mega \newton }\)

\(\newcommand {\Pa }{\pascal }\)

\(\newcommand {\kPa }{\kilo \pascal }\)

\(\newcommand {\MPa }{\mega \pascal }\)

\(\newcommand {\GPa }{\giga \pascal }\)

\(\newcommand {\mohm }{\milli \ohm }\)

\(\newcommand {\kohm }{\kilo \ohm }\)

\(\newcommand {\Mohm }{\mega \ohm }\)

\(\newcommand {\pV }{\pico \volt }\)

\(\newcommand {\nV }{\nano \volt }\)

\(\newcommand {\uV }{\micro \volt }\)

\(\newcommand {\mV }{\milli \volt }\)

\(\newcommand {\V }{\volt }\)

\(\newcommand {\kV }{\kilo \volt }\)

\(\newcommand {\W }{\watt }\)

\(\newcommand {\uW }{\micro \watt }\)

\(\newcommand {\mW }{\milli \watt }\)

\(\newcommand {\kW }{\kilo \watt }\)

\(\newcommand {\MW }{\mega \watt }\)

\(\newcommand {\GW }{\giga \watt }\)

\(\newcommand {\J }{\joule }\)

\(\newcommand {\uJ }{\micro \joule }\)

\(\newcommand {\mJ }{\milli \joule }\)

\(\newcommand {\kJ }{\kilo \joule }\)

\(\newcommand {\eV }{\electronvolt }\)

\(\newcommand {\meV }{\milli \electronvolt }\)

\(\newcommand {\keV }{\kilo \electronvolt }\)

\(\newcommand {\MeV }{\mega \electronvolt }\)

\(\newcommand {\GeV }{\giga \electronvolt }\)

\(\newcommand {\TeV }{\tera \electronvolt }\)

\(\newcommand {\kWh }{\kilo \watt \hour }\)

\(\newcommand {\F }{\farad }\)

\(\newcommand {\fF }{\femto \farad }\)

\(\newcommand {\pF }{\pico \farad }\)

\(\newcommand {\K }{\mathrm {K}}\)

\(\newcommand {\dB }{\mathrm {dB}}\)

\(\newcommand {\kibi }{\mathrm {Ki}}\)

\(\newcommand {\mebi }{\mathrm {Mi}}\)

\(\newcommand {\gibi }{\mathrm {Gi}}\)

\(\newcommand {\tebi }{\mathrm {Ti}}\)

\(\newcommand {\pebi }{\mathrm {Pi}}\)

\(\newcommand {\exbi }{\mathrm {Ei}}\)

\(\newcommand {\zebi }{\mathrm {Zi}}\)

\(\newcommand {\yobi }{\mathrm {Yi}}\)

\(\require {mhchem}\)

\(\require {cancel}\)

\(\newcommand {\fint }{âĺŊ}\)

\(\newcommand {\hdots }{\cdots }\)

\(\newcommand {\mathnormal }[1]{#1}\)

\(\newcommand {\vecs }[2]{\vec {#1}_{#2}}\)

\(\renewcommand {\A }{\mathcal {A}}\)

\(\newcommand {\B }{\mathcal {B}}\)

\(\renewcommand {\C }{\mathcal {C}}\)

\(\newcommand {\EE }{\mathbb {E}}\)

\(\renewcommand {\N }{\mathcal {N}}\)

\(\renewcommand {\P }{\mathcal {P}}\)

\(\newcommand {\PP }{\mathbb {P}}\)

\(\newcommand {\T }{\mathcal {T}}\)

\(\renewcommand {\U }{\mathcal {U}}\)

\(\newcommand {\X }{\mathcal {X}}\)

\(\newcommand {\Y }{\mathcal {Y}}\)

\(\newcommand {\Bin }{\operatorname {Bin}}\)

\(\newcommand {\Pois }{\operatorname {Pois}}\)

\(\newcommand {\Exp }{\operatorname {Exp}}\)

\(\newcommand {\BetaV }{\operatorname {Beta}}\)

\(\newcommand {\GammaV }{\operatorname {Gamma}}\)

\(\newcommand {\pot }{\mathfrak {P}}\)

\(\renewcommand {\1}{𝟙}\)

\(\newcommand {\id }{\mathrm {id}}\)

\(\renewcommand {\i }{\mathrm {i}}\)

\(\renewcommand {\theta }{\vartheta }\)

\(\newcommand {\Tu }{\underline {T}}\)

\(\newcommand {\To }{\overline {T}}\)

\(\newcommand {\Var }{\mathrm {Var}}\)

\(\newcommand {\Cov }{\mathrm {Cov}}\)

\(\newcommand {\name }[1]{\textsc {#1}}\)

\(\newcommand {\smallpmatrix }[1]{\left (\begin {smallmatrix}#1\end {smallmatrix}\right )}\)

\(\newcommand {\matlab }{{\fontfamily {bch}\scshape \selectfont {}Matlab}}\)

\(\newcommand {\innerproduct }[1]{\left \langle {#1}\right \rangle }\)

\(\newcommand {\norm }[1]{\left \Vert {#1}\right \Vert }\)

\(\renewcommand {\natural }{\mathbb {N}}\)

\(\newcommand {\integer }{\mathbb {Z}}\)

\(\newcommand {\rational }{\mathbb {Q}}\)

\(\newcommand {\real }{\mathbb {R}}\)

\(\newcommand {\complex }{\mathbb {C}}\)

\(\renewcommand {\d }{\mathop {}\!\mathrm {d}}\)

\(\newcommand {\dr }{\d {}r}\)

\(\newcommand {\ds }{\d {}s}\)

\(\newcommand {\dt }{\d {}t}\)

\(\newcommand {\du }{\d {}u}\)

\(\newcommand {\dv }{\d {}v}\)

\(\newcommand {\dw }{\d {}w}\)

\(\newcommand {\dx }{\d {}x}\)

\(\newcommand {\dy }{\d {}y}\)

\(\newcommand {\dz }{\d {}z}\)

\(\newcommand {\dsigma }{\d {}\sigma }\)

\(\newcommand {\dphi }{\d {}\phi }\)

\(\newcommand {\dvarphi }{\d {}\varphi }\)

\(\newcommand {\dtau }{\d {}\tau }\)

\(\newcommand {\dxi }{\d {}\xi }\)

\(\newcommand {\dtheta }{\d {}\theta }\)

\(\newcommand {\tp }{\mathrm {T}}\)

</div>

<style type="text/css">
.lwarp-contents li.list-item-f0::marker {
  content:'•\00a0\00a0';
}
.lwarp-contents li.list-item-f1::marker {
  content:'•\00a0\00a0';
}
.lwarp-contents li.list-item-f2::marker {
  content:'•\00a0\00a0';
}
.lwarp-contents li.list-item-f3::marker {
  content:'1.\00a0\00a0';
}
.lwarp-contents li.list-item-f4::marker {
  content:'2.\00a0\00a0';
}
.lwarp-contents li.list-item-f5::marker {
  content:'3.\00a0\00a0';
}
.lwarp-contents li.list-item-f6::marker {
  content:'1.\00a0\00a0';
}
.lwarp-contents li.list-item-f7::marker {
  content:'2.\00a0\00a0';
}
.lwarp-contents li.list-item-f8::marker {
  content:'1.\00a0\00a0';
}
.lwarp-contents li.list-item-f9::marker {
  content:'2.\00a0\00a0';
}
.lwarp-contents li.list-item-f10::marker {
  content:'3.\00a0\00a0';
}
.lwarp-contents li.list-item-f11::marker {
  content:'4.\00a0\00a0';
}
</style>
<p>

</p>


<p>
<em>Bemerkung</em>: Man sucht nach optimalen Tests basierend auf Likelihood-Quotienten fu&#x0308;r
</p>
<ul style="list-style-type:none">

<li class="list-item-f0"><p>einfache Hypothesen \(H_0\colon \theta = \theta _0\) vs. \(H_1\colon \theta = \theta _1\),
</p>
</li>
<li class="list-item-f1"><p>fu&#x0308;r einseitige (zusammengesetzte) Hypothesen, z.&#x202f;B. \(H_0\colon \theta \le \theta _0\) vs. \(H_1\colon \theta &gt; \theta _0\), und
</p>
</li>
<li class="list-item-f2"><p>fu&#x0308;r zweiseitige Hypothesen \(H_0\colon \theta = \theta _0\) vs. \(H_1\colon \theta \not = \theta _0\), wobei in diesem Fall die Klasse der betrachteten Tests eingeschra&#x0308;nkt wird.
</p>
</li>
</ul>



<h2 id="das-neyman-pearson-lemma">Das <span style="font-variant: small-caps;">Neyman</span>-<span style="font-variant: small-caps;">Pearson</span>-Lemma</h2>

</p>


<p>
<b>UMP-Test</b>:&#x2003; Ein Test \(\delta ^\ast \) zum Niveau \(\alpha \in [0, 1]\) heißt <em><span class="dashuline" >gleichma&#x0308;ßig bester Test (uniformly most powerful test, UMP-Test)</span></em>,
fu&#x0308;r das Testproblem \(H_0\colon \theta \in \Theta _0\) vs. \(H_1\colon \theta \in \Theta _1\), falls fu&#x0308;r jeden weiteren Test \(\delta \) zum selben Niveau \(\alpha \) gilt, dass \(\forall _{\theta
\in \Theta _1}\; G_\delta (\theta ) \le G_{\delta ^\ast }(\theta )\).
</p>

<p>
<em>Bemerkung</em>: Da \(G_\delta (\theta )\) fu&#x0308;r \(\theta \in \Theta _1\) gleich \(1\) minus der Fehlerwahrscheinlichkeit 2. Art entspricht, sind UMP-Tests charakterisiert durch Minimierung der
Fehlerwahrscheinlichkeit 2. Art unter allen Tests zum Niveau \(\alpha \).
</p>

<p>
<b>Likelihood-Quotienten-Statistik</b>:&#x2003;<br />
Sei \(p\) Za&#x0308;hl- oder L.-B.-Dichte von \(X\), wobei \(X\) Werte in \(\real ^n\) annehme.<br />
Dann heißt \(L(x, \theta _0, \theta _1) := \frac {p(x, \theta _1)}{p(x, \theta _0)}\) <em><span class="dashuline" >Likelihood-Quotienten-Statistik</span></em> zur Beobachtung \(x\).<br />
Man definiert \(L(x, \theta _0, \theta _1) := 0\) fu&#x0308;r \(p(x, \theta _1) = p(x, \theta _0) = 0\) und \(L(x, \theta _0, \theta _1) := \infty \) fu&#x0308;r \(p(x, \theta _1) &gt; 0\) und \(p(x,
\theta _0) = 0\).
</p>

<p>
<em>Bemerkung</em>: Große Werte von \(L\) sprechen eher fu&#x0308;r \(\theta _1\), kleine eher fu&#x0308;r \(\theta _0\).
</p>

<p>
<span class="uline" ><em>Satz</em> (<span class="textsl" ><span class="textsc" >Neyman</span>-<span class="textsc" >Pearson</span>-Lemma</span>):</span><br />
Seien \((\X , \A , \P )\) ein statistischer Raum mit einem regula&#x0308;ren statistischen Modell<br />
\(\P = \{p(\cdot , \theta ) \;|\; \theta \in \Theta \}\) und \(\Theta = \{\theta _0, \theta _1\}\) mit Testproblem \(H_0\colon \theta = \theta _0\) vs. \(H_1\colon \theta = \theta _1\).<br />
Dann gibt es fu&#x0308;r alle \(\alpha \in [0, 1]\) Zahlen \(k \in [0, \infty ]\) und \(\gamma \in [0, 1]\), sodass \(\delta \colon \X \rightarrow [0, 1]\) ein UMP-Test zum Niveau \(\alpha \) ist, wobei
\(\delta \) definiert ist durch \(\delta (x) := \begin {cases}0 &amp; L(x, \theta _0, \theta _1) &lt; k,\\ \gamma &amp; L(x, \theta _0, \theta _1) = k,\\1 &amp; L(x, \theta _0, \theta _1) &gt;
k.\end {cases}\)
</p>

<p>
<em>Bemerkung</em>: Im Beweis betrachtet man die Verteilungsfunktion \(g\) von \(Y\colon \X \rightarrow [0, \infty )\) mit \(Y(x) := L(x, \theta _0, \theta _1)\) fu&#x0308;r \(p(x, \theta _0) &gt; 0\) und
\(Y(x) := 0\) sonst. Fu&#x0308;r den Fall, dass es ein \(\overline {k} \in [0, \infty )\) gibt mit \(g(\overline {k}) = 1 - \alpha \), wa&#x0308;hlt man \(k := \overline {k}\) und \(\gamma := 0\). Sonst (falls
es kein solches \(\overline {k}\) gibt) gibt es ein \(\overline {k}\), sodass \(\lim _{k \to \overline {k}-0} g(k) \le 1 - \alpha &lt; \lim _{k \to \overline {k}+0} g(k)\). In diesem Fall wa&#x0308;hlt man
\(k := \overline {k}\) und \(\gamma \in [0, 1]\), sodass \(P_{\theta _0}(\{x \;|\; Y(x) \le \overline {k}\}) - \gamma P_{\theta _0}(\{x \;|\; Y(x) = \overline {k}\}) = 1 - \alpha \).
</p>

<p>
Die Randomisierung bewirkt, dass das vorgegebene Niveau \(\alpha \) voll ausgescho&#x0308;pft wird, d.&#x202f;h. \(\EE _{\theta _0}(\delta (X)) = \alpha \). Dies hat aber auch zur Folge, dass die
Gu&#x0308;tefunktion fu&#x0308;r \(\theta = \theta _1\) gro&#x0308;ßer (oder gleich) und damit die Fehlerwahrscheinlichkeit 2. Art kleiner (oder gleich) wird im Vergleich zum nicht-randomisierten Test.
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<em>Beispiel</em>: Es wird ein nicht-randomisierter Test zum Niveau \(\alpha = 0.05\) gesucht fu&#x0308;r \(H_0\colon \theta = \theta _0\) vs. \(H_1\colon \theta = \theta _1\), wobei \(X \sim \Bin (20, \theta
)\) und \(n := 20\) mit \(\theta \in \{0.2, 0.8\}\) und \(\theta _0 = 0.2\), \(\theta _1 = 0.8\).<br />
Der Test ist definiert durch \(\delta _{\text {nr}}(x) := \1_{\{p(x, 0.8)/p(x, 0.2) \ge k\}}\). Dabei ist<br />
\(\frac {p(x, 0.8)}{p(x, 0.2)} = \frac {\binom {n}{x} 0.8^x 0.2^{n-x}}{\binom {n}{x} 0.2^x 0.8^{n-x}} = 4^x (1/4)^{n-x} = 4^{2x} 4^{-n}\) monoton in \(x\), d.&#x202f;h. \(\frac {p(x, 0.8)}{p(x,
0.2)} \ge k \iff x \ge k’\).<br />
Wegen \(\PP _{0.2}(X \le 6) \approx 0.913\) und \(\PP _{0.2}(X \le 7) \approx 0.968\) wird \(H_0\colon \theta = 0.2\) abgelehnt, falls \(x &gt; 7\), denn dann ist \(\PP (H_0 \text { abl.} | H_0 \text {
wahr}) = \PP _{0.2}(X &gt; 7) = 1 - 0.968 = 0.032 &lt; \alpha \). Außerdem gilt \(\PP (H_0 \text { abl.} | H_1 \text { wahr}) = \PP _{0.8}(X &gt; 7) = 1 - \PP _{0.8}(X \le 7) = 1 - 1.5 \cdot
10^{-5}\), d.&#x202f;h. die Fehlerwahrscheinlichkeit 2. Art ist sehr klein.
</p>

<p>
Nun betrachtet man den randomisierten Test \(\delta _{\text {r}}(x) := 0\) fu&#x0308;r \(\frac {p(x, 0.8)}{p(x, 0.2)} &lt; k\), \(\delta _{\text {r}}(x) := \gamma \) fu&#x0308;r \(\frac {p(x, 0.8)}{p(x,
0.2)} = k\) und \(\delta _{\text {r}}(x) := 1\) fu&#x0308;r \(\frac {p(x, 0.8)}{p(x, 0.2)} &gt; k\). Dies entspricht den Fa&#x0308;llen \(x &lt; 7\), \(x = 7\) und \(x &gt; 7\) (sonst kein Test zum Niveau
\(\alpha \)). Nach dem Beweis des Satzes muss \(\gamma \in [0, 1]\) so gewa&#x0308;hlt werden, dass \(\PP _{0.2}(X &gt; 7) + \gamma \PP _{0.2}(X = 7) = \alpha = 0.05\), also \(\gamma = \frac {\alpha - \PP
_{0.2}(X &gt; 7)}{\PP _{0.2}(X = 7)} \approx 0.327\). Damit ergibt sich \(\PP (H_0 \text { abl.} | H_1 \text { wahr}) = \EE _{0.8}(\delta _{\text {r}}) = \gamma \cdot \PP _{0.8}(X = 7) + 1 \cdot
\PP _{0.8}(X &gt; 7) \approx 0.99999\). Damit gilt fu&#x0308;r die beiden zu \(\delta _{\text {nr}}\) und \(\delta _{\text {r}}\) zugeho&#x0308;rigen Gu&#x0308;tefunktionen, dass \(G_{\delta _{\text
{nr}}}(\theta ) &lt; G_{\delta _{\text {r}}}(\theta )\) fu&#x0308;r \(\theta = \theta _0, \theta _1\). Also ist \(\delta _{\text {r}}\) ein besserer Test zum Niveau \(\alpha = 0.05\) als \(\delta _{\text
{nr}}\) (sogar optimal zum Niveau \(\alpha = 0.05\) nach dem Neyman-Pearson-Lemma).
</p>



<h2 id="optimale-einseitige-tests">Optimale einseitige Tests</h2>

</p>


<p>
<b>monotoner Dichtequotient</b>:&#x2003; Sei \(\P = \{p(\cdot , \theta ) \;|\; \theta \in \Theta \}\) ein regula&#x0308;res, einparametriges statistisches Modell (d.&#x202f;h. \(\Theta \subset \real \)).
Dann besitzt \(\P \) einen <em><span class="dashuline" >monotonen Dichtequotienten</span></em> bzgl. der Statistik \(T\), falls es fu&#x0308;r alle \(\theta _1, \theta _2 \in \Theta \) mit \(\theta _1 &lt; \theta
_2\) eine streng monoton wachsende Funktion \(q_{\theta _1,\theta _2}\colon \real \rightarrow [0, \infty ]\) gibt mit \(q_{\theta _1,\theta _2}(T(x)) = \frac {p(x, \theta _2)}{p(x, \theta _1)}\)
fu&#x0308;r alle \(x \in \X \).
</p>

<p>
<em>Beispiel</em>: Einparametrige Exp.familien mit Dichte \(p(x, \theta ) = \1_A(x) \cdot \exp (c(\theta )T(x) + d(\theta ) + S(x))\) besitzen einen monotonen Dichtequotienten bzgl. der Statistik \(T\), wenn
\(c\colon \Theta \rightarrow \real \) streng monoton wachsend ist, da \(q_{\theta _1,\theta _2}(T(x)) := \exp ((c(\theta _2) - c(\theta _1)) T(x) + d(\theta _2) - d(\theta _1))\) in \(T(x)\) streng
monoton wachsend ist (fu&#x0308;r \(\theta _1 &lt; \theta _2\)).
</p>

<p>
<span class="uline" ><em>Satz</em> (<span class="textsl" >UMP-Tests bei rechtsseitigen Hypothesen</span>):</span> \(\P = \{p(\cdot , \theta ) \;|\; \theta \in \Theta \}\) (\(\Theta \subset \real \))
besitze einen monotonen Dichtequotienten bzgl. der Statistik \(T\) und \(H_0\colon \theta \le \theta _0\) vs. \(H_1\colon \theta &gt; \theta _0\).<br />
Dann gibt es fu&#x0308;r alle \(\alpha \in (0, 1)\) Zahlen \(c \in \real \) und \(\gamma \in [0, 1]\), sodass \(\delta \colon \X \rightarrow [0, 1]\) ein UMP-Test zum Niveau \(\alpha \) ist, wobei \(\delta \)
definiert ist durch \(\delta (x) := \begin {cases}0 &amp; T(x) &lt; c,\\ \gamma &amp; T(x) = c,\\1 &amp; T(x) &gt; c.\end {cases}\)
</p>

<p>
<em>Bemerkung</em>: \(\delta \) ist sogar ein Level-\(\alpha \)-Test.<br />
\(\gamma \) und \(c\) ergeben sich genauso wie beim Beweis vom Neyman-Pearson-Lemma, wenn man \(Y(x)\) durch \(T(x)\) ersetzt. Der im Satz definierte Test \(\delta      \) ist ein UMP-Test fu&#x0308;r jedes \(c \in \real
\) und \(\gamma \in [0, 1]\), sodass \(\PP _{\theta _0}(T(X) \le c) - \gamma \PP _{\theta _0}(T(X) = c) = 1 - \alpha \). Im Fall \(\PP _{\theta _0}(T(X)                 = c) = 0\) ist jedes \(\gamma \) erlaubt und \(c\) ist
dann das \((1 - \alpha )\)-Quantil der Verteilung von \(T(X)\) unter \(\theta = \theta _0\).<br />
Ist \(H_0\colon \theta \ge \theta _0\) vs \(H_1\colon \theta &lt; \theta _0\) zu testen, so gibt es unter den Voraussetzungen des Satzes von eben fu&#x0308;r alle       \(\alpha \in (0, 1)\) Zahlen \(c \in \real \) und
\(\gamma \in [0, 1]\), sodass \(\delta \colon \X \rightarrow [0, 1]\) ein UMP-Test zum Niveau \(\alpha \) ist, wobei \(\delta \) definiert ist durch \(\delta (x)        := \begin {cases}0 &amp; T(x) &gt; c,\\ \gamma
&amp; T(x) = c,\\1 &amp; T(x) &lt; c.\end {cases}\)
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<em>Beispiel</em>: Seien \(X_1, \dotsc , X_n \sim \N (\mu , \sigma ^2)\) i.i.d. mit \(\mu \) unbekannt und \(\sigma ^2\) bekannt, wobei \(X = (X_1, \dotsc , X_n)\). Zu testen ist \(H_0\colon \mu \le \mu _0\) vs.
\(H_1\colon \mu &gt; \mu _0\). Fu&#x0308;r die Dichte \(p(\cdot , \mu )\) von \(X\) gilt<br />
\(\ln p(x, \mu ) = -\frac {1}{2\sigma ^2} \sum _{i=1}^n (x_i - \mu )^2 - \frac {n}{2} \ln (2\pi \sigma ^2) = c(\mu ) T(x) - \frac {n}{2} \left (\frac {\mu ^2}{\sigma ^2} + \ln (2\pi \sigma
^2)\right ) - \frac {n\overline {x}}{2\sigma ^2}\)<br />
mit \(T(x) := \frac {\overline {x}}{\sigma /\sqrt {n}}\) und \(c(\mu ) := \frac {\mu }{\sigma /\sqrt {n}}\). Also geho&#x0308;rt die Verteilung von \(X\) zu einer \(1\)-parametrigen Exponentialfamilie.
\(c\colon \real \rightarrow \real \) ist streng monoton wachsend, d.&#x202f;h. \(\P \) besitzt nach obiger Bemerkung einen monotonen Dichtequotienten bzgl. \(T\).
</p>

<p>
Wegen \(\PP _\mu (T(X) = c) = 0\) fu&#x0308;r alle \(c \in \real \) kann \(\gamma \) beliebig gewa&#x0308;hlt werden, z.&#x202f;B. \(\gamma = 1\). Der nicht-randomisierte Test \(\delta (x) := \1_{\{T(X) \ge
c\}}\) aus dem Satz hat die Gu&#x0308;tefunktion<br />
\(G_\delta (\mu ) = \EE _\mu (\delta (X)) = \PP _\mu (\delta (X) = 1) = \PP _\mu \!\left (\frac {\overline {X}}{\sigma /\sqrt {n}} \ge c\right ) = \PP _\mu \!\left (\frac {\overline {X} - \mu
}{\sigma /\sqrt {n}} \ge c - \frac {\mu }{\sigma /\sqrt {n}}\right )\)<br />
\(= 1 - \Phi \!\left (c - \frac {\mu }{\sigma /\sqrt {n}}\right )\). Fu&#x0308;r einen Level-\(\alpha \)-Test muss<br />
\(\sup _{\mu \le \mu _0} G_\delta (\mu ) = \sup _{\mu \le \mu _0} \left [1 - \Phi \!\left (c - \frac {\mu }{\sigma /\sqrt {n}}\right )\right ] \overset {!}{=} \alpha \) gelten. Der Ausdruck in
eckigen Klammern ist monoton wachsend in \(\mu \), daher ist dies a&#x0308;quivalent zu<br />
\(1 - \Phi \!\left (c - \frac {\mu _0}{\sigma /\sqrt {n}}\right ) = \alpha \iff \Phi \!\left (c - \frac {\mu _0}{\sigma /\sqrt {n}}\right ) = 1 - \alpha \iff c = z_{1-\alpha } + \frac {\mu
_0}{\sigma /\sqrt {n}}\).
</p>

<p>
Nach dem Satz ist daher \(\delta (X) = \1_{\left \{\frac {\overline {X} - \mu _0} {\sigma /\sqrt {n}} \,\ge \, z_{1-\alpha }\right \}}\) ein UMP-Test fu&#x0308;r \(H_0\colon \mu \le \mu _0\) vs.
\(H_1\colon \mu &gt; \mu _0\) (einseitiger Gauß-Test).
</p>



<h2 id="optimale-zweiseitige-tests">Optimale zweiseitige Tests</h2>

</p>


<p>
<em>Bemerkung</em>: Im Folgenden werden verschiedene Arten von zweiseitigen Hypothesen betrachtet:
</p>
<ul style="list-style-type:none">

<li class="list-item-f3"><p>\(H_0\colon \theta = \theta _0\) vs. \(H_1\colon \theta \not = \theta _0\)
</p>
</li>
<li class="list-item-f4"><p>\(H_0\colon \theta \in [\theta _1, \theta _2]\) vs. \(H_1\colon \theta \notin [\theta _1, \theta _2]\)
</p>
</li>
<li class="list-item-f5"><p>\(H_0\colon \theta \notin (\theta _1, \theta _2)\) vs. \(H_1\colon \theta \in (\theta _1, \theta _2)\)
</p>
</li>
</ul>

<p>
UMP-Tests zu diesen Hypothesen existieren nur unter speziellen Bedingungen.
</p>

<p>
<em>Beispiel</em>: Seien wieder \(X_1, \dotsc , X_n \sim \N (\mu , \sigma ^2)\) i.i.d. mit \(\mu \) unbekannt und \(\sigma ^2\) bekannt. Das Testproblem sei \(H_0\colon \mu = \mu _0\) vs. \(H_1\colon \mu \not =
\mu _0\).<br />
Dann ist der zweiseitige Gauß-Test \(\delta (X) := \1_{\{|T(X)| \ge z_{1-\alpha /2}\}}\) zum Niveau \(\alpha \) mit \(T(X) := \frac {\overline {X} - \mu _0}{\sigma /\sqrt {n}}\) kein UMP-Test fu&#x0308;r
dieses Testproblem, da die Gu&#x0308;tefunktion des Neyman-Pearson-Tests fu&#x0308;r \(H_0\colon \mu = \mu _0\) vs. \(H_1\colon \mu = \mu _1\) fu&#x0308;r ein beliebiges (aber festes) \(\mu _1 &gt; \mu _0\)
fu&#x0308;r \(\mu = \mu _1\) gro&#x0308;ßer ist.<br />
Alternativ kann man auch argumentieren, dass die Gu&#x0308;tefunktion des einseitigen Gauß-Tests fu&#x0308;r \(H_0\colon \mu \le \mu _0\) vs. \(H_1\colon \mu &gt; \mu _0\) fu&#x0308;r alle \(\mu &gt; \mu _0\)
besser ist als die des zweiseitigen Gauß-Tests. Jedoch ist der einseitige Gauß-Test zum zweiseitigen Testproblem ein verfa&#x0308;lschter Test, da fu&#x0308;r \(\mu &lt; \mu _0\) (Spezialfall der Alternativhypothese) die
Wahrscheinlichkeit \(H_0\) abzulehnen kleiner ist als die Wahrscheinlichkeit \(H_0\) abzulehnen, wenn \(H_0\) wahr ist (also die Fehlerw.keit 1. Art).
</p>

<p>
<b>unverfa&#x0308;lscht</b>:&#x2003;<br />
Ein statistischer Hypothesentest \(\delta \) zum Niveau \(\alpha \) heißt <em><span class="dashuline" >unverfa&#x0308;lscht</span></em>, falls \(\forall _{\theta \in \Theta _1}\; G_\delta (\theta ) \ge
\alpha \).
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<em>Bemerkung</em>: Fu&#x0308;r spezielle \(1\)-parametrige Exponentialfamilien mit monotonem Dichtequotienten ko&#x0308;nnen unter gewissen weiteren Regularita&#x0308;tsvoraussetzungen gleichma&#x0308;ßig beste
Tests (unter allen unverfa&#x0308;lschten Tests) konstruiert werden.
</p>

<p>
Diese hier angesprochenen Tests erha&#x0308;lt man auch als Kombination zweier einseitiger Tests. Im Folgenden seien die Annahmen des Satzes zu optimalen einseitigen Tests erfu&#x0308;llt.
</p>
<ul style="list-style-type:none">

<li class="list-item-f6"><p>Bestimme die Konstanten \(\gamma _r\) und \(c_r\) zum rechtsseitigen Testproblem<br />
\(H_0\colon \theta \le \theta _0\) vs. \(H_1\colon \theta &gt; \theta _0\).
</p>
</li>
<li class="list-item-f7"><p>Bestimme die Konstanten \(\gamma _\ell \) und \(c_\ell \) zum linksseitigen Testproblem<br />
\(H_0\colon \theta \ge \theta _0\) vs. \(H_1\colon \theta &lt; \theta _0\).
</p>
</li>
</ul>

<p>
Dadurch erha&#x0308;lt man zwei UMP-Tests \(\delta _\ell (x) := \begin {cases}0 &amp; T(x) &gt; c_\ell ,\\ \gamma _\ell &amp; T(x) = c_\ell ,\\1 &amp; T(x) &lt; c_\ell ,\end {cases}\) und \(\delta
_r(x) := \begin {cases}0 &amp; T(x) &lt; c_r,\\ \gamma _r &amp; T(x) = c_r,\\1 &amp; T(x) &gt; c_r,\end {cases}\)<br />
Falls \(\alpha &lt; 1\) ist, so gilt stets \(c_\ell \le c_r\). Fu&#x0308;r \(c_\ell &lt; c_r\) ko&#x0308;nnen \(\delta _\ell \) und \(\delta _r\) zu einem einzigen Test kombiniert werden: \(\delta (x) := \begin
{cases}0 &amp; T(x) \in (c_\ell , c_r),\\ \gamma _\ell &amp; T(x) = c_\ell ,\\\gamma _r &amp; T(x) = c_r,\\ 1 &amp; T(x) \notin [c_\ell , c_r].\end {cases}\)<br />
Man kann zeigen, dass dies ein UMP-Test unter allen unverfa&#x0308;lschten Tests zum Niveau \(\alpha \) fu&#x0308;r das zweiseitige Testproblem \(H_0\colon \theta = \theta _0\) vs. \(H_1\colon \theta \not = \theta
_0\) ist.
</p>



<h2 id="likelihood-quotienten-tests">Likelihood-Quotienten-Tests</h2>

</p>


<p>
<em>Bemerkung</em>: Das Ziel ist die Verallgemeinerung der Neyman-Pearson-Teststatistik \(L(x, \theta _0, \theta _1)\) fu&#x0308;r das Testproblem \(H_0\colon \theta = \theta _0\) vs. \(H_1\colon \theta =
\theta _1\) auf allgemeine Testprobleme der Form<br />
\(H_0\colon \theta \in \Theta _0\) vs. \(H_1\colon \theta \in \Theta _1\).
</p>

<p>
<b>verallgemeinerte Likelihood-Quotienten-Statistik</b>:&#x2003;<br />
Sei \(\P = \{p(\cdot , \theta ) \;|\; \theta \in \Theta \}\) ein regula&#x0308;res statistisches Modell.<br />
Dann heißt \(L(X) := \frac {\sup _{\theta \in \Theta _1} p(X, \theta )} {\sup _{\theta \in \Theta _0} p(X, \theta )}\) <em><span class="dashuline" >verallgemeinerte
Likelihood-Quotienten-Statistik</span></em>.
</p>

<p>
<b>verallgemeinerter Likelihood-Quotienten-Test</b>:&#x2003; Der Hypothesentest \(\delta (X) := \1_{\{L(X) \ge c\}}\)<br />
heißt <em><span class="dashuline" >verallgemeinerter Likelihood-Quotienten-Test</span></em> zu einem kritischen Wert \(c \in [0, \infty ]\).
</p>

<p>
<em>Bemerkung</em>: Der Za&#x0308;hler der verallg. L.-Q.-Statistik ist ha&#x0308;ufig schwer zu berechnen. Daher geht man in der Praxis ha&#x0308;ufig wie folgt vor:
</p>
<ul style="list-style-type:none">

<li class="list-item-f8"><p>Berechne den MLS \(\widehat {\theta }\) von \(\theta \in \Theta \).
</p>
</li>
<li class="list-item-f9"><p>Berechne den MLS \(\widehat {\theta }_0\) von \(\theta \in \Theta _0\).
</p>
</li>
<li class="list-item-f10"><p>Berechne \(\lambda (x) := \frac {p(x, \widehat {\theta })}{p(x, \widehat {\theta }_0)} = \frac {\sup _{\theta \in \Theta } p(x, \theta )}{\sup _{\theta \in \Theta _0} p(x, \theta )}\) (leichter
zu berechnender Za&#x0308;hler).
</p>
</li>
<li class="list-item-f11"><p>Finde eine strikt monotone Funktion \(h\) auf dem Bild von \(\lambda \), sodass die Verteilung von \(h(\lambda (X))\) unter \(H_0\) bekannt ist.
</p>
</li>
</ul>

<p>
Dadurch erha&#x0308;lt man einen verallg. L.-Q.-Test der Form \(\delta (X) := \1_{\{h(\lambda (X)) \ge h_{1-\alpha }\}}\) mit \(h_{1-\alpha }\) dem \((1-\alpha )\)-Quantil der Verteilung von \(h(\lambda (X))\)
unter \(H_0\). Der Zusammenhang zwischen \(\lambda \) und \(L\) wird durch \(\lambda (x) = \frac {\max \{\sup _{\theta \in \Theta _1} p(x, \theta ),\; \sup _{\theta \in \Theta _0} p(x, \theta
)\}}{\sup _{\theta \in \Theta _0} p(x, \theta )} = \max \{L(x), 1\}\) ersichtlich. Wenn \(\lambda (x)\) bzw. \(L(x)\) „deutlich“ gro&#x0308;ßer als \(1\) ist, so spricht dies eher gegen \(H_0\).
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<em>Bemerkung</em>: Basierend auf der Dualita&#x0308;t zwischen Hypothesentests und Konfidenzintervallen lassen sich Konfidenzbereiche fu&#x0308;r den unbekannten Parameter \(\theta \in \Theta \subset \real ^d\)
konstruieren.<br />
Man betrachtet dazu das Testproblem \(H_0\colon \theta = \theta _0\) vs. \(H_1\colon \theta \not = \theta _0\). Bestimme \(c(\theta _0)\) durch \(\alpha = \PP _{\theta _0}\!\left (\frac {\sup _{\theta
\in \Theta } p(X, \theta )}{p(X, \theta _0)} \ge c(\theta _0)\right ) = \PP _{\theta _0}(\lambda (X) \ge c(\theta _0))\).<br />
Falls der Annahmebereich \(C(x) := \left \{\theta \in \Theta \;|\; p(x, \theta ) &gt; \frac {\sup _{\theta \in \Theta } p(x, \theta )}{c(\theta _0)}\right \}\) des verallg. L.-Q.-Tests<br />
\(\delta (X) := \1_{\{\lambda (X) \ge c(\theta _0)\}}\) in der Form \([\underline {C}_1(x), \overline {C}_1(x)] \times \dotsb \times [\underline {C}_d(x), \overline {C}_d(x)]\) geschrieben werden
kann, so ist \(C(x)\) ein \((1-\alpha )\)-Konfidenzbereich fu&#x0308;r den unbekannten Parameter \(\theta \in \Theta \).
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<em>Beispiel</em>: Seien \(X_1, \dotsc , X_n \sim \N (\mu , \sigma ^2)\) i.i.d. mit \(\theta = (\mu , \sigma ^2) \in \Theta := \real \times \real ^+\) unbekannt. Das zu testende Hypothesenpaar lautet
\(H_0\colon \mu = \mu _0\) vs. \(H_1\colon \mu \not = \mu _0\), also \(\Theta _0 := \{(\mu _0, \sigma ^2) \;|\; \sigma ^2 \in \real ^+\}\) und \(\Theta _1 := \Theta \setminus \Theta _0\). Die Dichte
von \(X := (X_1, \dotsc , X_n)\) ist gleich<br />
\(p(x, \theta ) = \prod _{i=1}^n \frac {1}{\sqrt {2\pi \sigma ^2}} \exp \!\left (-\frac {(x_i - \mu )^2}{2\sigma ^2}\right ) = \frac {1}{(2\pi \sigma ^2)^{n/2}} \exp \!\left (-\frac
{1}{2\sigma ^2} \sum _{i=1}^n (x_i - \mu )^2\right )\).<br />
Man berechnet nun den MLS \(\widehat {\theta } := (\overline {X}, \widehat {\sigma }^2)\) fu&#x0308;r \(\theta \in \Theta \), wobei \(\widehat {\sigma }^2 := \frac {n-1}{n} S^2(X)\) die unkorrigierte
Stichprobenvarianz ist. Fu&#x0308;r \(\mu = \mu _0\) ergibt sich als MLS fu&#x0308;r \(\sigma ^2\) der Scha&#x0308;tzer \(\widehat {\sigma }_0^2 := {S^\ast }^2(X) = \frac {1}{n} \sum _{i=1}^n (X_i - \mu
_0)^2\), also ist \(\widehat {\theta }_0 := (\mu _0, \widehat {\sigma }_0^2)\) der MLS fu&#x0308;r \(\theta \in \Theta _0\).
</p>

<p>
Somit erha&#x0308;lt man den verallg. L.-Q.-Test \(\delta (X) = \1_{\{h(\lambda (X)) \ge h_{1-\alpha }\}}\) mit \(\lambda (x) := \frac {p(x, \widehat {\theta })}{p(x, \widehat {\theta }_0)}\).<br />
Also gilt \(\ln \lambda (x) = \ln p(x, \widehat {\theta }) - \ln p(x, \widehat {\theta }_0)\)<br />
\(= -\frac {1}{2\widehat {\sigma }^2} \sum _{i=1}^n (x_i - \overline {x})^2 - \frac {n}{2} \ln (2\pi \widehat {\sigma }^2) + \frac {1}{2\widehat {\sigma }_0^2} \sum _{i=1}^n (x_i - \mu _0)^2
- \frac {n}{2} \ln (2\pi \widehat {\sigma }_0^2) = \frac {n}{2} \ln (\widehat {\sigma }_0^2/\widehat {\sigma }^2)\).<br />
Wegen der strengen Monotonie von \(\ln \) kann der Test auch durch \(\delta (X) = \1_{\{\widehat {\sigma }_0^2(X)/\widehat {\sigma }^2(X) &gt; c\}}\) definiert werden, wobei der kritische Wert \(c\) so
gewa&#x0308;hlt wird, dass das vorgegebene Niveau \(\alpha \) eingehalten wird.
</p>

<p>
Zur Bestimmung der Verteilung von \(\widehat {\sigma }_0^2/\widehat {\sigma }^2\) berechnet man \(\widehat {\sigma }_0^2/\widehat {\sigma }^2 = \frac {\widehat {\sigma }^2 + (\overline {X} - \mu
_0)^2}{\widehat {\sigma }^2} = 1 + \frac {(\overline {X} - \mu _0)^2}{\widehat {\sigma }^2}\)<br />
\(= 1 + \frac {1}{n-1} T(X)^2\) mit \(T(X) := \frac {\overline {X} - \mu _0}{S(X)/\sqrt {n}} \sim t_{n-1}\) unter \(H_0\colon \mu = \mu _0\). Damit ist \(\delta \) a&#x0308;quivalent zu einem Test
\(\widetilde {\delta }(X) := \1_{\{|T(X)| &gt; \widetilde {c}\}}\) mit \(\widetilde {c} := t_{n-1,1-\alpha /2}\).
</p>

<p>
Die Gu&#x0308;tefunktion berechnet sich zu \(G_{\widetilde {\delta }}(\theta ) = \EE _\theta (\widetilde {\delta }(X)) = \PP _\theta (|T(X)| &gt; t_{n-1,1-\alpha /2})\)<br />
\(= \PP _\theta \!\left (\left |\frac {\overline {X} - \mu }{S(X)/\sqrt {n}} + \frac {\mu - \mu _0}{S(X)/\sqrt {n}}\right | &gt; t_{n-1,1-\alpha /2}\right )\), denn \(T(X)\) besitzt eine
nicht-zentrale \(t\)-Verteilung mit Nichtzentralita&#x0308;tsparameter \(\Delta = \Delta (\theta ) = \frac {\mu - \mu _0}{\sigma /\sqrt {n}}\).
</p>

<p>
Der Annahmebereich \(C(X)\) des Tests \(\widetilde {\delta }\) ist ein \((1-\alpha )\)-Konfidenzintervall fu&#x0308;r \(\mu \), dabei gilt \(C(X) = \{\mu \in \real \;|\; |T(X)| \le t_{n-1,1-\alpha /2}\} =
\overline {X} \pm \frac {S(X)}{\sqrt {n}} t_{n-1,1-\alpha /2}\).
</p>

{% endraw %}
</div>
{:/nomarkdown}
