
{::nomarkdown}
<div class="lwarp-contents">
{% raw %}
<div class="hidden" >

\(\newcommand{\footnotename}{footnote}\)

\(\def \LWRfootnote {1}\)

\(\newcommand {\footnote }[2][\LWRfootnote ]{{}^{\mathrm {#1}}}\)

\(\newcommand {\footnotemark }[1][\LWRfootnote ]{{}^{\mathrm {#1}}}\)

\(\newcommand \ensuremath [1]{#1}\)

\(\newcommand {\LWRframebox }[2][]{\fbox {#2}} \newcommand {\framebox }[1][]{\LWRframebox } \)

\(\newcommand {\setlength }[2]{}\)

\(\newcommand {\addtolength }[2]{}\)

\(\newcommand {\setcounter }[2]{}\)

\(\newcommand {\addtocounter }[2]{}\)

\(\newcommand {\cline }[1]{}\)

\(\newcommand {\directlua }[1]{\text {(directlua)}}\)

\(\newcommand {\luatexdirectlua }[1]{\text {(directlua)}}\)

\(\newcommand {\protect }{}\)

\(\def \LWRabsorbnumber #1 {}\)

\(\def \LWRabsorbquotenumber &quot;#1 {}\)

\(\def \mathchar {\ifnextchar &quot;\LWRabsorbquotenumber \LWRabsorbnumber }\)

\(\def \mathcode #1={\mathchar }\)

\(\let \delcode \mathcode \)

\(\let \delimiter \mathchar \)

\(\let \LWRref \ref \)

\(\renewcommand {\ref }{\ifstar \LWRref \LWRref }\)

\(\newcommand {\intertext }[1]{\text {#1}\notag \\}\)

\(\newcommand {\mathllap }[2][]{{#1#2}}\)

\(\newcommand {\mathrlap }[2][]{{#1#2}}\)

\(\newcommand {\mathclap }[2][]{{#1#2}}\)

\(\newcommand {\mathmbox }[1]{#1}\)

\(\newcommand {\clap }[1]{#1}\)

\(\newcommand {\LWRmathmakebox }[2][]{#2}\)

\(\newcommand {\mathmakebox }[1][]{\LWRmathmakebox }\)

\(\newcommand {\cramped }[2][]{{#1#2}}\)

\(\newcommand {\crampedllap }[2][]{{#1#2}}\)

\(\newcommand {\crampedrlap }[2][]{{#1#2}}\)

\(\newcommand {\crampedclap }[2][]{{#1#2}}\)

\(\newenvironment {crampedsubarray}[1]{}{}\)

\(\newcommand {\crampedsubstack }{}\)

\(\newcommand {\smashoperator }[2][]{#2\limits }\)

\(\newcommand {\adjustlimits }{}\)

\(\newcommand {\SwapAboveDisplaySkip }{}\)

\(\require {extpfeil}\)

\(\Newextarrow \xleftrightarrow {10,10}{0x2194}\)

\(\Newextarrow \xLeftarrow {10,10}{0x21d0}\)

\(\Newextarrow \xhookleftarrow {10,10}{0x21a9}\)

\(\Newextarrow \xmapsto {10,10}{0x21a6}\)

\(\Newextarrow \xRightarrow {10,10}{0x21d2}\)

\(\Newextarrow \xLeftrightarrow {10,10}{0x21d4}\)

\(\Newextarrow \xhookrightarrow {10,10}{0x21aa}\)

\(\Newextarrow \xrightharpoondown {10,10}{0x21c1}\)

\(\Newextarrow \xleftharpoondown {10,10}{0x21bd}\)

\(\Newextarrow \xrightleftharpoons {10,10}{0x21cc}\)

\(\Newextarrow \xrightharpoonup {10,10}{0x21c0}\)

\(\Newextarrow \xleftharpoonup {10,10}{0x21bc}\)

\(\Newextarrow \xleftrightharpoons {10,10}{0x21cb}\)

\(\newcommand {\LWRdounderbracket }[3]{\underset {#3}{\underline {#1}}}\)

\(\newcommand {\LWRunderbracket }[2][]{\LWRdounderbracket {#2}}\)

\(\newcommand {\underbracket }[1][]{\LWRunderbracket }\)

\(\newcommand {\LWRdooverbracket }[3]{\overset {#3}{\overline {#1}}}\)

\(\newcommand {\LWRoverbracket }[2][]{\LWRdooverbracket {#2}}\)

\(\newcommand {\overbracket }[1][]{\LWRoverbracket }\)

\(\newcommand {\LaTeXunderbrace }[1]{\underbrace {#1}}\)

\(\newcommand {\LaTeXoverbrace }[1]{\overbrace {#1}}\)

\(\newenvironment {matrix*}[1][]{\begin {matrix}}{\end {matrix}}\)

\(\newenvironment {pmatrix*}[1][]{\begin {pmatrix}}{\end {pmatrix}}\)

\(\newenvironment {bmatrix*}[1][]{\begin {bmatrix}}{\end {bmatrix}}\)

\(\newenvironment {Bmatrix*}[1][]{\begin {Bmatrix}}{\end {Bmatrix}}\)

\(\newenvironment {vmatrix*}[1][]{\begin {vmatrix}}{\end {vmatrix}}\)

\(\newenvironment {Vmatrix*}[1][]{\begin {Vmatrix}}{\end {Vmatrix}}\)

\(\newenvironment {smallmatrix*}[1][]{\begin {matrix}}{\end {matrix}}\)

\(\newenvironment {psmallmatrix*}[1][]{\begin {pmatrix}}{\end {pmatrix}}\)

\(\newenvironment {bsmallmatrix*}[1][]{\begin {bmatrix}}{\end {bmatrix}}\)

\(\newenvironment {Bsmallmatrix*}[1][]{\begin {Bmatrix}}{\end {Bmatrix}}\)

\(\newenvironment {vsmallmatrix*}[1][]{\begin {vmatrix}}{\end {vmatrix}}\)

\(\newenvironment {Vsmallmatrix*}[1][]{\begin {Vmatrix}}{\end {Vmatrix}}\)

\(\newenvironment {psmallmatrix}[1][]{\begin {pmatrix}}{\end {pmatrix}}\)

\(\newenvironment {bsmallmatrix}[1][]{\begin {bmatrix}}{\end {bmatrix}}\)

\(\newenvironment {Bsmallmatrix}[1][]{\begin {Bmatrix}}{\end {Bmatrix}}\)

\(\newenvironment {vsmallmatrix}[1][]{\begin {vmatrix}}{\end {vmatrix}}\)

\(\newenvironment {Vsmallmatrix}[1][]{\begin {Vmatrix}}{\end {Vmatrix}}\)

\(\newcommand {\LWRmultlined }[1][]{\begin {multline*}}\)

\(\newenvironment {multlined}[1][]{\LWRmultlined }{\end {multline*}}\)

\(\let \LWRorigshoveleft \shoveleft \)

\(\renewcommand {\shoveleft }[1][]{\LWRorigshoveleft }\)

\(\let \LWRorigshoveright \shoveright \)

\(\renewcommand {\shoveright }[1][]{\LWRorigshoveright }\)

\(\newenvironment {dcases}{\begin {cases}}{\end {cases}}\)

\(\newenvironment {dcases*}{\begin {cases}}{\end {cases}}\)

\(\newenvironment {rcases}{\begin {cases}}{\end {cases}}\)

\(\newenvironment {rcases*}{\begin {cases}}{\end {cases}}\)

\(\newenvironment {drcases}{\begin {cases}}{\end {cases}}\)

\(\newenvironment {drcases*}{\begin {cases}}{\end {cases}}\)

\(\newenvironment {cases*}{\begin {cases}}{\end {cases}}\)

\(\newcommand {\MoveEqLeft }[1][]{}\)

\(\def \LWRAboxed #1&amp;#2&amp;#3!|!{\fbox {\(#1\)}&amp;\fbox {\(#2\)}} \newcommand {\Aboxed }[1]{\LWRAboxed #1&amp;&amp;!|!} \)

\( \newcommand {\LWRABLines }[1][\Updownarrow ]{#1 \notag \\}\newcommand {\ArrowBetweenLines }{\ifstar \LWRABLines \LWRABLines } \)

\(\newcommand {\shortintertext }[1]{\text {#1}\notag \\}\)

\(\newcommand {\vdotswithin }[1]{\hspace {.5em}\vdots }\)

\(\newcommand {\LWRshortvdotswithinstar }[1]{\vdots \hspace {.5em} &amp; \\}\)

\(\newcommand {\LWRshortvdotswithinnostar }[1]{&amp; \hspace {.5em}\vdots \\}\)

\(\newcommand {\shortvdotswithin }{\ifstar \LWRshortvdotswithinstar \LWRshortvdotswithinnostar }\)

\(\newcommand {\MTFlushSpaceAbove }{}\)

\(\newcommand {\MTFlushSpaceBelow }{\\}\)

\(\newcommand \lparen {(}\)

\(\newcommand \rparen {)}\)

\(\newcommand {\ordinarycolon }{:}\)

\(\newcommand {\vcentcolon }{\mathrel {\mathop \ordinarycolon }}\)

\(\newcommand \dblcolon {\vcentcolon \vcentcolon }\)

\(\newcommand \coloneqq {\vcentcolon =}\)

\(\newcommand \Coloneqq {\dblcolon =}\)

\(\newcommand \coloneq {\vcentcolon {-}}\)

\(\newcommand \Coloneq {\dblcolon {-}}\)

\(\newcommand \eqqcolon {=\vcentcolon }\)

\(\newcommand \Eqqcolon {=\dblcolon }\)

\(\newcommand \eqcolon {\mathrel {-}\vcentcolon }\)

\(\newcommand \Eqcolon {\mathrel {-}\dblcolon }\)

\(\newcommand \colonapprox {\vcentcolon \approx }\)

\(\newcommand \Colonapprox {\dblcolon \approx }\)

\(\newcommand \colonsim {\vcentcolon \sim }\)

\(\newcommand \Colonsim {\dblcolon \sim }\)

\(\newcommand {\nuparrow }{\mathrel {\cancel {\uparrow }}}\)

\(\newcommand {\ndownarrow }{\mathrel {\cancel {\downarrow }}}\)

\(\newcommand {\bigtimes }{\mathop {\Large \times }\limits }\)

\(\newcommand {\prescript }[3]{{}^{#1}_{#2}#3}\)

\(\newenvironment {lgathered}{\begin {gathered}}{\end {gathered}}\)

\(\newenvironment {rgathered}{\begin {gathered}}{\end {gathered}}\)

\(\newcommand {\splitfrac }[2]{{}^{#1}_{#2}}\)

\(\let \splitdfrac \splitfrac \)

\(\newcommand {\LWRoverlaysymbols }[2]{\mathord {\smash {\mathop {#2\strut }\limits ^{\smash {\lower 3ex{#1}}}}\strut }}\)

\(\newcommand{\alphaup}{\unicode{x03B1}}\)

\(\newcommand{\betaup}{\unicode{x03B2}}\)

\(\newcommand{\gammaup}{\unicode{x03B3}}\)

\(\newcommand{\digammaup}{\unicode{x03DD}}\)

\(\newcommand{\deltaup}{\unicode{x03B4}}\)

\(\newcommand{\epsilonup}{\unicode{x03F5}}\)

\(\newcommand{\varepsilonup}{\unicode{x03B5}}\)

\(\newcommand{\zetaup}{\unicode{x03B6}}\)

\(\newcommand{\etaup}{\unicode{x03B7}}\)

\(\newcommand{\thetaup}{\unicode{x03B8}}\)

\(\newcommand{\varthetaup}{\unicode{x03D1}}\)

\(\newcommand{\iotaup}{\unicode{x03B9}}\)

\(\newcommand{\kappaup}{\unicode{x03BA}}\)

\(\newcommand{\varkappaup}{\unicode{x03F0}}\)

\(\newcommand{\lambdaup}{\unicode{x03BB}}\)

\(\newcommand{\muup}{\unicode{x03BC}}\)

\(\newcommand{\nuup}{\unicode{x03BD}}\)

\(\newcommand{\xiup}{\unicode{x03BE}}\)

\(\newcommand{\omicronup}{\unicode{x03BF}}\)

\(\newcommand{\piup}{\unicode{x03C0}}\)

\(\newcommand{\varpiup}{\unicode{x03D6}}\)

\(\newcommand{\rhoup}{\unicode{x03C1}}\)

\(\newcommand{\varrhoup}{\unicode{x03F1}}\)

\(\newcommand{\sigmaup}{\unicode{x03C3}}\)

\(\newcommand{\varsigmaup}{\unicode{x03C2}}\)

\(\newcommand{\tauup}{\unicode{x03C4}}\)

\(\newcommand{\upsilonup}{\unicode{x03C5}}\)

\(\newcommand{\phiup}{\unicode{x03D5}}\)

\(\newcommand{\varphiup}{\unicode{x03C6}}\)

\(\newcommand{\chiup}{\unicode{x03C7}}\)

\(\newcommand{\psiup}{\unicode{x03C8}}\)

\(\newcommand{\omegaup}{\unicode{x03C9}}\)

\(\newcommand{\Alphaup}{\unicode{x0391}}\)

\(\newcommand{\Betaup}{\unicode{x0392}}\)

\(\newcommand{\Gammaup}{\unicode{x0393}}\)

\(\newcommand{\Digammaup}{\unicode{x03DC}}\)

\(\newcommand{\Deltaup}{\unicode{x0394}}\)

\(\newcommand{\Epsilonup}{\unicode{x0395}}\)

\(\newcommand{\Zetaup}{\unicode{x0396}}\)

\(\newcommand{\Etaup}{\unicode{x0397}}\)

\(\newcommand{\Thetaup}{\unicode{x0398}}\)

\(\newcommand{\Varthetaup}{\unicode{x03F4}}\)

\(\newcommand{\Iotaup}{\unicode{x0399}}\)

\(\newcommand{\Kappaup}{\unicode{x039A}}\)

\(\newcommand{\Lambdaup}{\unicode{x039B}}\)

\(\newcommand{\Muup}{\unicode{x039C}}\)

\(\newcommand{\Nuup}{\unicode{x039D}}\)

\(\newcommand{\Xiup}{\unicode{x039E}}\)

\(\newcommand{\Omicronup}{\unicode{x039F}}\)

\(\newcommand{\Piup}{\unicode{x03A0}}\)

\(\newcommand{\Varpiup}{\unicode{x03D6}}\)

\(\newcommand{\Rhoup}{\unicode{x03A1}}\)

\(\newcommand{\Sigmaup}{\unicode{x03A3}}\)

\(\newcommand{\Tauup}{\unicode{x03A4}}\)

\(\newcommand{\Upsilonup}{\unicode{x03A5}}\)

\(\newcommand{\Phiup}{\unicode{x03A6}}\)

\(\newcommand{\Chiup}{\unicode{x03A7}}\)

\(\newcommand{\Psiup}{\unicode{x03A8}}\)

\(\newcommand{\Omegaup}{\unicode{x03A9}}\)

\(\newcommand{\alphait}{\unicode{x1D6FC}}\)

\(\newcommand{\betait}{\unicode{x1D6FD}}\)

\(\newcommand{\gammait}{\unicode{x1D6FE}}\)

\(\newcommand{\digammait}{\mathit{\unicode{x03DD}}}\)

\(\newcommand{\deltait}{\unicode{x1D6FF}}\)

\(\newcommand{\epsilonit}{\unicode{x1D716}}\)

\(\newcommand{\varepsilonit}{\unicode{x1D700}}\)

\(\newcommand{\zetait}{\unicode{x1D701}}\)

\(\newcommand{\etait}{\unicode{x1D702}}\)

\(\newcommand{\thetait}{\unicode{x1D703}}\)

\(\newcommand{\varthetait}{\unicode{x1D717}}\)

\(\newcommand{\iotait}{\unicode{x1D704}}\)

\(\newcommand{\kappait}{\unicode{x1D705}}\)

\(\newcommand{\varkappait}{\unicode{x1D718}}\)

\(\newcommand{\lambdait}{\unicode{x1D706}}\)

\(\newcommand{\muit}{\unicode{x1D707}}\)

\(\newcommand{\nuit}{\unicode{x1D708}}\)

\(\newcommand{\xiit}{\unicode{x1D709}}\)

\(\newcommand{\omicronit}{\unicode{x1D70A}}\)

\(\newcommand{\piit}{\unicode{x1D70B}}\)

\(\newcommand{\varpiit}{\unicode{x1D71B}}\)

\(\newcommand{\rhoit}{\unicode{x1D70C}}\)

\(\newcommand{\varrhoit}{\unicode{x1D71A}}\)

\(\newcommand{\sigmait}{\unicode{x1D70E}}\)

\(\newcommand{\varsigmait}{\unicode{x1D70D}}\)

\(\newcommand{\tauit}{\unicode{x1D70F}}\)

\(\newcommand{\upsilonit}{\unicode{x1D710}}\)

\(\newcommand{\phiit}{\unicode{x1D719}}\)

\(\newcommand{\varphiit}{\unicode{x1D711}}\)

\(\newcommand{\chiit}{\unicode{x1D712}}\)

\(\newcommand{\psiit}{\unicode{x1D713}}\)

\(\newcommand{\omegait}{\unicode{x1D714}}\)

\(\newcommand{\Alphait}{\unicode{x1D6E2}}\)

\(\newcommand{\Betait}{\unicode{x1D6E3}}\)

\(\newcommand{\Gammait}{\unicode{x1D6E4}}\)

\(\newcommand{\Digammait}{\mathit{\unicode{x03DC}}}\)

\(\newcommand{\Deltait}{\unicode{x1D6E5}}\)

\(\newcommand{\Epsilonit}{\unicode{x1D6E6}}\)

\(\newcommand{\Zetait}{\unicode{x1D6E7}}\)

\(\newcommand{\Etait}{\unicode{x1D6E8}}\)

\(\newcommand{\Thetait}{\unicode{x1D6E9}}\)

\(\newcommand{\Varthetait}{\unicode{x1D6F3}}\)

\(\newcommand{\Iotait}{\unicode{x1D6EA}}\)

\(\newcommand{\Kappait}{\unicode{x1D6EB}}\)

\(\newcommand{\Lambdait}{\unicode{x1D6EC}}\)

\(\newcommand{\Muit}{\unicode{x1D6ED}}\)

\(\newcommand{\Nuit}{\unicode{x1D6EE}}\)

\(\newcommand{\Xiit}{\unicode{x1D6EF}}\)

\(\newcommand{\Omicronit}{\unicode{x1D6F0}}\)

\(\newcommand{\Piit}{\unicode{x1D6F1}}\)

\(\newcommand{\Rhoit}{\unicode{x1D6F2}}\)

\(\newcommand{\Sigmait}{\unicode{x1D6F4}}\)

\(\newcommand{\Tauit}{\unicode{x1D6F5}}\)

\(\newcommand{\Upsilonit}{\unicode{x1D6F6}}\)

\(\newcommand{\Phiit}{\unicode{x1D6F7}}\)

\(\newcommand{\Chiit}{\unicode{x1D6F8}}\)

\(\newcommand{\Psiit}{\unicode{x1D6F9}}\)

\(\newcommand{\Omegait}{\unicode{x1D6FA}}\)

\(\let \digammaup \Digammaup \)

\(\renewcommand {\digammait }{\mathit {\digammaup }}\)

\(\newcommand {\smallin }{\unicode {x220A}}\)

\(\newcommand {\smallowns }{\unicode {x220D}}\)

\(\newcommand {\notsmallin }{\LWRoverlaysymbols {/}{\unicode {x220A}}}\)

\(\newcommand {\notsmallowns }{\LWRoverlaysymbols {/}{\unicode {x220D}}}\)

\(\newcommand {\rightangle }{\unicode {x221F}}\)

\(\newcommand {\intclockwise }{\unicode {x2231}}\)

\(\newcommand {\ointclockwise }{\unicode {x2232}}\)

\(\newcommand {\ointctrclockwise }{\unicode {x2233}}\)

\(\newcommand {\oiint }{\unicode {x222F}}\)

\(\newcommand {\oiiint }{\unicode {x2230}}\)

\(\newcommand {\ddag }{\unicode {x2021}}\)

\(\newcommand {\P }{\unicode {x00B6}}\)

\(\newcommand {\copyright }{\unicode {x00A9}}\)

\(\newcommand {\dag }{\unicode {x2020}}\)

\(\newcommand {\pounds }{\unicode {x00A3}}\)

\(\newcommand {\iddots }{\unicode {x22F0}}\)

\(\newcommand {\utimes }{\overline {\times }}\)

\(\newcommand {\dtimes }{\underline {\times }}\)

\(\newcommand {\udtimes }{\overline {\underline {\times }}}\)

\(\newcommand {\leftwave }{\left \{}\)

\(\newcommand {\rightwave }{\right \}}\)

\(\newcommand {\toprule }[1][]{\hline }\)

\(\let \midrule \toprule \)

\(\let \bottomrule \toprule \)

\(\newcommand {\cmidrule }[2][]{}\)

\(\newcommand {\morecmidrules }{}\)

\(\newcommand {\specialrule }[3]{\hline }\)

\(\newcommand {\addlinespace }[1][]{}\)

\(\newcommand {\LWRsubmultirow }[2][]{#2}\)

\(\newcommand {\LWRmultirow }[2][]{\LWRsubmultirow }\)

\(\newcommand {\multirow }[2][]{\LWRmultirow }\)

\(\newcommand {\mrowcell }{}\)

\(\newcommand {\mcolrowcell }{}\)

\(\newcommand {\STneed }[1]{}\)

\( \newcommand {\multicolumn }[3]{#3}\)

\(\newcommand {\tothe }[1]{^{#1}}\)

\(\newcommand {\raiseto }[2]{{#2}^{#1}}\)

\(\newcommand {\ang }[2][]{(\mathrm {#2})\degree }\)

\(\newcommand {\num }[2][]{\mathrm {#2}}\)

\(\newcommand {\si }[2][]{\mathrm {#2}}\)

\(\newcommand {\LWRSI }[2][]{\mathrm {#1\LWRSInumber \,#2}}\)

\(\newcommand {\SI }[2][]{\def \LWRSInumber {#2}\LWRSI }\)

\(\newcommand {\numlist }[2][]{\mathrm {#2}}\)

\(\newcommand {\numrange }[3][]{\mathrm {#2\,\unicode {x2013}\,#3}}\)

\(\newcommand {\SIlist }[3][]{\mathrm {#2\,#3}}\)

\(\newcommand {\SIrange }[4][]{\mathrm {#2\,#4\,\unicode {x2013}\,#3\,#4}}\)

\(\newcommand {\tablenum }[2][]{\mathrm {#2}}\)

\(\newcommand {\ampere }{\mathrm {A}}\)

\(\newcommand {\candela }{\mathrm {cd}}\)

\(\newcommand {\kelvin }{\mathrm {K}}\)

\(\newcommand {\kilogram }{\mathrm {kg}}\)

\(\newcommand {\metre }{\mathrm {m}}\)

\(\newcommand {\mole }{\mathrm {mol}}\)

\(\newcommand {\second }{\mathrm {s}}\)

\(\newcommand {\becquerel }{\mathrm {Bq}}\)

\(\newcommand {\degreeCelsius }{\unicode {x2103}}\)

\(\newcommand {\coulomb }{\mathrm {C}}\)

\(\newcommand {\farad }{\mathrm {F}}\)

\(\newcommand {\gray }{\mathrm {Gy}}\)

\(\newcommand {\hertz }{\mathrm {Hz}}\)

\(\newcommand {\henry }{\mathrm {H}}\)

\(\newcommand {\joule }{\mathrm {J}}\)

\(\newcommand {\katal }{\mathrm {kat}}\)

\(\newcommand {\lumen }{\mathrm {lm}}\)

\(\newcommand {\lux }{\mathrm {lx}}\)

\(\newcommand {\newton }{\mathrm {N}}\)

\(\newcommand {\ohm }{\mathrm {\Omega }}\)

\(\newcommand {\pascal }{\mathrm {Pa}}\)

\(\newcommand {\radian }{\mathrm {rad}}\)

\(\newcommand {\siemens }{\mathrm {S}}\)

\(\newcommand {\sievert }{\mathrm {Sv}}\)

\(\newcommand {\steradian }{\mathrm {sr}}\)

\(\newcommand {\tesla }{\mathrm {T}}\)

\(\newcommand {\volt }{\mathrm {V}}\)

\(\newcommand {\watt }{\mathrm {W}}\)

\(\newcommand {\weber }{\mathrm {Wb}}\)

\(\newcommand {\day }{\mathrm {d}}\)

\(\newcommand {\degree }{\mathrm {^\circ }}\)

\(\newcommand {\hectare }{\mathrm {ha}}\)

\(\newcommand {\hour }{\mathrm {h}}\)

\(\newcommand {\litre }{\mathrm {l}}\)

\(\newcommand {\liter }{\mathrm {L}}\)

\(\newcommand {\arcminute }{^\prime }\)
\(\newcommand {\minute }{\mathrm {min}}\)

\(\newcommand {\arcsecond }{^{\prime \prime }}\)

\(\newcommand {\tonne }{\mathrm {t}}\)

\(\newcommand {\astronomicalunit }{au}\)

\(\newcommand {\atomicmassunit }{u}\)

\(\newcommand {\bohr }{\mathit {a}_0}\)

\(\newcommand {\clight }{\mathit {c}_0}\)

\(\newcommand {\dalton }{\mathrm {D}_\mathrm {a}}\)

\(\newcommand {\electronmass }{\mathit {m}_{\mathrm {e}}}\)

\(\newcommand {\electronvolt }{\mathrm {eV}}\)

\(\newcommand {\elementarycharge }{\mathit {e}}\)

\(\newcommand {\hartree }{\mathit {E}_{\mathrm {h}}}\)

\(\newcommand {\planckbar }{\mathit {\unicode {x210F}}}\)

\(\newcommand {\angstrom }{\mathrm {\unicode {x212B}}}\)

\(\let \LWRorigbar \bar \)

\(\newcommand {\bar }{\mathrm {bar}}\)

\(\newcommand {\barn }{\mathrm {b}}\)

\(\newcommand {\bel }{\mathrm {B}}\)

\(\newcommand {\decibel }{\mathrm {dB}}\)

\(\newcommand {\knot }{\mathrm {kn}}\)

\(\newcommand {\mmHg }{\mathrm {mmHg}}\)

\(\newcommand {\nauticalmile }{\mathrm {M}}\)

\(\newcommand {\neper }{\mathrm {Np}}\)

\(\newcommand {\yocto }{\mathrm {y}}\)

\(\newcommand {\zepto }{\mathrm {z}}\)

\(\newcommand {\atto }{\mathrm {a}}\)

\(\newcommand {\femto }{\mathrm {f}}\)

\(\newcommand {\pico }{\mathrm {p}}\)

\(\newcommand {\nano }{\mathrm {n}}\)

\(\newcommand {\micro }{\mathrm {\unicode {x00B5}}}\)

\(\newcommand {\milli }{\mathrm {m}}\)

\(\newcommand {\centi }{\mathrm {c}}\)

\(\newcommand {\deci }{\mathrm {d}}\)

\(\newcommand {\deca }{\mathrm {da}}\)

\(\newcommand {\hecto }{\mathrm {h}}\)

\(\newcommand {\kilo }{\mathrm {k}}\)

\(\newcommand {\mega }{\mathrm {M}}\)

\(\newcommand {\giga }{\mathrm {G}}\)

\(\newcommand {\tera }{\mathrm {T}}\)

\(\newcommand {\peta }{\mathrm {P}}\)

\(\newcommand {\exa }{\mathrm {E}}\)

\(\newcommand {\zetta }{\mathrm {Z}}\)

\(\newcommand {\yotta }{\mathrm {Y}}\)

\(\newcommand {\percent }{\mathrm {\%}}\)

\(\newcommand {\meter }{\mathrm {m}}\)

\(\newcommand {\metre }{\mathrm {m}}\)

\(\newcommand {\gram }{\mathrm {g}}\)

\(\newcommand {\kg }{\kilo \gram }\)

\(\newcommand {\of }[1]{_{\mathrm {#1}}}\)

\(\newcommand {\squared }{^2}\)

\(\newcommand {\square }[1]{\mathrm {#1}^2}\)

\(\newcommand {\cubed }{^3}\)

\(\newcommand {\cubic }[1]{\mathrm {#1}^3}\)

\(\newcommand {\per }{/}\)

\(\newcommand {\celsius }{\unicode {x2103}}\)

\(\newcommand {\fg }{\femto \gram }\)

\(\newcommand {\pg }{\pico \gram }\)

\(\newcommand {\ng }{\nano \gram }\)

\(\newcommand {\ug }{\micro \gram }\)

\(\newcommand {\mg }{\milli \gram }\)

\(\newcommand {\g }{\gram }\)

\(\newcommand {\kg }{\kilo \gram }\)

\(\newcommand {\amu }{\mathrm {u}}\)

\(\newcommand {\nm }{\nano \metre }\)

\(\newcommand {\um }{\micro \metre }\)

\(\newcommand {\mm }{\milli \metre }\)

\(\newcommand {\cm }{\centi \metre }\)

\(\newcommand {\dm }{\deci \metre }\)

\(\newcommand {\m }{\metre }\)

\(\newcommand {\km }{\kilo \metre }\)

\(\newcommand {\as }{\atto \second }\)

\(\newcommand {\fs }{\femto \second }\)

\(\newcommand {\ps }{\pico \second }\)

\(\newcommand {\ns }{\nano \second }\)

\(\newcommand {\us }{\micro \second }\)

\(\newcommand {\ms }{\milli \second }\)

\(\newcommand {\s }{\second }\)

\(\newcommand {\fmol }{\femto \mol }\)

\(\newcommand {\pmol }{\pico \mol }\)

\(\newcommand {\nmol }{\nano \mol }\)

\(\newcommand {\umol }{\micro \mol }\)

\(\newcommand {\mmol }{\milli \mol }\)

\(\newcommand {\mol }{\mol }\)

\(\newcommand {\kmol }{\kilo \mol }\)

\(\newcommand {\pA }{\pico \ampere }\)

\(\newcommand {\nA }{\nano \ampere }\)

\(\newcommand {\uA }{\micro \ampere }\)

\(\newcommand {\mA }{\milli \ampere }\)

\(\newcommand {\A }{\ampere }\)

\(\newcommand {\kA }{\kilo \ampere }\)

\(\newcommand {\ul }{\micro \litre }\)

\(\newcommand {\ml }{\milli \litre }\)

\(\newcommand {\l }{\litre }\)

\(\newcommand {\hl }{\hecto \litre }\)

\(\newcommand {\uL }{\micro \liter }\)

\(\newcommand {\mL }{\milli \liter }\)

\(\newcommand {\L }{\liter }\)

\(\newcommand {\hL }{\hecto \liter }\)

\(\newcommand {\mHz }{\milli \hertz }\)

\(\newcommand {\Hz }{\hertz }\)

\(\newcommand {\kHz }{\kilo \hertz }\)

\(\newcommand {\MHz }{\mega \hertz }\)

\(\newcommand {\GHz }{\giga \hertz }\)

\(\newcommand {\THz }{\tera \hertz }\)

\(\newcommand {\mN }{\milli \newton }\)

\(\newcommand {\N }{\newton }\)

\(\newcommand {\kN }{\kilo \newton }\)

\(\newcommand {\MN }{\mega \newton }\)

\(\newcommand {\Pa }{\pascal }\)

\(\newcommand {\kPa }{\kilo \pascal }\)

\(\newcommand {\MPa }{\mega \pascal }\)

\(\newcommand {\GPa }{\giga \pascal }\)

\(\newcommand {\mohm }{\milli \ohm }\)

\(\newcommand {\kohm }{\kilo \ohm }\)

\(\newcommand {\Mohm }{\mega \ohm }\)

\(\newcommand {\pV }{\pico \volt }\)

\(\newcommand {\nV }{\nano \volt }\)

\(\newcommand {\uV }{\micro \volt }\)

\(\newcommand {\mV }{\milli \volt }\)

\(\newcommand {\V }{\volt }\)

\(\newcommand {\kV }{\kilo \volt }\)

\(\newcommand {\W }{\watt }\)

\(\newcommand {\uW }{\micro \watt }\)

\(\newcommand {\mW }{\milli \watt }\)

\(\newcommand {\kW }{\kilo \watt }\)

\(\newcommand {\MW }{\mega \watt }\)

\(\newcommand {\GW }{\giga \watt }\)

\(\newcommand {\J }{\joule }\)

\(\newcommand {\uJ }{\micro \joule }\)

\(\newcommand {\mJ }{\milli \joule }\)

\(\newcommand {\kJ }{\kilo \joule }\)

\(\newcommand {\eV }{\electronvolt }\)

\(\newcommand {\meV }{\milli \electronvolt }\)

\(\newcommand {\keV }{\kilo \electronvolt }\)

\(\newcommand {\MeV }{\mega \electronvolt }\)

\(\newcommand {\GeV }{\giga \electronvolt }\)

\(\newcommand {\TeV }{\tera \electronvolt }\)

\(\newcommand {\kWh }{\kilo \watt \hour }\)

\(\newcommand {\F }{\farad }\)

\(\newcommand {\fF }{\femto \farad }\)

\(\newcommand {\pF }{\pico \farad }\)

\(\newcommand {\K }{\mathrm {K}}\)

\(\newcommand {\dB }{\mathrm {dB}}\)

\(\newcommand {\kibi }{\mathrm {Ki}}\)

\(\newcommand {\mebi }{\mathrm {Mi}}\)

\(\newcommand {\gibi }{\mathrm {Gi}}\)

\(\newcommand {\tebi }{\mathrm {Ti}}\)

\(\newcommand {\pebi }{\mathrm {Pi}}\)

\(\newcommand {\exbi }{\mathrm {Ei}}\)

\(\newcommand {\zebi }{\mathrm {Zi}}\)

\(\newcommand {\yobi }{\mathrm {Yi}}\)

\(\require {mhchem}\)

\(\require {cancel}\)

\(\newcommand {\fint }{âĺŊ}\)

\(\newcommand {\hdots }{\cdots }\)

\(\newcommand {\mathnormal }[1]{#1}\)

\(\newcommand {\vecs }[2]{\vec {#1}_{#2}}\)

\(\renewcommand {\A }{\mathcal {A}}\)

\(\newcommand {\B }{\mathcal {B}}\)

\(\renewcommand {\C }{\mathcal {C}}\)

\(\newcommand {\D }{\mathcal {D}}\)

\(\newcommand {\E }{\mathcal {E}}\)

\(\renewcommand {\L }{\mathcal {L}}\)

\(\newcommand {\R }{\mathcal {R}}\)

\(\renewcommand {\U }{\mathcal {U}}\)

\(\newcommand {\EE }{\mathbb {E}}\)

\(\newcommand {\diag }{\operatorname {diag}}\)

\(\renewcommand {\Re }{\operatorname {Re}}\)

\(\renewcommand {\Im }{\operatorname {Im}}\)

\(\newcommand {\Kern }{\operatorname {Kern}}\)

\(\newcommand {\Eig }{\operatorname {Eig}}\)

\(\newcommand {\iu }{\text {i}}\)

\(\newcommand {\trace }{\operatorname {trace}}\)

\(\newcommand {\rg }{\operatorname {rg}}\)

\(\newcommand {\psd }{\succcurlyeq 0}\)

\(\newcommand {\pd }{\succ 0}\)

\(\newcommand {\nsd }{\preccurlyeq 0}\)

\(\newcommand {\nd }{\prec 0}\)

\(\newcommand {\loc }{{\text {loc}}}\)

\(\newcommand {\GL }{\text {GL}}\)

\(\newcommand {\const }{\text {const}}\)

\(\newcommand {\esssup }{\operatorname {ess\,sup}}\)

\(\newcommand {\Spur }{\operatorname {Spur}}\)

\(\newcommand {\cov }{\operatorname {cov}}\)

\(\newcommand {\opt }{{\text {opt}}}\)

\(\newcommand {\dotwidehat }[1]{{\dot {\widehat {#1}}}}\)

\(\newcommand {\dotwidetilde }[1]{{\dot {\widetilde {#1}}}}\)

\(\newcommand {\modelscale }{0.85}\)

\(\newcommand {\code }[1]{\texttt {#1}}\)

\(\newcommand {\name }[1]{\textsc {#1}}\)

\(\newcommand {\smallpmatrix }[1]{\left (\begin {smallmatrix}#1\end {smallmatrix}\right )}\)

\(\newcommand {\matlab }{{\fontfamily {bch}\scshape \selectfont {}Matlab}}\)

\(\newcommand {\innerproduct }[1]{\left \langle {#1}\right \rangle }\)

\(\newcommand {\norm }[1]{\left \Vert {#1}\right \Vert }\)

\(\renewcommand {\natural }{\mathbb {N}}\)

\(\newcommand {\integer }{\mathbb {Z}}\)

\(\newcommand {\rational }{\mathbb {Q}}\)

\(\newcommand {\real }{\mathbb {R}}\)

\(\newcommand {\complex }{\mathbb {C}}\)

\(\renewcommand {\d }{\mathop {}\!\mathrm {d}}\)

\(\newcommand {\dr }{\d {}r}\)

\(\newcommand {\ds }{\d {}s}\)

\(\newcommand {\dt }{\d {}t}\)

\(\newcommand {\du }{\d {}u}\)

\(\newcommand {\dv }{\d {}v}\)

\(\newcommand {\dw }{\d {}w}\)

\(\newcommand {\dx }{\d {}x}\)

\(\newcommand {\dy }{\d {}y}\)

\(\newcommand {\dz }{\d {}z}\)

\(\newcommand {\dsigma }{\d {}\sigma }\)

\(\newcommand {\dphi }{\d {}\phi }\)

\(\newcommand {\dvarphi }{\d {}\varphi }\)

\(\newcommand {\dtau }{\d {}\tau }\)

\(\newcommand {\dxi }{\d {}\xi }\)

\(\newcommand {\dtheta }{\d {}\theta }\)

\(\newcommand {\tp }{\mathrm {T}}\)

</div>

<style type="text/css">
.lwarp-contents li.list-item-f0::marker {
  font-style:italic;
  content:'(1)\00a0\00a0';
}
.lwarp-contents li.list-item-f1::marker {
  font-style:italic;
  content:'(2)\00a0\00a0';
}
.lwarp-contents li.list-item-f2::marker {
  font-style:italic;
  content:'(3)\00a0\00a0';
}
.lwarp-contents li.list-item-f3::marker {
  font-style:italic;
  content:'(4)\00a0\00a0';
}
.lwarp-contents li.list-item-f4::marker {
  font-style:italic;
  content:'(1)\00a0\00a0';
}
.lwarp-contents li.list-item-f5::marker {
  font-style:italic;
  content:'(2)\00a0\00a0';
}
.lwarp-contents li.list-item-f6::marker {
  font-style:italic;
  content:'(3)\00a0\00a0';
}
.lwarp-contents li.list-item-f7::marker {
  font-style:italic;
  content:'(4)\00a0\00a0';
}
.lwarp-contents li.list-item-f8::marker {
  font-style:italic;
  content:'(5)\00a0\00a0';
}
.lwarp-contents li.list-item-f9::marker {
  font-style:italic;
  content:'(1)\00a0\00a0';
}
.lwarp-contents li.list-item-f10::marker {
  font-style:italic;
  content:'(2)\00a0\00a0';
}
.lwarp-contents li.list-item-f11::marker {
  font-style:italic;
  content:'(3)\00a0\00a0';
}
.lwarp-contents li.list-item-f12::marker {
  font-style:italic;
  content:'(4)\00a0\00a0';
}
.lwarp-contents li.list-item-f13::marker {
  font-style:italic;
  content:'(1)\00a0\00a0';
}
.lwarp-contents li.list-item-f14::marker {
  font-style:italic;
  content:'(2)\00a0\00a0';
}
.lwarp-contents li.list-item-f15::marker {
  font-style:italic;
  content:'(1)\00a0\00a0';
}
.lwarp-contents li.list-item-f16::marker {
  font-style:italic;
  content:'(2)\00a0\00a0';
}
.lwarp-contents li.list-item-f17::marker {
  font-style:italic;
  content:'(1)\00a0\00a0';
}
.lwarp-contents li.list-item-f18::marker {
  font-style:italic;
  content:'(2)\00a0\00a0';
}
.lwarp-contents li.list-item-f19::marker {
  font-style:italic;
  content:'(1)\00a0\00a0';
}
.lwarp-contents li.list-item-f20::marker {
  font-style:italic;
  content:'(2)\00a0\00a0';
}
.lwarp-contents li.list-item-f21::marker {
  content:'•\00a0\00a0';
}
.lwarp-contents li.list-item-f22::marker {
  content:'•\00a0\00a0';
}
.lwarp-contents li.list-item-f23::marker {
  content:'•\00a0\00a0';
}
.lwarp-contents li.list-item-f24::marker {
  content:'•\00a0\00a0';
}
.lwarp-contents li.list-item-f25::marker {
  content:'•\00a0\00a0';
}
.lwarp-contents li.list-item-f26::marker {
  content:'•\00a0\00a0';
}
.lwarp-contents li.list-item-f27::marker {
  content:'•\00a0\00a0';
}
.lwarp-contents li.list-item-f28::marker {
  content:'•\00a0\00a0';
}
.lwarp-contents li.list-item-f29::marker {
  content:'•\00a0\00a0';
}
.lwarp-contents li.list-item-f30::marker {
  content:'•\00a0\00a0';
}
</style>
<h2 id="diagonalisierbare-matrizen">Diagonalisierbare Matrizen</h2>
Die Zustandsraum-Darstellung eines dynamischen Systems ohne Ein- und Ausgang ist \(\dot {x} = f(x)\) mit \(f\colon X \rightarrow \real ^n\), \(X \subset \real ^n\). Das System ist linear, falls \(f\) eine lineare
Abbildung ist. Daher wird ein lineares, autonomes System beschrieben durch \(\dot {x} = Ax\) mit \(A \in \real ^{n \times n}\). Lo&#x0308;sungen solcher Systeme sind durch Methoden der linearen Algebra
vollsta&#x0308;ndig bekannt.
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b>diagonale Matrix</b>: Fu&#x0308;r \(A = \diag (\lambda _1, \dotsc , \lambda _n)\) mit \(\lambda _k \in \real \), \(k = 1, \dotsc , n\), ist das System a&#x0308;quivalent zu \(\dot {x}_1 = \lambda _1
x_1\), &#x2026;, \(\dot {x}_n = \lambda _n x_n\). Jede Gleichung dieses vollkommen entkoppelten Systems kann separat gelo&#x0308;st werden. Als Lo&#x0308;sungen erha&#x0308;lt man \(x_k(t) = e^{\lambda _k t}
\xi _k\), \(\xi _k \in \real \), fu&#x0308;r \(k = 1, \dotsc , n\). Kompakter la&#x0308;sst sich das schreiben als \(x(t) = \smallpmatrix {e^{\lambda _1 t} &amp; &amp; 0 \\ &amp; \ddots &amp; \\ 0 &amp;
&amp; e^{\lambda _n t}} \xi \) mit \(\xi = \smallpmatrix {\xi _1 \\ \vdots \\ \xi _n}\), wobei \(x(0) = \xi \) gilt.
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
Fu&#x0308;r \(A\) nicht diagonal muss man eine Koordinatentransformation durchfu&#x0308;hren.
</p>

<p>
<b>Zustandskoordinaten-Transformation</b>: Jede invertierbare Matrix \(T \in \real ^{n \times n}\) definiert eine <em><span class="dashuline" >Zustandskoordinaten-Transformation (state-coordinate
transformation)</span></em> \(z = Tx\).
</p>

<p>
Wenn \(x(t)\) die Gleichung \(\dot {x}(t) = Ax(t)\) erfu&#x0308;llt, dann gilt mit \(z(t) := Tx(t)\), dass<br />
\(\dot {z}(t) = T\dot {x}(t) = TAx(t) = TAT^{-1} Tx(t) = \widetilde {A} z(t)\), wobei in den neuen Koordinaten das System durch \(\widetilde {A} := TAT^{-1}\) beschrieben wird. Umgekehrt erfu&#x0308;llt
\(x(t) := T^{-1} z(t)\) die DGL \(\dot {x}(t) = Ax(t)\), falls \(z(t)\) die DGL \(\widetilde {z}(t) = \widetilde {A} z(t)\) erfu&#x0308;llt.
</p>

<p>
Die Lo&#x0308;sungsmenge von \(\dot {z} = \widetilde {A} z\) transformiert sich also linear durch \(T^{-1}\) in die Lo&#x0308;sungsmenge von \(\dot {x} = Ax\).
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
Oft ist \(A\) zwar nicht diagonal, dafu&#x0308;r aber diagonalisierbar.
</p>

<p>
<b>Satz (Lo&#x0308;sung von \(\dot {x} = Ax\) fu&#x0308;r \(A\) diagonalisierbar)</b>:<br />
Sei \(T \in \real ^{n \times n}\), sodass \(TAT^{-1} = \diag (\lambda _1, \dotsc , \lambda _n)\) mit \(\lambda _1, \dotsc , \lambda _n \in \real \). Dann ist die eindeutige Lo&#x0308;sung von \(\dot {x} =
Ax\), \(x(0) = \xi \), gegeben durch \(x(t) := \left [T^{-1} \diag (e^{\lambda _1 t}, \dotsc , e^{\lambda _n t}) T\right ] \xi \).
</p>

<p>
Jede Komponente einer Lo&#x0308;sung \(x\) von \(\dot {x} = Ax\) ist eine Linearkombination von \(e^{\lambda _k t}\), \(k = 1, \dotsc , n\). Genauer: Wenn \(\xi \) gleich einer der Spalten \(c_k\) von \(S :=
T^{-1}\) ist, dann ist \(x(t) = c_k e^{\lambda _k t}\), da \(Se_k = c_k\) und \(S \diag (e^{\lambda _1 t}, \dotsc , e^{\lambda _n t}) (S^{-1} c_k) = S (\diag (e^{\lambda _1 t}, \dotsc , e^{\lambda _n
t}) e_k) = S (e^{\lambda _k t} e_k) = c_k e^{\lambda _k t}\).<br />
Alle anderen Lo&#x0308;sungen sind wegen Linearita&#x0308;t Linearkombinationen dieser \(n\) Lo&#x0308;sungen:<br />
\([S \diag (e^{\lambda _1 t}, \dotsc , e^{\lambda _n t}) S^{-1}] (\sum _{k=1}^n \mu _k c_k) = \sum _{k=1}^n \mu _k c_k e^{\lambda _k t}\).
</p>

<p>
<b>Beispiel</b>: Beim linearisierten inversen Federpendel bekommt man im oberen Gleichgewicht die Matrix \(A = \smallpmatrix {0 &amp; 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 1 \\ 0 &amp; 3.92 &amp; -2
&amp; -0.32 \\ 0 &amp; 22.1 &amp; -3.23 &amp; -1.82}\). Man erha&#x0308;lt Matrizen \(S = \smallpmatrix {1 &amp; -0.03 &amp; -0.04 &amp; 0.58 \\ 0 &amp; -0.26 &amp; -0.16 &amp; -0.11 \\ 0 &amp;
-0.12 &amp; 0.22 &amp; -0.79 \\ 0 &amp; -0.96 &amp; 0.96 &amp; 0.16}\) und<br />
\(\Lambda = \diag (0, 3.72, -6.16, -1.38)\) mit \(\Lambda = S^{-1} AS\). Die Lo&#x0308;sung divergiert nicht bestimmt genau dann, wenn \(\xi \in \left \{S \left .\smallpmatrix {\widetilde {\xi }_1 \\ 0
\\ \widetilde {\xi }_3 \\ \widetilde {\xi }_4} \;\right |\; \widetilde {\xi }_1, \widetilde {\xi }_3, \widetilde {\xi }_4 \in \real \right \}\).
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b>komplexe Transformationen und Diagonalmatrizen</b>: Fu&#x0308;r die Linearisierung im unteren Gleichgewicht sind die Matrizen \(T = \smallpmatrix {r_1 \\ r_2 \\ r_3 \\ r_4}\), \(S = \smallpmatrix {c_1
&amp; c_2 &amp; c_3 &amp; c_4}\) und \(\Lambda = \diag (\lambda _1, \lambda _2, \lambda _3, \lambda _4)\) komplex. Dennoch stimmt obiger Satz, denn Eigenwerte von reellen Matrizen treten immer komplex
konjugiert auf. Hier ist z.&#x202f;B. \(\lambda _2 = \overline {\lambda _3}\), \(c_2 = \overline {c_3}\) und \(r_2 = \overline {r_3}\). Daher ist<br />
\(\left [T^{-1} \diag (e^{\lambda _1 t}, e^{\lambda _2 t}, e^{\lambda _3 t}, e^{\lambda _4 t}) T\right ] = \smallpmatrix {c_1 e^{\lambda _1 t} &amp; c_2 e^{\lambda _2 t} &amp; \overline {c_2}
e^{\overline {\lambda _2} t} &amp; c_4 e^{\lambda _4 t}} \smallpmatrix {r_1 \\ r_2 \\ \overline {r_2} \\ r_4}\)<br />
\(= e^{\lambda _1 t} c_1 r_1 + e^{\lambda _2 t} c_2 r_2 + e^{\overline {\lambda _2} t} \overline {c_2} \overline {r_2} + e^{\lambda _4 t} c_4 r_4 = e^{\lambda _1 t} c_1 r_1 + 2 \Re \!\left
[e^{\lambda _2 t} c_2 r_2\right ] + e^{\lambda _4 t} c_4 r_4\) immer eine reelle Matrix. Dementsprechend ist die Lo&#x0308;sung fu&#x0308;r den Anfangswert \(\xi \in \real ^4\) gleich<br />
\(e^{\lambda _1 t} c_1 (r_1 \xi ) + 2 \Re \!\left [e^{\lambda _2 t} c_2 (r_2 \xi )\right ] + e^{\lambda _4 t} c_4 (r_4 \xi )\).
</p>

<p>
Das la&#x0308;sst sich noch etwas vereinfachen: Fu&#x0308;r \(\lambda = \sigma + \iu \omega \in \complex \) (\(\sigma , \omega \in \real \)) gilt<br />
\(e^{\lambda t} = e^{\sigma t}[\cos (\omega t) + \iu \sin (\omega t)]\). Wenn also \(c\) und \(r\) komplexe Spalten- bzw. Zeilenvektoren sind, dann ist \(cr = [\Re (c) + \iu \Im (c)] [\Re (r) + \iu \Im
(r)] = M + \iu N\) mit \(M := [\Re (c) \Re (r) - \Im (c) \Im (r)]\) und \(N := [\Re (c) \Im (r) + \Im (c) \Re (r)]\).<br />
Das fu&#x0308;hrt zur expliziten Formel \(\Re \!\left [e^{\lambda t} c r\right ] = e^{\sigma t} [\cos (\omega t) M - \sin (\omega t) N]\).<br />
Die Komponenten von \(\Re \!\left [e^{\lambda t} c r\right ] \xi \) sind also gleichbleibende (\(\sigma = 0\)), wachsende (\(\sigma &gt; 0\)) oder kleiner werdende (\(\sigma &lt; 0\)) Oszillationen.
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
Bei der Diagonalisierung einer Matrix \(A \in \real ^{n \times n}\) bestimmt man fu&#x0308;r jeden Eigenwert \(\lambda \) eine Basis des zugeho&#x0308;rigen Eigenraums \(\Kern (A - \lambda I)\). Die Basen aller
Eigenra&#x0308;ume fasst man zu \(v_1, \dotsc , v_g\) zusammen, diese Menge ist automatisch linear unabha&#x0308;ngig und daher \(g \le n\).
</p>

<p>
<b>Satz (Diagonalisierbarkeitskriterium)</b>: Seien \(v_1, \dotsc , v_g\) linear unabha&#x0308;ngige Eigenvektoren zu Eigenwerten \(\lambda _1, \dotsc , \lambda _g\) der Matrix \(A \in \real ^{n \times n}\),
sodass keine gro&#x0308;ßere Liste linear unabha&#x0308;ngiger Eigenvektoren existiert. Dann ist \(A\) diagonalisierbar genau dann, wenn \(g = n\). In diesem Fall ist \(S^{-1} A S = \diag (\lambda _1, \dotsc , \lambda
_n)\) mit \(S = \smallpmatrix {v_1 &amp; \dots &amp; v_n}\).
</p>

<p>
<b>Modi, Modusformen</b>: Die Eigenwerte von \(A\) heißen <em><span class="dashuline" >Modi (modes)</span></em> des Systems \(\dot {x} = Ax\). Die zugeho&#x0308;rigen Eigenvektoren heißen <em><span
class="dashuline" >Modusformen (mode-shapes)</span></em>.
</p>



<h2 id="nicht-diagonalisierbare-matrizen">Nicht-diagonalisierbare Matrizen</h2>

</p>


<p>
<b>Matrixexponential</b>: Seien \(A \in \real ^{n \times n}\) und \(t \in \real \).<br />
Dann ist \(e^{At} := \sum _{k=0}^\infty \frac {1}{k!} (At)^k\) das <em><span class="dashuline" >Matrixexponential</span></em> von \(At\).
</p>

<p>
<b>Satz (Matrixexponential)</b>:
</p>
<ul style="list-style-type:none">

<li class="list-item-f0"><p>Die Reihe \(e^{At}\) konvergiert gleichma&#x0308;ßig auf \([-T, T]\) fu&#x0308;r jedes \(T &gt; 0\).<br />
Daher ist \(t \mapsto e^{At}\) eine wohldefinierte, analytische Funktion auf \(\real \).
</p>
</li>
<li class="list-item-f1"><p>Es gilt \(e^{A0} = I\), \(e^{A(t + \tau )} = e^{At} e^{A\tau }\) und daher \(e^{-At} = [e^{At}]^{-1}\).
</p>
</li>
<li class="list-item-f2"><p>Es gilt \(\frac {d}{dt} e^{At} = A e^{At} = e^{At} A\).
</p>
</li>
<li class="list-item-f3"><p>Es gilt \(e^{S^{-1} (At) S} = S^{-1} e^{At} S\).
</p>
</li>
</ul>

<p>
<b>diagonalisierbare Matrizen</b>: Gilt \(A = T^{-1} \Lambda T\), so ist \(e^{At} = T^{-1} \diag (e^{\lambda _1 t}, \dotsc , e^{\lambda _n t}) T\).
</p>

<p>
<b>Satz (Lo&#x0308;sung von \(\dot {x} = Ax\))</b>: Fu&#x0308;r \(A \in \real ^{n \times n}\) ist die eindeutige Lo&#x0308;sung von \(\dot {x} = Ax\), \(x(0) = \xi \) gegeben durch \(x(t) = e^{At} \xi \)
(fu&#x0308;r \(x(\tau ) = \xi \) durch \(x(t) = e^{A(t - \tau )} \xi \)).
</p>

<p>
<b>Beispiel</b>: Den <em><span class="dashuline" >Doppelintegrator (double integrator)</span></em> \(\ddot {q} = u\) kann man durch \(\dot {x} = Ax + Bu\) mit Matrizen \(A = \smallpmatrix {0 &amp; 1 \\ 0
&amp; 0}\) und \(B = \smallpmatrix {0 \\ 1}\) in die Zustandsraum-Darstellung bringen. Es gilt \((At)^2 = 0\), somit also \(e^{At} = I + (At) = \smallpmatrix {1 &amp; t \\ 0 &amp; 1}\). Die Lo&#x0308;sungen
von \(\dot {x} = Ax\) sind daher \(x(t) = e^{At} \xi = \smallpmatrix {\xi _1 + t \xi _2 \\ \xi _2}\).
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b>Satz (<span class="textsc" >Jordan</span>-Normalform)</b>: Sei \(A \in \complex ^{n \times n}\).
</p>
<ul style="list-style-type:none">

<li class="list-item-f4"><p>Es gibt eine invertierbare Matrix \(S \in \complex ^{n \times n}\) mit \(S^{-1} A S = J\) mit der <em><span class="dashuline" ><span class="textsc" >Jordan</span>-Normalform</span></em> \(J :=
\smallpmatrix {J_1 &amp; &amp; 0 \\ &amp; \ddots &amp; \\ 0 &amp; &amp; J_g}\), wobei \(J_\ell := \smallpmatrix {\lambda _\ell &amp; 1 &amp; &amp; 0 \\ &amp; \ddots &amp; \ddots &amp; \\ &amp;
&amp; \lambda _\ell &amp; 1 \\ 0 &amp; &amp; &amp; \lambda _\ell }\) die <em><span class="dashuline" ><span class="textsc" >Jordan</span>-Blo&#x0308;cke</span></em> sind.
</p>
</li>
<li class="list-item-f5"><p>Bis auf Permutation der Jordan-Blo&#x0308;cke ist die Jordan-Normalform eindeutig bestimmt.
</p>
</li>
<li class="list-item-f6"><p>\(\lambda _1, \dotsc , \lambda _g\) sind die nicht notwendigerweise verschiedenen Eigenwerte von \(A\).
</p>
</li>
<li class="list-item-f7"><p>Es gibt genau \(g\) linear unabha&#x0308;ngige Eigenvektoren von \(A\).
</p>
</li>
<li class="list-item-f8"><p>\(A\) ist diagonalisierbar genau dann, wenn alle Jordan-Blo&#x0308;cke Dimension \(1\) haben.
</p>
</li>
</ul>

<p>
<b>Beispiel</b>: Fu&#x0308;r \(A = \smallpmatrix {1 &amp; 7 &amp; 7 &amp; -8 &amp; 6 \\ 1 &amp; 5 &amp; 5 &amp; -5 &amp; 5 \\ 1 &amp; 0 &amp; 2 &amp; -1 &amp; 1 \\ 0 &amp; 3 &amp; 3 &amp; -3
&amp; 2 \\ -1 &amp; -4 &amp; -5 &amp; 5 &amp; -4}\) ist \(J = \smallpmatrix {-1 &amp; 1 &amp; &amp; &amp; 0 \\ 0 &amp; -1 &amp; &amp; &amp; \\ &amp; &amp; 1 &amp; 1 &amp; \\ &amp; &amp; 0 &amp;
1 &amp; \\ 0 &amp; &amp; &amp; &amp; 1}\) mit einer bestimmten Matrix \(S\). Die erste, dritte und fu&#x0308;nfte Spalte von \(S\) sind linear unabha&#x0308;ngige Eigenvektoren von \(A\) fu&#x0308;r die Eigenwerte
\(-1\), \(1\) und \(1\). Die anderen Spalten sind <em><span class="dashuline" >verallgemeinerte Eigenvektoren</span></em>, d.&#x202f;h. in \(\Kern ((A - \lambda I)^\nu )\) fu&#x0308;r \(\lambda \in \Eig (A)\)
und \(\nu \ge 2\).
</p>

<p>
<b>JNF in MATLAB</b>: In MATLAB kann man die Jordan-Normalform mit <kbd>[S, J] = jordan(A)</kbd> berechnen. Allerdings wird dies nicht fu&#x0308;r numerische Berechnungen empfohlen, da die Funktion numerisch
unzuverla&#x0308;ssig ist. Stattdessen soll die <em><span class="dashuline" ><span class="textsc" >Schur</span>-Zerlegung</span></em> verwendet werden (unita&#x0308;re A&#x0308;hnlichkeitstransformation auf
obere Dreiecksmatrix, wenn das charakteristische Polynom in Linearfaktoren zerfa&#x0308;llt).
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b>Satz (Berechnung von \(e^{At}\) mit der JNF)</b>: Sei \(A = SJS^{-1}\) mit \(J\) der JNF von \(A\).<br />
Dann gilt \(e^{At} = S e^{Jt} S^{-1} = S \diag (e^{J_1 t}, \dotsc , e^{J_g t}) S^{-1}\), wobei
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--



                                                                                                                  t2               t d−2    t d−1
                                                                                                                                                 
                                                                                                          1   t   2!       ...    (d−2)!   (d−1)!
                                                                                                                                   t d−3    t d−2 
                                                                                                      
                                                                                                             1    t       ···    (d−3)!   (d−2)! 
                                                                                                                 ..       ..       ..       ..   
                                                                                    e J` t   = e λ` t 
                                                                                                                      .      .      .        .   ,
                                                                                                                                                  
                                                                                                                                                       ` = 1, . . . , g,
                                                                                                                                            t2
                                                                                                                            1
                                                                                                                                                 
                                                                                                                                   t       2!
                                                                                                                                                  
                                                                                                                                    1        t
                                                                                                                                                 
                                                                                                          0                                  1


-->


<p>

\begin{align*}
e^{J_\ell t} = e^{\lambda _\ell t} \begin{pmatrix} 1 &amp; t &amp; \frac {t^2}{2!} &amp; \dots &amp; \frac {t^{d-2}}{(d-2)!} &amp; \frac {t^{d-1}}{(d-1)!} \\ &amp; 1 &amp; t &amp; \dotsb
&amp; \frac {t^{d-3}}{(d-3)!} &amp; \frac {t^{d-2}}{(d-2)!} \\ &amp; &amp; \ddots &amp; \ddots &amp; \vdots &amp; \vdots \\ &amp; &amp; &amp; 1 &amp; t &amp; \frac {t^2}{2!} \\ &amp; &amp;
&amp; &amp; 1 &amp; t \\ 0 &amp; &amp; &amp; &amp; &amp; 1 \end {pmatrix},\quad \ell = 1, \dotsc , g,
\end{align*}
wenn \(J_\ell \) die Dimension \(d\) besitzt.
</p>

<p>
<b>komplexe Eigenwerte</b>: Fu&#x0308;r \(S = \smallpmatrix {C_1 &amp; \dots &amp; C_g}\) und \(T = \smallpmatrix {R_1 \\ \vdots \\ R_g}\) (Aufteilung wie bei \(J\)) gilt \(e^{At} = C_1 e^{J_1 t} R_1 +
\dotsb + C_g e^{J_g t} R_g\). Wenn \(\lambda _k\) reell ist, dann sind \(C_k\) und \(R_k\) auch reell. Wenn \(\lambda _k\) dagegen komplex ist, dann gibt es ein \(\ell \) mit \(\lambda _k = \overline {\lambda _\ell
}\) sowie \(C_k = \overline {C_\ell }\) und \(R_k = \overline {R_\ell }\). Fu&#x0308;r \(\lambda _1 = \overline {\lambda _2}\) addieren sich beispielsweise \(C_1 e^{J_1 t} R_1\) und \(\overline {C_1}
e^{\overline {J_1} t} \overline {R_1}\) in der Formel von eben zu \(2\Re [C_1 e^{J_1 t} R_1]\).
</p>



<h2 id="stabilitaet-linearer-systeme">Stabilität linearer Systeme</h2>

</p>


<p>
Die folgenden beiden Stabilita&#x0308;tsbegriffe sind global, weil die Bedingung jeweils fu&#x0308;r alle Anfangswerte gelten muss.
</p>

<p>
<b>asymptotische Stabilita&#x0308;t</b>: Das lineare System \(\dot {x} = Ax\) bzw. das Gleichgewicht \(0\) heißt <em><span class="dashuline" >(global) asymptotisch stabil</span></em>, falls alle Lo&#x0308;sungen
\(\lim _{t \to \infty } x(t) = 0\) erfu&#x0308;llen.
</p>

<p>
Asymptotische Stabilita&#x0308;t heißt anders ausgedru&#x0308;ckt, dass \(\lim _{t \to \infty } e^{At} = 0\).
</p>

<p>
<b><span class="textsc" >Hurwitz</span>-Matrix</b>:<br />
Eine <em><span class="dashuline" ><span class="textsc" >Hurwitz</span>-Matrix</span></em> ist eine Matrix, deren Eigenwerte alle negative Realteile besitzen.
</p>

<p>
<b>Satz (asymptotische Stabilita&#x0308;t)</b>:<br />
Das System \(\dot {x} = Ax\) ist asymptotisch stabil genau dann, wenn \(A\) eine Hurwitz-Matrix ist.
</p>

<p>
<b>Lemma</b>: \(A \in \real ^{2 \times 2}\) ist eine Hurwitz-Matrix genau dann, wenn \(\det (A) &gt; 0\) und \(\trace (A) &lt; 0\).
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b><span class="textsc" >Lyapunov</span>-Stabilita&#x0308;t</b>: Das lineare System \(\dot {x} = Ax\) heißt <em><span class="dashuline" >(global) <span class="textsc" >Lyapunov</span>-stabil</span></em>,
falls jede Lo&#x0308;sung \(x(t)\) fu&#x0308;r \(t \to \infty \) beschra&#x0308;nkt bleibt.
</p>

<p>
Lyapunov-Stabilita&#x0308;t heißt anders ausgedru&#x0308;ckt, dass \(e^{At}\) fu&#x0308;r \(t \to \infty \) beschra&#x0308;nkt bleibt.
</p>

<p>
<b>Satz (<span class="textsc" >Lyapunov</span>-Stabilita&#x0308;t)</b>: Das System \(\dot {x} = Ax\) ist Lyapunov-stabil genau dann, wenn alle Eigenwerte von \(A\) einen nicht-positiven Realteil und alle
Jordan-Blo&#x0308;cke zu Eigenwerten mit Realteil \(0\) die Dimension \(1\) besitzen.
</p>



<h2 id="stabilitaet-nicht-linearer-systeme-lyapunov-funktionen">Stabilität nicht-linearer Systeme (<span style="font-variant: small-caps;">Lyapunov</span>-Funktionen)</h2>

</p>


<p>
Im Folgenden betrachtet man das System \(\dot {x} = f(x)\) mit \(f \in \C ^1(G, \real ^n)\) fu&#x0308;r eine offene Menge \(G \subset \real ^n\). \(\varphi (\cdot , \xi )\) sei die Lo&#x0308;sung des
Anfangswertproblems mit \(x(0) = \xi \in G\). Man nennt \(\varphi \) auch den <em><span class="dashuline" >Fluss (flow)</span></em> der DGL.
</p>

<p>
<b>Stabilita&#x0308;t nicht-linearer Systeme</b>: Ein Gleichgewicht \(x_e \in G\) von \(\dot {x} = f(x)\) heißt
</p>
<ul style="list-style-type:none">

<li class="list-item-f9"><p><em><span class="dashuline" >stabil</span></em>, falls \(\forall _{\varepsilon &gt; 0} \exists _{\delta &gt; 0} \forall _{\xi \in G,\; \norm {\xi - x_e} \le \delta } \forall _ {t \ge
0}\; \norm {\varphi (t, \xi ) - x_e} \le \varepsilon \),
</p>
</li>
<li class="list-item-f10"><p><em><span class="dashuline" >instabil</span></em>, falls es nicht stabil ist,
</p>
</li>
<li class="list-item-f11"><p><em><span class="dashuline" >attraktiv</span></em>, falls \(\exists _{\delta &gt; 0} \forall _{\xi \in G,\; \norm {\xi - x_e} \le \delta }\; \lim _{t \to \infty } \varphi (t, \xi ) =
x_e\), und
</p>
</li>
<li class="list-item-f12"><p><em><span class="dashuline" >asymptotisch stabil</span></em>, falls es stabil und attraktiv ist.
</p>
</li>
</ul>

<p>
Alle Begriffe sind lokal, d.&#x202f;h. die Kriterien gelten nur fu&#x0308;r bestimmte Anfangsbedingungen. Stabilita&#x0308;t und Attraktivita&#x0308;t sind voneinander unabha&#x0308;ngige Eigenschaften.
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b><span class="textsc" >Lyapunov</span>-Funktion</b>: Eine Funktion \(V \in \C ^1(G, \real )\) heißt <em><span class="dashuline" ><span class="textsc" >Lyapunov</span>-Funktion</span></em>
fu&#x0308;r die nicht-lineare DGL \(\dot {x} = f(x)\), falls \(\forall _{x \in G}\; \dot {V}(x) := \partial _x V(x) \cdot f(x) \le 0\).
</p>

<p>
Ist \(x(\cdot )\) eine Trajektorie der nicht-linearen DGL in \(G\), so gilt fu&#x0308;r alle \(t\)<br />
\(\frac {d}{dt} V(x(t)) = \partial _x V(x(t)) \cdot \dot {x}(t) = \partial _x V(x(t)) \cdot f(x(t)) = \dot {V}(x(t)) \le 0\). Daher ist \(t \mapsto V(x(t))\) fu&#x0308;r jede Lo&#x0308;sung
\(x(\cdot )\) der DGL monoton fallend. Deswegen kann man \(V\) als ein Potential betrachten, sodass Trajektorien zu den Punkten konvergieren, in denen \(V\) minimal ist.
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b>Satz (direkte Methode von <span class="textsc" >Lyapunov</span>)</b>:<br />
Sei \(V\) eine Lyapunov-Funktion fu&#x0308;r \(\dot {x} = f(x)\) und \(x_e \in G\) ein Gleichgewicht.
</p>
<ul style="list-style-type:none">

<li class="list-item-f13"><p>Wenn \(\forall _{x \in G \setminus \{x_e\}}\; V(x) &gt; V(x_e)\), dann ist \(x_e\) stabil.
</p>
</li>
<li class="list-item-f14"><p>Wenn \(\forall _{x \in G \setminus \{x_e\}}\; V(x) &gt; V(x_e) \;\land \; \dot {V}(x) &lt; 0\), dann ist \(x_e\) asymptotisch stabil.
</p>
</li>
</ul>

<p>
Man kann ohne Einschra&#x0308;nkung annehmen, dass \(V(x_e) = 0\) (durch Verschiebung von \(V\)). In der Praxis wird oft eine Lyapunov-Funktion gesucht, um die Stabilita&#x0308;t eines Gleichgewichts zu sichern.
Allerdings ist dies schwierig und die Stabilita&#x0308;tseigenschaften gelten dann auch nur lokal. Zur Vereinfachung wird \(G\) meist als eine offene Kugel um \(x_e\) gewa&#x0308;hlt.
</p>

<p>
<b>Beispiel</b>: Beim geda&#x0308;mpften Federpendel ohne Eingang ist \(\smallpmatrix {\dot {x}_1 \\ \dot {x}_2} = \smallpmatrix {x_2 \\ -\frac {k}{m} x_1 - \frac {1}{m} c(x_2)} =: f(x_1, x_2)\) mit
\(c(\cdot ) \in \C ^1(\real , \real )\). Sei \(c\) so gewa&#x0308;hlt, dass \(c(x_2) = 0 \iff x_2 = 0\), d.&#x202f;h. \(x_e = (0, 0)\) ist das eindeutige Gleichgewicht. Definiere \(V(x_1, x_2) := \frac {1}{2}
kx_1^2 + \frac {1}{2} mx_2^2\) (Gesamtenergie bestehend aus der Federenergie und der kinetischen Energie). Es gilt \(\dot {V}(x) = \partial _x V(x) \cdot f(x) = -x_2 c(x_2)\). \(V\) ist also eine Lyapunov-Funktion,
wenn man annimmt, dass \(x_2 c(x_2) \ge 0\) fu&#x0308;r alle \(x_2 \in \real \). Außerdem gilt \(V(x) &gt; V(0) = 0\) fu&#x0308;r alle \(x \not = 0\). Somit ist \(x_e = 0\) nach dem ersten Teil des Satzes stabil.<br
/>
Den zweiten Teil des Satzes kann man nicht anwenden, da \(\dot {V}(x) = 0 \iff x_2 = 0\).
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b>Satz (Invarianzprinzip von <span class="textsc" >LaSalle</span>)</b>:<br />
Sei \(V\) eine Lyapunov-Funktion fu&#x0308;r \(\dot {x} = f(x)\) und \(x_e \in G\) ein Gleichgewicht. Außerdem gelte
</p>
<ul style="list-style-type:none">

<li class="list-item-f15"><p>\(\forall _{x \in G \setminus \{x_e\}}\; V(x) &gt; V(x_e)\) und
</p>
</li>
<li class="list-item-f16"><p>\(\forall _{\xi \in G}\; ([\forall _{t \in (t_-, t_+)}\; \dot {V}(\varphi (t, \xi )) = 0] \;\Rightarrow \; \xi = x_e)\).
</p>
</li>
</ul>

<p>
Dann ist \(x_e\) asymptotisch stabil.
</p>

<p>
Gilt \(\forall _{x \in G \setminus \{x_e\}}\; \dot {V}(x) &lt; 0\) wie im obigen Satz, so gilt Bedingung <em>(2)</em> des Invarianzprinzips, da fu&#x0308;r \(\xi \in G\) mit \(\dot {V}(\varphi (t, \xi )) = 0\)
fu&#x0308;r alle \(t \in (t_-, t_+)\) gilt, dass \(\dot {V}(\varphi (0, \xi )) = \dot {V}(\xi ) = 0\), also \(\xi = x_e\).
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b>Beispiel</b>: Im obigen Beispiel gilt fu&#x0308;r \(\xi \in \real ^2\) mit \(\forall _{t \in (t_-, t_+)}\; \dot {V}(\varphi (t, \xi )) = 0\) und \(x(t) := \varphi (t, \xi )\), dass \(-x_2(t) c(x_2(t))
\equiv 0\), also \(x_2(t) \equiv 0\). Insbesondere gilt \(\dot {x}_2(t) \equiv 0\). Aus der DGL ergibt sich damit \(x_1(t) \equiv 0\). Man erha&#x0308;lt also \(\varphi (t, \xi ) \equiv 0\), d.&#x202f;h. \(\xi =
x_e = 0\). Daher ist \(x_e\) asymptotisch stabil.
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b>Satz (Abscha&#x0308;tzung des Attraktivita&#x0308;tsgebiets)</b>:<br />
Sei \(V\) eine Lyapunov-Funktion fu&#x0308;r \(\dot {x} = f(x)\) und \(x_e \in G\) ein Gleichgewicht. Außerdem gelte
</p>
<ul style="list-style-type:none">

<li class="list-item-f17"><p>\(M := \{x \in G \;|\; V(x) \le \alpha \}\) kompakt in \(\real ^n\) fu&#x0308;r ein \(\alpha \in \real \) und
</p>
</li>
<li class="list-item-f18"><p>\(\forall _{\xi \in M}\; ([\forall _{t \in (t_-, t_+)}\; \dot {V}(\varphi (t, \xi )) = 0] \;\Rightarrow \; \xi = x_e)\).
</p>
</li>
</ul>

<p>
Dann gilt \(\forall _{\xi \in M}\; \lim _{t \to \infty } \varphi (t, \xi ) = x_e\).
</p>

<p>
Die <em><span class="dashuline" >Unterniveaumenge (sublevel-set)</span></em> \(M\) entha&#x0308;lt Punkte, die durch \(x_e\) angezogen werden. Mit anderen Worten ist \(M\) eine Teilmenge des
Attraktivita&#x0308;tsgebiets, d.&#x202f;h. von<br />
\(\{\xi \in G \;|\; \lim _{t \to \infty } \varphi (t, \xi ) = x_e\}\). \(M\) kann groß sein und die Stabilita&#x0308;t von \(x_e\) wird nicht vorausgesetzt oder behauptet.
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b>Satz (globale Attraktivita&#x0308;t)</b>:<br />
Sei \(V\) eine Lyapunov-Funktion fu&#x0308;r \(\dot {x} = f(x)\) und \(x_e \in G\) ein Gleichgewicht. Außerdem gelte
</p>
<ul style="list-style-type:none">

<li class="list-item-f19"><p>\(\forall _{(x_\nu )_{\nu \in \natural },\; x_\nu \in G}\; \left (\left [x_\nu \to x \in \partial G \;\lor \; \norm {x_\nu } \to \infty \right ] \;\Rightarrow \; V(x_\nu )
\xrightarrow {\nu \to \infty } \infty \right )\) und
</p>
</li>
<li class="list-item-f20"><p>\(\forall _{\xi \in G}\; ([\forall _{t \in (t_-, t_+)}\; \dot {V}(\varphi (t, \xi )) = 0] \;\Rightarrow \; \xi = x_e)\).
</p>
</li>
</ul>

<p>
Dann gilt \(\forall _{\xi \in G}\; \lim _{t \to \infty } \varphi (t, \xi ) = x_e\).
</p>

<p>
Wenn \(G = \real ^n\) ist, dann ist die erste Bedingung a&#x0308;quivalent zu \(V(x) \to \infty \) fu&#x0308;r \(\norm {x} \to \infty \). Solche Lyapunov-Funktionen heißen <em><span class="dashuline" >radial
unbeschra&#x0308;nkt</span></em>.
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
Die Linearisierung von \(\dot {x} = f(x)\) um \(x_e\) ist gegeben durch \(\dot {x}_\Delta = Ax_\Delta \) mit \(A = \partial _x f(x_e)\). Man hofft, dass \(x(t) = x_e + x_\Delta (t)\), d.&#x202f;h. eine
Lo&#x0308;sung des linearen Systems fu&#x0308;hrt zu einer guten Approximation der Lo&#x0308;sung des nicht-linearen Systems.
</p>

<p>
<b>Satz (indirekte Methode von <span class="textsc" >Lyapunov</span>)</b>: Sei \(\partial _x f(x_e)\) eine Hurwitz-Matrix.<br />
Dann ist \(x_e\) ein asymptotisch stabiles Gleichgewicht von \(\dot {x} = f(x)\).
</p>

<p>
(Globale) asymptotische Stabilita&#x0308;t der Linearisierung fu&#x0308;hrt also zu (lokaler) asymptotischer Stabilita&#x0308;t des nicht-linearen Systems um den Punkt der Linearisierung. Die Umkehrung gilt nicht (nur bei
exponentiell-asymptotischer Stabilita&#x0308;t).
</p>

<p>
<b>Beispiel</b>: Im obigen Beispiel ist \(\dot {x} = f(x) := \smallpmatrix {x_2 \\ -\frac {k}{m} x_1 - \frac {1}{m} c(x_2)}\). Es gilt \(\partial _x f(x) = \smallpmatrix {0 &amp; 1 \\ -\frac {k}{m} &amp;
-\frac {1}{m} c’(x_2)}\), also ist \(\dot {x}_\Delta = Ax_\Delta \) mit \(A := \smallpmatrix {0 &amp; 1 \\ -\frac {k}{m} &amp; -\frac {1}{m} c’(0)}\) die Linearisierung um \(x_e = 0\). Diese Matrix ist eine
Hurwitz-Matrix genau dann, wenn \(c’(0) &gt; 0\) (na&#x0308;mlich \(\det (A) &gt; 0\) und \(\trace (A) &lt; 0\)). Somit ist \(x_e = 0\) ein (lokal) asymptotisch stabiles Gleichgewicht von \(\dot {x} = f(x)\), wenn
\(c’(0) &gt; 0\). Allerdings wurde vorhin mit dem Invarianzprinzip von LaSalle schon asymptotische Stabilita&#x0308;t auch fu&#x0308;r \(c’(0) = 0\) gezeigt (wenn \(x_2 c(x_2) \ge 0\) gilt). Man erkennt also, dass die
Linearisierung auch nicht asymptotisch stabil sein kann, obwohl die nicht-lineare DGL asymptotisch stabil ist.
</p>



<h2 id="verhalten-linearer-systeme">Verhalten linearer Systeme</h2>

</p>


<p>
Im Folgenden werden wieder lineare Systeme \(\dot {x} = Ax + Bu\), \(y = Cx + Du\) betrachtet mit \(A \in \real ^{n \times n}\), \(B \in \real ^{n \times m}\), \(C \in \real ^{k \times n}\) und \(D \in \real
^{k \times m}\).
</p>

<p>
<b>Satz (explizite Lo&#x0308;sung linearer Systeme)</b>: Fu&#x0308;r den Eingang \(u \in \C ([a, b], \real ^m)\) und die Anfangsbedingung \(x(\tau ) = \xi \in \real ^n\), \(\tau \in [a, b]\), ist die
eindeutige Lo&#x0308;sung gegeben durch<br />
\(x(t) = e^{A(t - \tau )} \xi + \int _\tau ^t e^{A(t - s)} Bu(s) \ds \) und der Ausgang daher durch<br />
\(y(t) = Ce^{A(t - \tau )} \xi + \int _\tau ^t [Ce^{A(t - s)} B]u(s) \ds + Du(t)\).
</p>

<p>
Die Lo&#x0308;sung kann man durch <em><span class="dashuline" >Variation der Konstanten</span></em> herleiten: Mit dem Ansatz \(x(t) = e^{At} z(t)\) mit geeignetem \(z(t)\) erha&#x0308;lt man \(\dot {x}(t) =
A e^{At} z(t) + e^{At} \dot {z}(t) = Ax(t) + e^{At} \dot {z}(t)\). Dies ist gleich \(Ax(t) + Bu(t)\) genau dann, wenn \(e^{At} \dot {z}(t) = Bu(t) \iff \dot {z}(s) = e^{-As} Bu(s)\). Integration
fu&#x0308;hrt zu \(z(t) = c + \int _\tau ^t e^{-As} Bu(s) \ds \) mit einem konstanten Vektor \(c\), der durch \(\xi = x(\tau ) = e^{A\tau } z(\tau ) = e^{A\tau } c\) bestimmt ist als \(c = e^{-A\tau } \xi
\). Einsetzen von \(c\) in \(z(t)\) und Berechnung von \(x(t) = e^{At} z(t)\) ergibt die Formel.
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
Im Folgenden wird oBdA \(\tau = 0\) angenommen.
</p>

<p>
<b>Herleitung der Antwort auf konstanten Eingang</b>:<br />
Fu&#x0308;r einen konstanten Eingang \(u(t) \equiv u_e\) gilt<br />
\(x(t) = e^{At} \xi + \int _0^t e^{A(t - s)} B u_e \ds = e^{At} \xi + \left (\int _0^t e^{A\varrho } d\varrho \right ) B u_e\) mit \(\varrho = t - s\). Ist \(A\) eine Hurwitz-Matrix, so ist \(A\)
invertierbar und es gilt \(\int _0^t e^{A\varrho } d\varrho = \int _0^t \frac {d}{d\varrho } e^{A\varrho } A^{-1} d\varrho = e^{At} A^{-1} - A^{-1}\). Damit kann man die Zustandsgro&#x0308;ße schreiben
als \(x(t) = e^{At} [\xi + A^{-1} B u_e] - A^{-1} B u_e\). Fu&#x0308;r \(t \to \infty \) gilt \(e^{At} \to 0\) und somit \(x(t) \to x_e := -A^{-1} B u_e\) (wenn \(A\) eine Hurwitz-Matrix ist). Der Zustand
konvergiert also in diesem Fall zum eindeutigen Gleichgewicht (d.&#x202f;h. zur Lo&#x0308;sung von \(Ax_e + Bu_e = 0\)).
</p>

<p>
<b>Antwort auf konstanten Eingang</b>: Die <em><span class="dashuline" >Antwort auf einen konstanten Eingang</span></em> \(u(t) \equiv u_e\) ist<br />
\(y(t) = Ce^{At} [\xi + A^{-1} B u_e] + [D - CA^{-1}B] u_e\). Dabei bezeichnet
</p>
<ul style="list-style-type:none">

<li class="list-item-f21"><p>\(Ce^{At} [\xi + A^{-1} B u_e]\) die <em><span class="dashuline" >Einschwingantwort (transient response)</span></em> und
</p>
</li>
<li class="list-item-f22"><p>\([D - CA^{-1} B] u_e\) die <em><span class="dashuline" >stationa&#x0308;re Antwort (steady-state response)</span></em>.<br />
Die Matrix \(D - CA^{-1}B\) heißt <em><span class="dashuline" >stationa&#x0308;re Versta&#x0308;rkung (steady-state gain)</span></em>.
</p>
</li>
</ul>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b>Superpositionsprinzip</b>: Der Zustand sowie der Ausgang ha&#x0308;ngen jeweils linear von \(\xi \) und von \(u(\cdot )\) ab (wenn \(u(\cdot )\) bzw. \(\xi \) auf Null gesetzt wird). Dies nennt man das <em><span
class="dashuline" >Superpositionsprinzip</span></em>.
</p>

<p>
Nach dem Superpositionsprinzip kann man zum Beispiel fu&#x0308;r \(m &gt; 1\) den Ausgang als Summe von Ausga&#x0308;ngen fu&#x0308;r einen skalaren Eingang \(u(\cdot )\) darstellen: Ist \(u(t) = \smallpmatrix
{u_1(t) \\ \vdots \\ u_m(t)}\) und sind \(B_k\) und \(D_k\) die Spalten von \(B\) bzw. \(D\), so gilt \(y(t) = C e^{At} \xi + \sum _{k=1}^m \left (\int _0^t Ce^{A(t-s)} B_k u_k(s)\ds + D_k u_k(t)\right )\).
Jeden dieser Beitra&#x0308;ge kann man also separat analysieren.
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
Spru&#x0308;nge und Impulse sind Testeinga&#x0308;nge, mit denen man Informationen u&#x0308;ber das dynamische Verhalten eines Systems gewinnen kann. Beispielsweise kann man mit dem Impulsausgang \(H(t) :=
Ce^{At}B + D\delta (t)\) durch \(\int _0^t H(t - s) u(s) \ds \) den Ausgang fu&#x0308;r jeden anderen Eingang \(u(\cdot )\) bestimmen (Anfangsbedingung \(x(0) = 0\)).
</p>

<p>
<b>Herleitung der Sprungantwort</b>: Ist \(u_k(\cdot )\) gleich der Sprungfunktion \(\Theta (t) := 0\) fu&#x0308;r \(t &lt; 0\) und \(\Theta (t) := 1\) fu&#x0308;r \(t \ge 0\) (<em><span class="dashuline"
><span class="textsc" >Heaviside</span>-Funktion</span></em>), so erha&#x0308;lt man<br />
\(\int _0^t Ce^{A(t-s)} B_k u_k(s)\ds + D_k u_k(t) = \int _0^t Ce^{A\varrho } B_k d\varrho + D_k\) als Ausgang fu&#x0308;r den \(k\)-ten Eingang.
</p>

<p>
<b>Herleitung der Impulsantwort</b>: Ist \(u_k(\cdot )\) gleich dem Impuls \(\delta (\cdot )\) bei \(t = 0\) (<em><span class="dashuline" ><span class="textsc" >Dirac</span>sche
Delta-Distribution</span></em>), so erha&#x0308;lt man<br />
\(\int _0^t Ce^{A(t-s)} B_k u_k(s)\ds + D_k u_k(t) = Ce^{At}B_k + D_k \delta (t)\) als Ausgang fu&#x0308;r den \(k\)-ten Eingang.<br />
Die Delta-Distribution ist gleich der Ableitung der Heaviside-Funktion, daher ist die Impulsantwort die Ableitung der Sprungantwort.
</p>

<p>
<b>Sprung- und Impulsantwort</b>: Man nennt
</p>
<ul style="list-style-type:none">

<li class="list-item-f23"><p>\(\int _0^t Ce^{A\varrho }B d\varrho + D\) die <em><span class="dashuline" >Sprungantwort (step response)</span></em> und
</p>
</li>
<li class="list-item-f24"><p>\(C e^{At} B + D \delta (t)\) die <em><span class="dashuline" >Impulsantwort (impulse response)</span></em>.
</p>
</li>
</ul>

<p>
Die Antworten erha&#x0308;lt man durch Anwendung von \(m\) Spru&#x0308;ngen/Impulsen (fu&#x0308;r jeden Eingang).
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b>Herleitung der Antwort fu&#x0308;r sinusfo&#x0308;rmigen Eingang</b>:<br />
Fu&#x0308;r \(\lambda = \sigma + \iu \omega \in \complex \) und \(u_e \in \real ^m\) betrachtet man den <em><span class="dashuline" >sinusfo&#x0308;rmigen Eingang (sinusoidal input)</span></em><br />
\(u(t) := u_e e^{\lambda t} = u_e e^{\sigma t} [\cos (\omega t) + \iu \sin (\omega t)]\).<br />
Wenn \(A - \lambda I\) invertierbar ist (d.&#x202f;h. \(\lambda \) ist kein Eigenwert von \(A\)), so gilt mit \(\varrho = t - s\), dass<br />
\(y(t) = Ce^{At} \xi + \int _0^t [Ce^{A(t - s)} B]u(s) \ds + Du(t)\)<br />
\(= C \left (e^{At} \xi + \left [\int _0^t e^{A\varrho } e^{\lambda (t - \varrho )} d\varrho \right ] Bu_e\right ) + D (u_e e^{\lambda t})\)<br />
\(= C \left (e^{At} \xi + e^{\lambda t} \left [\int _0^t e^{(A - \lambda I) \varrho } d\varrho \right ] Bu_e\right ) + D (u_e e^{\lambda t})\)<br />
\(= C \left (e^{At} \xi + e^{\lambda t} \left [e^{(A - \lambda I)t} - I\right ] (A - \lambda I)^{-1} B u_e\right ) + D (u_e e^{\lambda t})\).
</p>

<p>
Durch Umordnung erha&#x0308;lt man \(y(t) = Ce^{At} [\xi - (\lambda I - A)^{-1} Bu_e] + [C (\lambda I - A)^{-1} B + D] (u_e e^{\lambda t})\), wobei man die Summanden wieder als <em><span
class="dashuline" >Einschwingantwort</span></em> und <em><span class="dashuline" >stationa&#x0308;re Antwort</span></em> bezeichnet (fu&#x0308;r \(A\) Hurwitz-Matrix ergibt die Namensgebung einen Sinn, in
diesem Fall geht die Einschwingantwort gegen Null fu&#x0308;r \(t \to \infty \)).
</p>

<p>
<b>Antwort auf sinusfo&#x0308;rmigen Eingang</b>: Fu&#x0308;r exponentiell gewichtete, sinusfo&#x0308;rmige, komplexe Einga&#x0308;nge \(u(t) = u_e e^{\lambda t} = u_e e^{\sigma t} [\cos (\omega t) +
\iu \sin (\omega t)]\) (\(\lambda = \sigma + \iu \omega \in \complex \)) mit \(\lambda I - A\) invertierbar erha&#x0308;lt man den Zustand \(x(t) = e^{At} [\xi - (\lambda I - A)^{-1} Bu_e] + (\lambda I
- A)^{-1} B (u_e e^{\lambda t})\) und den Ausgang \(y(t) = C e^{At} [\xi - (\lambda I - A)^{-1} Bu_e] + [C (\lambda I - A)^{-1} B + D] (u_e e^{\lambda t})\).
</p>

<p>
Weil \(A, B, C, D\) und \(\xi \) reell sind, erha&#x0308;lt man die Zusta&#x0308;nde und Ausga&#x0308;nge fu&#x0308;r die Einga&#x0308;nge<br />
\(v(t) = u_e e^{\sigma t} \cos (\omega t)\) und \(w(t) = u_e e^{\sigma t} \sin (\omega t)\), indem man einfach den Real- bzw. den Imagina&#x0308;rteil betrachtet.
</p>



<h2 id="laplace-transformation-und-uebertragungsmatrizen"><span style="font-variant: small-caps;">Laplace</span>-Transformation und Übertragungsmatrizen</h2>

</p>


<p>
<b><span class="textsc" >Laplace</span>-Transformation</b>: Sei \(f\colon \real \rightarrow \complex \) messbar und von <em><span class="dashuline" >exponentieller Ordnung (exponential type)</span></em>,
d.&#x202f;h. \(\exists _{\sigma , c &gt; 0} \forall _{t \ge 0}\; |e^{-\sigma t} f(t)| \le c\). Dann ist die <em><span class="dashuline" >(einseitige) <span class="textsc"
>Laplace</span>-Transformation</span></em> von \(f\) fu&#x0308;r alle \(s \in \complex \) mit \(\Re (s) &gt; \sigma \) definiert durch \(\widehat {f}(s) = \L (f)(s) := \int _0^\infty e^{-st} f(t) \dt \).
</p>

<p>
Die Laplace-Transformierte \(\widehat {f} = \L (f)\) ist auf \(\{s \in \complex \;|\; \Re (s) &gt; \sigma \}\) analytisch. Oft kann man die Laplace-Transformierte aber auf viel gro&#x0308;ßere Bereiche von
\(\complex \) analytisch fortsetzen.
</p>

<p>
Die Abbildung \(\L \colon f \mapsto \widehat {f} = \L (f)\) ist linear und injektiv (d.&#x202f;h. aus \(\L (f) = \L (g)\) folgt \(f = g\)).
</p>

<p>
<b>Eigenschaften der <span class="textsc" >Laplace</span>-Transformation</b>: Sei \(\widehat {f} = \L (f)\). Dann gilt
</p>
<ul style="list-style-type:none">

<li class="list-item-f25"><p>\(\L (f’)(s) = s \widehat {f}(s) - f(0)\),
</p>
</li>
<li class="list-item-f26"><p>\(\L (\int _0^t f(\tau )\d \tau )(s) = \frac {1}{s} \widehat {f}(s)\) und
</p>
</li>
<li class="list-item-f27"><p>\(\L (e^{-pt} f(t))(s) = \widehat {f}(s + p)\).
</p>
</li>
</ul>

<p>
<b>Beispiel</b>: Durch iterative Anwendung erha&#x0308;lt man bspw. \(\L (\frac {1}{(m-1)!} t^{m-1} e^{-pt})(s) = \frac {1}{(s + p)^m}\).
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b>Berechnung von Ausga&#x0308;ngen mit der <span class="textsc" >Laplace</span>-Transformation</b>: Wenn man die Laplace-Transformation auf beiden Seiten von \(\dot {x} = Ax + Bu\), \(y = Cx + Du\)
anwendet, erha&#x0308;lt man \(s \widehat {x}(s) - x(0) = A\widehat {x}(s) + B\widehat {u}(s)\), \(\widehat {y}(s) = C\widehat {x}(s) + D\widehat {u}(s)\). Es treten keine Ableitungen mehr auf, sodass
man algebraisch nach \(\widehat {x}(s)\) auflo&#x0308;sen kann: \(\widehat {x}(s) = (sI - A)^{-1} \xi + (sI - A)^{-1} B \widehat {u}(s)\), \(\widehat {y}(s) = C (sI - A)^{-1} \xi + [C (sI - A)^{-1} B
+ D] \widehat {u}(s)\).
</p>

<p>
Man nennt diese Formel die sog. <em><span class="dashuline" >frequenzbasierte Darstellung (frequency-domain analogue)</span></em> der zeitbasierten Lo&#x0308;sungsformeln fu&#x0308;r \(x(t)\) und \(y(t)\). Das
Faltungsintegral in der zeitbasierten Darstellung ist durch eine simple Multiplikation in der frequenzbasierten Darstellung ersetzt worden. Mit der inversen Laplace-Transformation kann man oft \(x(t)\) und \(y(t)\) berechnen.
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b>U&#x0308;bertragungsmatrix</b>: Die Matrix \(G(s) := C(sI - A)^{-1} B + D\) mit \(s \in \complex \) heißt <em><span class="dashuline" >U&#x0308;bertragungsmatrix (transfer matrix)</span></em> des
Systems \(\dot {x} = Ax + Bu\), \(y = Cx + Du\).
</p>

<p>
Wenn \(s \in \complex \) kein Eigenwert von \(A\) ist, so kann man \(G(s)\) berechnen.
</p>

<p>
Die Eintra&#x0308;ge von \((sI - A)^{-1}\) sind rationale Funktionen, da \((sI - A)^{-1} = \frac {1}{\det (sI - A)} \operatorname {adj}(sI - A)\) nach der Cramerschen Regel mit der Adjunkten \(\operatorname
{adj}(sI - A)\). Die Eintra&#x0308;ge von \((sI - A)^{-1}\) ko&#x0308;nnen daher als \(\frac {n_{ij}(s)}{\chi _A(s)}\) geschrieben werden, wobei \(n_{ij}(s)\) Polynome vom Grad \(&lt; n\) sind und \(\chi
_A(s) = \det (sI - A)\) ein Polynom vom Grad \(n\) ist, denn bei Bildung der Adjunkten sind die Eintra&#x0308;ge bis auf das Vorzeichen gleich Determinaten von Komatrizen, die entstehen, wenn man aus \(sI - A\) jeweils
eine Zeile und eine Spalte entfernt.
</p>

<p>
<b>(echt) proper</b>: Eine rationale Funktion heißt <em><span class="dashuline" >(echt) proper ((strictly) proper)</span></em>,<br />
falls der Za&#x0308;hlergrad echt kleiner als der bzw. kleiner/gleich dem Nennergrad ist.
</p>

<p>
Die Elemente von \((sI - A)^{-1}\) und von \(C(sI - A)^{-1} B\) sind echt propere rationale Funktionen. Die Eintra&#x0308;ge von \(G(s)\) sind Linearkombinationen von denen von \((sI - A)^{-1}\) plus eine konstante
Matrix \(D\), d.&#x202f;h. im Allgemeinen nur noch propere Funktionen.
</p>

<p>
<b>Polstellen</b>: Jeder Eintrag von \(G(s)\) wird in der Form \(\frac {n_{ij}(s)}{d_{ij}(s)}\) geschrieben, wobei die Za&#x0308;hler- und Nennerpolynome keine gemeinsamen Nullstellen besitzen. Die <em><span
class="dashuline" >Polstellen</span></em> von \(G(s)\) sind dann definiert als \(\{s \in \complex \;|\; \exists _{i, j}\; d_{ij}(s) = 0\}\).
</p>

<p>
<b>stabil</b>: \(G(s)\) heißt <em><span class="dashuline" >stabil</span></em>, wenn jede Polstelle von \(G(s)\) einen negativen Realteil besitzt.
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
Die U&#x0308;bertragungsmatrix bringt den meisten Nutzen, wenn der Anfangswert \(\xi \) gleich Null ist. In diesem Fall ist mit \(\widehat {y}(s) = G(s) \widehat {u}(s)\) der Ausgang durch den Eingang \(u(\cdot )\)
bestimmt.
</p>

<p>
Sind zwei Systeme \(\dot {x}_1 = A_1 x_1 + B_1 u_1\), \(y_1 = C_1 x_1 + D_1 u_1\), \(x_1(0) = 0\), und<br />
\(\dot {x}_2 = A_2 x_2 + B_2 u_2\), \(y_2 = C_2 x_2 + D_2 u_2\), \(x_2(0) = 0\), gegeben, so lauten die U&#x0308;bertragungsmatrizen \(G_1(s) = C_1 (sI - A_1)^{-1} B_1 + D_1\) bzw. \(G_2(s) = C_2 (sI -
A_2)^{-1} B_2 + D_2\)<br />
(damit gilt \(\widehat {y}_1(s) = G_1(s) \widehat {u}_1(s)\) bzw. \(\widehat {y}_2(s) = G_2(s) \widehat {u}_2(s)\)).
</p>

<p>
<b>Reihenschaltung</b>: Bei einer Reihenschaltung erha&#x0308;lt man als U&#x0308;bertragungsmatrix das Produkt der U&#x0308;bertragungsmatrizen durch \(\widehat {y}(s) = (G_2(s) G_1(s)) \cdot \widehat
{u}(s)\) (zuerst System \(1\), dann System \(2\)).
</p>

<p>
<b>Parallelschaltung</b>: Bei einer Parallelschaltung erha&#x0308;lt man als U&#x0308;bertragungsmatrix die Summe der U&#x0308;bertragungsmatrizen durch \(\widehat {y}(s) = (G_1(s) + G_2(s)) \cdot \widehat
{u}(s)\).
</p>

<p>
<b>stationa&#x0308;re Antworten</b>: Wenn \(A\) eine Hurwitz-Matrix und \(\lambda = \sigma + \iu \omega \in \complex \) kein Eigenwert von \(A\) ist, dann sind die stationa&#x0308;ren Antworten gegeben durch
</p>
<ul style="list-style-type:none">

<li class="list-item-f28"><p>\(G(0) u_e\) fu&#x0308;r den konstanten Eingang \(u(t) \equiv u_e\),
</p>
</li>
<li class="list-item-f29"><p>\(G(\iu \omega ) u_e e^{\iu \omega t}\) fu&#x0308;r den sinusfo&#x0308;rmigen Eingang \(u(t) = u_e e^{\iu \omega t}\) und
</p>
</li>
<li class="list-item-f30"><p>\(G(\lambda ) u_e e^{\lambda t}\) fu&#x0308;r den exponentiell gewichteten, sinusfo&#x0308;rmigen Eingang \(u(t) = u_e e^{\lambda t}\).
</p>
</li>
</ul>

<p>
Der erste und der zweite Fall sind im dritten als Spezialfall enthalten (fu&#x0308;r \(\lambda = 0\) bzw. \(\lambda = \iu \omega \)).
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
Ein System in Zustandsraum-Darstellung bestimmt seine U&#x0308;bertragungsmatrix durch direktes Ausrechnen. Man kann sich jedoch auch eine umgekehrte Fragestellung u&#x0308;berlegen.
</p>

<p>
<b>Realisierungsproblem</b>: Fu&#x0308;r \(s \in \complex \) sei eine Matrix \(G(s) \in \real ^{k \times m}\) gegeben, deren Eintra&#x0308;ge proper-rationale Funktionen in \(s\) sind. Gibt es Matrizen \(A \in
\real ^{n \times n}\), \(B \in \real ^{n \times m}\), \(C \in \real ^{k \times n}\) und \(D \in \real ^{k \times m}\), sodass \(G(s) = C(sI - A)^{-1} B + D\) (<em><span class="dashuline"
>Realisierungsproblem (realization problem)</span></em>)?
</p>

<p>
<b>Realisierung</b>: Falls fu&#x0308;r die gegebene Funktion \(G(s)\) gilt, dass \(G(s) = C(sI - A)^{-1} B + D\), dann heißt \((A, B, C, D)\) <em><span class="dashuline" >(Zustandsraum-)Realisierung ((state-space)
realization)</span></em> von \(G(s)\).
</p>

<p>
<b>Invarianz der U&#x0308;bertragungsmatrix unter Koordinatentransformation</b>:<br />
Eine Realisierung von \(G(s)\) ist nie eindeutig. Ein Grund unter vielen ist, dass ein Zustandsraum-Koordinatenwechsel zwar die beschreibenden Matrizen eines Zustandsraum-Systems vera&#x0308;ndert, aber nicht die
U&#x0308;bertragungsmatrix:<br />
Seien \(\dot {x} = Ax + Bu\), \(y = Cx + Du\) das System und \(z = Tx\) mit \(T\) invertierbar der Koordinatenwechsel. Es gilt \(\dot {z} = T\dot {x} = TAx + TBu = (TAT^{-1})z + TBu = \widetilde {A}z +
\widetilde {B}u\) mit \(\widetilde {A} := TAT^{-1}\) und \(\widetilde {B} := TB\). Analog ist \(y = CT^{-1}z + Du = \widetilde {C}z + \widetilde {D}u\) mit \(\widetilde {C} := CT^{-1}\) und
\(\widetilde {D} := D\). Die U&#x0308;bertragungsmatrix berechnet sich durch \(\widetilde {G}(s) = \widetilde {C} (sI - \widetilde {A})^{-1} \widetilde {B} + \widetilde {D} = CT^{-1} (sI -
TAT^{-1})^{-1} TB + D\)<br />
\(= C (T^{-1} (sI - TAT^{-1}) T)^{-1} B + D = C (sI - A) B + D = G(s)\), d.&#x202f;h. sie bleibt invariant unter dem Koordinatenwechsel.
</p>

{% endraw %}
</div>
{:/nomarkdown}
