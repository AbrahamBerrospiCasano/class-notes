
{::nomarkdown}
<div class="lwarp-contents">
{% raw %}
<div class="hidden" >

\(\newcommand{\footnotename}{footnote}\)

\(\def \LWRfootnote {1}\)

\(\newcommand {\footnote }[2][\LWRfootnote ]{{}^{\mathrm {#1}}}\)

\(\newcommand {\footnotemark }[1][\LWRfootnote ]{{}^{\mathrm {#1}}}\)

\(\newcommand \ensuremath [1]{#1}\)

\(\newcommand {\LWRframebox }[2][]{\fbox {#2}} \newcommand {\framebox }[1][]{\LWRframebox } \)

\(\newcommand {\setlength }[2]{}\)

\(\newcommand {\addtolength }[2]{}\)

\(\newcommand {\setcounter }[2]{}\)

\(\newcommand {\addtocounter }[2]{}\)

\(\newcommand {\cline }[1]{}\)

\(\newcommand {\directlua }[1]{\text {(directlua)}}\)

\(\newcommand {\luatexdirectlua }[1]{\text {(directlua)}}\)

\(\newcommand {\protect }{}\)

\(\def \LWRabsorbnumber #1 {}\)

\(\def \LWRabsorbquotenumber &quot;#1 {}\)

\(\def \mathchar {\ifnextchar &quot;\LWRabsorbquotenumber \LWRabsorbnumber }\)

\(\def \mathcode #1={\mathchar }\)

\(\let \delcode \mathcode \)

\(\let \delimiter \mathchar \)

\(\let \LWRref \ref \)

\(\renewcommand {\ref }{\ifstar \LWRref \LWRref }\)

\(\newcommand {\intertext }[1]{\text {#1}\notag \\}\)

\(\newcommand {\mathllap }[2][]{{#1#2}}\)

\(\newcommand {\mathrlap }[2][]{{#1#2}}\)

\(\newcommand {\mathclap }[2][]{{#1#2}}\)

\(\newcommand {\mathmbox }[1]{#1}\)

\(\newcommand {\clap }[1]{#1}\)

\(\newcommand {\LWRmathmakebox }[2][]{#2}\)

\(\newcommand {\mathmakebox }[1][]{\LWRmathmakebox }\)

\(\newcommand {\cramped }[2][]{{#1#2}}\)

\(\newcommand {\crampedllap }[2][]{{#1#2}}\)

\(\newcommand {\crampedrlap }[2][]{{#1#2}}\)

\(\newcommand {\crampedclap }[2][]{{#1#2}}\)

\(\newenvironment {crampedsubarray}[1]{}{}\)

\(\newcommand {\crampedsubstack }{}\)

\(\newcommand {\smashoperator }[2][]{#2\limits }\)

\(\newcommand {\adjustlimits }{}\)

\(\newcommand {\SwapAboveDisplaySkip }{}\)

\(\require {extpfeil}\)

\(\Newextarrow \xleftrightarrow {10,10}{0x2194}\)

\(\Newextarrow \xLeftarrow {10,10}{0x21d0}\)

\(\Newextarrow \xhookleftarrow {10,10}{0x21a9}\)

\(\Newextarrow \xmapsto {10,10}{0x21a6}\)

\(\Newextarrow \xRightarrow {10,10}{0x21d2}\)

\(\Newextarrow \xLeftrightarrow {10,10}{0x21d4}\)

\(\Newextarrow \xhookrightarrow {10,10}{0x21aa}\)

\(\Newextarrow \xrightharpoondown {10,10}{0x21c1}\)

\(\Newextarrow \xleftharpoondown {10,10}{0x21bd}\)

\(\Newextarrow \xrightleftharpoons {10,10}{0x21cc}\)

\(\Newextarrow \xrightharpoonup {10,10}{0x21c0}\)

\(\Newextarrow \xleftharpoonup {10,10}{0x21bc}\)

\(\Newextarrow \xleftrightharpoons {10,10}{0x21cb}\)

\(\newcommand {\LWRdounderbracket }[3]{\underset {#3}{\underline {#1}}}\)

\(\newcommand {\LWRunderbracket }[2][]{\LWRdounderbracket {#2}}\)

\(\newcommand {\underbracket }[1][]{\LWRunderbracket }\)

\(\newcommand {\LWRdooverbracket }[3]{\overset {#3}{\overline {#1}}}\)

\(\newcommand {\LWRoverbracket }[2][]{\LWRdooverbracket {#2}}\)

\(\newcommand {\overbracket }[1][]{\LWRoverbracket }\)

\(\newcommand {\LaTeXunderbrace }[1]{\underbrace {#1}}\)

\(\newcommand {\LaTeXoverbrace }[1]{\overbrace {#1}}\)

\(\newenvironment {matrix*}[1][]{\begin {matrix}}{\end {matrix}}\)

\(\newenvironment {pmatrix*}[1][]{\begin {pmatrix}}{\end {pmatrix}}\)

\(\newenvironment {bmatrix*}[1][]{\begin {bmatrix}}{\end {bmatrix}}\)

\(\newenvironment {Bmatrix*}[1][]{\begin {Bmatrix}}{\end {Bmatrix}}\)

\(\newenvironment {vmatrix*}[1][]{\begin {vmatrix}}{\end {vmatrix}}\)

\(\newenvironment {Vmatrix*}[1][]{\begin {Vmatrix}}{\end {Vmatrix}}\)

\(\newenvironment {smallmatrix*}[1][]{\begin {matrix}}{\end {matrix}}\)

\(\newenvironment {psmallmatrix*}[1][]{\begin {pmatrix}}{\end {pmatrix}}\)

\(\newenvironment {bsmallmatrix*}[1][]{\begin {bmatrix}}{\end {bmatrix}}\)

\(\newenvironment {Bsmallmatrix*}[1][]{\begin {Bmatrix}}{\end {Bmatrix}}\)

\(\newenvironment {vsmallmatrix*}[1][]{\begin {vmatrix}}{\end {vmatrix}}\)

\(\newenvironment {Vsmallmatrix*}[1][]{\begin {Vmatrix}}{\end {Vmatrix}}\)

\(\newenvironment {psmallmatrix}[1][]{\begin {pmatrix}}{\end {pmatrix}}\)

\(\newenvironment {bsmallmatrix}[1][]{\begin {bmatrix}}{\end {bmatrix}}\)

\(\newenvironment {Bsmallmatrix}[1][]{\begin {Bmatrix}}{\end {Bmatrix}}\)

\(\newenvironment {vsmallmatrix}[1][]{\begin {vmatrix}}{\end {vmatrix}}\)

\(\newenvironment {Vsmallmatrix}[1][]{\begin {Vmatrix}}{\end {Vmatrix}}\)

\(\newcommand {\LWRmultlined }[1][]{\begin {multline*}}\)

\(\newenvironment {multlined}[1][]{\LWRmultlined }{\end {multline*}}\)

\(\let \LWRorigshoveleft \shoveleft \)

\(\renewcommand {\shoveleft }[1][]{\LWRorigshoveleft }\)

\(\let \LWRorigshoveright \shoveright \)

\(\renewcommand {\shoveright }[1][]{\LWRorigshoveright }\)

\(\newenvironment {dcases}{\begin {cases}}{\end {cases}}\)

\(\newenvironment {dcases*}{\begin {cases}}{\end {cases}}\)

\(\newenvironment {rcases}{\begin {cases}}{\end {cases}}\)

\(\newenvironment {rcases*}{\begin {cases}}{\end {cases}}\)

\(\newenvironment {drcases}{\begin {cases}}{\end {cases}}\)

\(\newenvironment {drcases*}{\begin {cases}}{\end {cases}}\)

\(\newenvironment {cases*}{\begin {cases}}{\end {cases}}\)

\(\newcommand {\MoveEqLeft }[1][]{}\)

\(\def \LWRAboxed #1&amp;#2&amp;#3!|!{\fbox {\(#1\)}&amp;\fbox {\(#2\)}} \newcommand {\Aboxed }[1]{\LWRAboxed #1&amp;&amp;!|!} \)

\( \newcommand {\LWRABLines }[1][\Updownarrow ]{#1 \notag \\}\newcommand {\ArrowBetweenLines }{\ifstar \LWRABLines \LWRABLines } \)

\(\newcommand {\shortintertext }[1]{\text {#1}\notag \\}\)

\(\newcommand {\vdotswithin }[1]{\hspace {.5em}\vdots }\)

\(\newcommand {\LWRshortvdotswithinstar }[1]{\vdots \hspace {.5em} &amp; \\}\)

\(\newcommand {\LWRshortvdotswithinnostar }[1]{&amp; \hspace {.5em}\vdots \\}\)

\(\newcommand {\shortvdotswithin }{\ifstar \LWRshortvdotswithinstar \LWRshortvdotswithinnostar }\)

\(\newcommand {\MTFlushSpaceAbove }{}\)

\(\newcommand {\MTFlushSpaceBelow }{\\}\)

\(\newcommand \lparen {(}\)

\(\newcommand \rparen {)}\)

\(\newcommand {\ordinarycolon }{:}\)

\(\newcommand {\vcentcolon }{\mathrel {\mathop \ordinarycolon }}\)

\(\newcommand \dblcolon {\vcentcolon \vcentcolon }\)

\(\newcommand \coloneqq {\vcentcolon =}\)

\(\newcommand \Coloneqq {\dblcolon =}\)

\(\newcommand \coloneq {\vcentcolon {-}}\)

\(\newcommand \Coloneq {\dblcolon {-}}\)

\(\newcommand \eqqcolon {=\vcentcolon }\)

\(\newcommand \Eqqcolon {=\dblcolon }\)

\(\newcommand \eqcolon {\mathrel {-}\vcentcolon }\)

\(\newcommand \Eqcolon {\mathrel {-}\dblcolon }\)

\(\newcommand \colonapprox {\vcentcolon \approx }\)

\(\newcommand \Colonapprox {\dblcolon \approx }\)

\(\newcommand \colonsim {\vcentcolon \sim }\)

\(\newcommand \Colonsim {\dblcolon \sim }\)

\(\newcommand {\nuparrow }{\mathrel {\cancel {\uparrow }}}\)

\(\newcommand {\ndownarrow }{\mathrel {\cancel {\downarrow }}}\)

\(\newcommand {\bigtimes }{\mathop {\Large \times }\limits }\)

\(\newcommand {\prescript }[3]{{}^{#1}_{#2}#3}\)

\(\newenvironment {lgathered}{\begin {gathered}}{\end {gathered}}\)

\(\newenvironment {rgathered}{\begin {gathered}}{\end {gathered}}\)

\(\newcommand {\splitfrac }[2]{{}^{#1}_{#2}}\)

\(\let \splitdfrac \splitfrac \)

\(\newcommand {\LWRoverlaysymbols }[2]{\mathord {\smash {\mathop {#2\strut }\limits ^{\smash {\lower 3ex{#1}}}}\strut }}\)

\(\newcommand{\alphaup}{\unicode{x03B1}}\)

\(\newcommand{\betaup}{\unicode{x03B2}}\)

\(\newcommand{\gammaup}{\unicode{x03B3}}\)

\(\newcommand{\digammaup}{\unicode{x03DD}}\)

\(\newcommand{\deltaup}{\unicode{x03B4}}\)

\(\newcommand{\epsilonup}{\unicode{x03F5}}\)

\(\newcommand{\varepsilonup}{\unicode{x03B5}}\)

\(\newcommand{\zetaup}{\unicode{x03B6}}\)

\(\newcommand{\etaup}{\unicode{x03B7}}\)

\(\newcommand{\thetaup}{\unicode{x03B8}}\)

\(\newcommand{\varthetaup}{\unicode{x03D1}}\)

\(\newcommand{\iotaup}{\unicode{x03B9}}\)

\(\newcommand{\kappaup}{\unicode{x03BA}}\)

\(\newcommand{\varkappaup}{\unicode{x03F0}}\)

\(\newcommand{\lambdaup}{\unicode{x03BB}}\)

\(\newcommand{\muup}{\unicode{x03BC}}\)

\(\newcommand{\nuup}{\unicode{x03BD}}\)

\(\newcommand{\xiup}{\unicode{x03BE}}\)

\(\newcommand{\omicronup}{\unicode{x03BF}}\)

\(\newcommand{\piup}{\unicode{x03C0}}\)

\(\newcommand{\varpiup}{\unicode{x03D6}}\)

\(\newcommand{\rhoup}{\unicode{x03C1}}\)

\(\newcommand{\varrhoup}{\unicode{x03F1}}\)

\(\newcommand{\sigmaup}{\unicode{x03C3}}\)

\(\newcommand{\varsigmaup}{\unicode{x03C2}}\)

\(\newcommand{\tauup}{\unicode{x03C4}}\)

\(\newcommand{\upsilonup}{\unicode{x03C5}}\)

\(\newcommand{\phiup}{\unicode{x03D5}}\)

\(\newcommand{\varphiup}{\unicode{x03C6}}\)

\(\newcommand{\chiup}{\unicode{x03C7}}\)

\(\newcommand{\psiup}{\unicode{x03C8}}\)

\(\newcommand{\omegaup}{\unicode{x03C9}}\)

\(\newcommand{\Alphaup}{\unicode{x0391}}\)

\(\newcommand{\Betaup}{\unicode{x0392}}\)

\(\newcommand{\Gammaup}{\unicode{x0393}}\)

\(\newcommand{\Digammaup}{\unicode{x03DC}}\)

\(\newcommand{\Deltaup}{\unicode{x0394}}\)

\(\newcommand{\Epsilonup}{\unicode{x0395}}\)

\(\newcommand{\Zetaup}{\unicode{x0396}}\)

\(\newcommand{\Etaup}{\unicode{x0397}}\)

\(\newcommand{\Thetaup}{\unicode{x0398}}\)

\(\newcommand{\Varthetaup}{\unicode{x03F4}}\)

\(\newcommand{\Iotaup}{\unicode{x0399}}\)

\(\newcommand{\Kappaup}{\unicode{x039A}}\)

\(\newcommand{\Lambdaup}{\unicode{x039B}}\)

\(\newcommand{\Muup}{\unicode{x039C}}\)

\(\newcommand{\Nuup}{\unicode{x039D}}\)

\(\newcommand{\Xiup}{\unicode{x039E}}\)

\(\newcommand{\Omicronup}{\unicode{x039F}}\)

\(\newcommand{\Piup}{\unicode{x03A0}}\)

\(\newcommand{\Varpiup}{\unicode{x03D6}}\)

\(\newcommand{\Rhoup}{\unicode{x03A1}}\)

\(\newcommand{\Sigmaup}{\unicode{x03A3}}\)

\(\newcommand{\Tauup}{\unicode{x03A4}}\)

\(\newcommand{\Upsilonup}{\unicode{x03A5}}\)

\(\newcommand{\Phiup}{\unicode{x03A6}}\)

\(\newcommand{\Chiup}{\unicode{x03A7}}\)

\(\newcommand{\Psiup}{\unicode{x03A8}}\)

\(\newcommand{\Omegaup}{\unicode{x03A9}}\)

\(\newcommand{\alphait}{\unicode{x1D6FC}}\)

\(\newcommand{\betait}{\unicode{x1D6FD}}\)

\(\newcommand{\gammait}{\unicode{x1D6FE}}\)

\(\newcommand{\digammait}{\mathit{\unicode{x03DD}}}\)

\(\newcommand{\deltait}{\unicode{x1D6FF}}\)

\(\newcommand{\epsilonit}{\unicode{x1D716}}\)

\(\newcommand{\varepsilonit}{\unicode{x1D700}}\)

\(\newcommand{\zetait}{\unicode{x1D701}}\)

\(\newcommand{\etait}{\unicode{x1D702}}\)

\(\newcommand{\thetait}{\unicode{x1D703}}\)

\(\newcommand{\varthetait}{\unicode{x1D717}}\)

\(\newcommand{\iotait}{\unicode{x1D704}}\)

\(\newcommand{\kappait}{\unicode{x1D705}}\)

\(\newcommand{\varkappait}{\unicode{x1D718}}\)

\(\newcommand{\lambdait}{\unicode{x1D706}}\)

\(\newcommand{\muit}{\unicode{x1D707}}\)

\(\newcommand{\nuit}{\unicode{x1D708}}\)

\(\newcommand{\xiit}{\unicode{x1D709}}\)

\(\newcommand{\omicronit}{\unicode{x1D70A}}\)

\(\newcommand{\piit}{\unicode{x1D70B}}\)

\(\newcommand{\varpiit}{\unicode{x1D71B}}\)

\(\newcommand{\rhoit}{\unicode{x1D70C}}\)

\(\newcommand{\varrhoit}{\unicode{x1D71A}}\)

\(\newcommand{\sigmait}{\unicode{x1D70E}}\)

\(\newcommand{\varsigmait}{\unicode{x1D70D}}\)

\(\newcommand{\tauit}{\unicode{x1D70F}}\)

\(\newcommand{\upsilonit}{\unicode{x1D710}}\)

\(\newcommand{\phiit}{\unicode{x1D719}}\)

\(\newcommand{\varphiit}{\unicode{x1D711}}\)

\(\newcommand{\chiit}{\unicode{x1D712}}\)

\(\newcommand{\psiit}{\unicode{x1D713}}\)

\(\newcommand{\omegait}{\unicode{x1D714}}\)

\(\newcommand{\Alphait}{\unicode{x1D6E2}}\)

\(\newcommand{\Betait}{\unicode{x1D6E3}}\)

\(\newcommand{\Gammait}{\unicode{x1D6E4}}\)

\(\newcommand{\Digammait}{\mathit{\unicode{x03DC}}}\)

\(\newcommand{\Deltait}{\unicode{x1D6E5}}\)

\(\newcommand{\Epsilonit}{\unicode{x1D6E6}}\)

\(\newcommand{\Zetait}{\unicode{x1D6E7}}\)

\(\newcommand{\Etait}{\unicode{x1D6E8}}\)

\(\newcommand{\Thetait}{\unicode{x1D6E9}}\)

\(\newcommand{\Varthetait}{\unicode{x1D6F3}}\)

\(\newcommand{\Iotait}{\unicode{x1D6EA}}\)

\(\newcommand{\Kappait}{\unicode{x1D6EB}}\)

\(\newcommand{\Lambdait}{\unicode{x1D6EC}}\)

\(\newcommand{\Muit}{\unicode{x1D6ED}}\)

\(\newcommand{\Nuit}{\unicode{x1D6EE}}\)

\(\newcommand{\Xiit}{\unicode{x1D6EF}}\)

\(\newcommand{\Omicronit}{\unicode{x1D6F0}}\)

\(\newcommand{\Piit}{\unicode{x1D6F1}}\)

\(\newcommand{\Rhoit}{\unicode{x1D6F2}}\)

\(\newcommand{\Sigmait}{\unicode{x1D6F4}}\)

\(\newcommand{\Tauit}{\unicode{x1D6F5}}\)

\(\newcommand{\Upsilonit}{\unicode{x1D6F6}}\)

\(\newcommand{\Phiit}{\unicode{x1D6F7}}\)

\(\newcommand{\Chiit}{\unicode{x1D6F8}}\)

\(\newcommand{\Psiit}{\unicode{x1D6F9}}\)

\(\newcommand{\Omegait}{\unicode{x1D6FA}}\)

\(\let \digammaup \Digammaup \)

\(\renewcommand {\digammait }{\mathit {\digammaup }}\)

\(\newcommand {\smallin }{\unicode {x220A}}\)

\(\newcommand {\smallowns }{\unicode {x220D}}\)

\(\newcommand {\notsmallin }{\LWRoverlaysymbols {/}{\unicode {x220A}}}\)

\(\newcommand {\notsmallowns }{\LWRoverlaysymbols {/}{\unicode {x220D}}}\)

\(\newcommand {\rightangle }{\unicode {x221F}}\)

\(\newcommand {\intclockwise }{\unicode {x2231}}\)

\(\newcommand {\ointclockwise }{\unicode {x2232}}\)

\(\newcommand {\ointctrclockwise }{\unicode {x2233}}\)

\(\newcommand {\oiint }{\unicode {x222F}}\)

\(\newcommand {\oiiint }{\unicode {x2230}}\)

\(\newcommand {\ddag }{\unicode {x2021}}\)

\(\newcommand {\P }{\unicode {x00B6}}\)

\(\newcommand {\copyright }{\unicode {x00A9}}\)

\(\newcommand {\dag }{\unicode {x2020}}\)

\(\newcommand {\pounds }{\unicode {x00A3}}\)

\(\newcommand {\iddots }{\unicode {x22F0}}\)

\(\newcommand {\utimes }{\overline {\times }}\)

\(\newcommand {\dtimes }{\underline {\times }}\)

\(\newcommand {\udtimes }{\overline {\underline {\times }}}\)

\(\newcommand {\leftwave }{\left \{}\)

\(\newcommand {\rightwave }{\right \}}\)

\(\newcommand {\toprule }[1][]{\hline }\)

\(\let \midrule \toprule \)

\(\let \bottomrule \toprule \)

\(\newcommand {\cmidrule }[2][]{}\)

\(\newcommand {\morecmidrules }{}\)

\(\newcommand {\specialrule }[3]{\hline }\)

\(\newcommand {\addlinespace }[1][]{}\)

\(\newcommand {\LWRsubmultirow }[2][]{#2}\)

\(\newcommand {\LWRmultirow }[2][]{\LWRsubmultirow }\)

\(\newcommand {\multirow }[2][]{\LWRmultirow }\)

\(\newcommand {\mrowcell }{}\)

\(\newcommand {\mcolrowcell }{}\)

\(\newcommand {\STneed }[1]{}\)

\( \newcommand {\multicolumn }[3]{#3}\)

\(\newcommand {\tothe }[1]{^{#1}}\)

\(\newcommand {\raiseto }[2]{{#2}^{#1}}\)

\(\newcommand {\ang }[2][]{(\mathrm {#2})\degree }\)

\(\newcommand {\num }[2][]{\mathrm {#2}}\)

\(\newcommand {\si }[2][]{\mathrm {#2}}\)

\(\newcommand {\LWRSI }[2][]{\mathrm {#1\LWRSInumber \,#2}}\)

\(\newcommand {\SI }[2][]{\def \LWRSInumber {#2}\LWRSI }\)

\(\newcommand {\numlist }[2][]{\mathrm {#2}}\)

\(\newcommand {\numrange }[3][]{\mathrm {#2\,\unicode {x2013}\,#3}}\)

\(\newcommand {\SIlist }[3][]{\mathrm {#2\,#3}}\)

\(\newcommand {\SIrange }[4][]{\mathrm {#2\,#4\,\unicode {x2013}\,#3\,#4}}\)

\(\newcommand {\tablenum }[2][]{\mathrm {#2}}\)

\(\newcommand {\ampere }{\mathrm {A}}\)

\(\newcommand {\candela }{\mathrm {cd}}\)

\(\newcommand {\kelvin }{\mathrm {K}}\)

\(\newcommand {\kilogram }{\mathrm {kg}}\)

\(\newcommand {\metre }{\mathrm {m}}\)

\(\newcommand {\mole }{\mathrm {mol}}\)

\(\newcommand {\second }{\mathrm {s}}\)

\(\newcommand {\becquerel }{\mathrm {Bq}}\)

\(\newcommand {\degreeCelsius }{\unicode {x2103}}\)

\(\newcommand {\coulomb }{\mathrm {C}}\)

\(\newcommand {\farad }{\mathrm {F}}\)

\(\newcommand {\gray }{\mathrm {Gy}}\)

\(\newcommand {\hertz }{\mathrm {Hz}}\)

\(\newcommand {\henry }{\mathrm {H}}\)

\(\newcommand {\joule }{\mathrm {J}}\)

\(\newcommand {\katal }{\mathrm {kat}}\)

\(\newcommand {\lumen }{\mathrm {lm}}\)

\(\newcommand {\lux }{\mathrm {lx}}\)

\(\newcommand {\newton }{\mathrm {N}}\)

\(\newcommand {\ohm }{\mathrm {\Omega }}\)

\(\newcommand {\pascal }{\mathrm {Pa}}\)

\(\newcommand {\radian }{\mathrm {rad}}\)

\(\newcommand {\siemens }{\mathrm {S}}\)

\(\newcommand {\sievert }{\mathrm {Sv}}\)

\(\newcommand {\steradian }{\mathrm {sr}}\)

\(\newcommand {\tesla }{\mathrm {T}}\)

\(\newcommand {\volt }{\mathrm {V}}\)

\(\newcommand {\watt }{\mathrm {W}}\)

\(\newcommand {\weber }{\mathrm {Wb}}\)

\(\newcommand {\day }{\mathrm {d}}\)

\(\newcommand {\degree }{\mathrm {^\circ }}\)

\(\newcommand {\hectare }{\mathrm {ha}}\)

\(\newcommand {\hour }{\mathrm {h}}\)

\(\newcommand {\litre }{\mathrm {l}}\)

\(\newcommand {\liter }{\mathrm {L}}\)

\(\newcommand {\arcminute }{^\prime }\)
\(\newcommand {\minute }{\mathrm {min}}\)

\(\newcommand {\arcsecond }{^{\prime \prime }}\)

\(\newcommand {\tonne }{\mathrm {t}}\)

\(\newcommand {\astronomicalunit }{au}\)

\(\newcommand {\atomicmassunit }{u}\)

\(\newcommand {\bohr }{\mathit {a}_0}\)

\(\newcommand {\clight }{\mathit {c}_0}\)

\(\newcommand {\dalton }{\mathrm {D}_\mathrm {a}}\)

\(\newcommand {\electronmass }{\mathit {m}_{\mathrm {e}}}\)

\(\newcommand {\electronvolt }{\mathrm {eV}}\)

\(\newcommand {\elementarycharge }{\mathit {e}}\)

\(\newcommand {\hartree }{\mathit {E}_{\mathrm {h}}}\)

\(\newcommand {\planckbar }{\mathit {\unicode {x210F}}}\)

\(\newcommand {\angstrom }{\mathrm {\unicode {x212B}}}\)

\(\let \LWRorigbar \bar \)

\(\newcommand {\bar }{\mathrm {bar}}\)

\(\newcommand {\barn }{\mathrm {b}}\)

\(\newcommand {\bel }{\mathrm {B}}\)

\(\newcommand {\decibel }{\mathrm {dB}}\)

\(\newcommand {\knot }{\mathrm {kn}}\)

\(\newcommand {\mmHg }{\mathrm {mmHg}}\)

\(\newcommand {\nauticalmile }{\mathrm {M}}\)

\(\newcommand {\neper }{\mathrm {Np}}\)

\(\newcommand {\yocto }{\mathrm {y}}\)

\(\newcommand {\zepto }{\mathrm {z}}\)

\(\newcommand {\atto }{\mathrm {a}}\)

\(\newcommand {\femto }{\mathrm {f}}\)

\(\newcommand {\pico }{\mathrm {p}}\)

\(\newcommand {\nano }{\mathrm {n}}\)

\(\newcommand {\micro }{\mathrm {\unicode {x00B5}}}\)

\(\newcommand {\milli }{\mathrm {m}}\)

\(\newcommand {\centi }{\mathrm {c}}\)

\(\newcommand {\deci }{\mathrm {d}}\)

\(\newcommand {\deca }{\mathrm {da}}\)

\(\newcommand {\hecto }{\mathrm {h}}\)

\(\newcommand {\kilo }{\mathrm {k}}\)

\(\newcommand {\mega }{\mathrm {M}}\)

\(\newcommand {\giga }{\mathrm {G}}\)

\(\newcommand {\tera }{\mathrm {T}}\)

\(\newcommand {\peta }{\mathrm {P}}\)

\(\newcommand {\exa }{\mathrm {E}}\)

\(\newcommand {\zetta }{\mathrm {Z}}\)

\(\newcommand {\yotta }{\mathrm {Y}}\)

\(\newcommand {\percent }{\mathrm {\%}}\)

\(\newcommand {\meter }{\mathrm {m}}\)

\(\newcommand {\metre }{\mathrm {m}}\)

\(\newcommand {\gram }{\mathrm {g}}\)

\(\newcommand {\kg }{\kilo \gram }\)

\(\newcommand {\of }[1]{_{\mathrm {#1}}}\)

\(\newcommand {\squared }{^2}\)

\(\newcommand {\square }[1]{\mathrm {#1}^2}\)

\(\newcommand {\cubed }{^3}\)

\(\newcommand {\cubic }[1]{\mathrm {#1}^3}\)

\(\newcommand {\per }{/}\)

\(\newcommand {\celsius }{\unicode {x2103}}\)

\(\newcommand {\fg }{\femto \gram }\)

\(\newcommand {\pg }{\pico \gram }\)

\(\newcommand {\ng }{\nano \gram }\)

\(\newcommand {\ug }{\micro \gram }\)

\(\newcommand {\mg }{\milli \gram }\)

\(\newcommand {\g }{\gram }\)

\(\newcommand {\kg }{\kilo \gram }\)

\(\newcommand {\amu }{\mathrm {u}}\)

\(\newcommand {\nm }{\nano \metre }\)

\(\newcommand {\um }{\micro \metre }\)

\(\newcommand {\mm }{\milli \metre }\)

\(\newcommand {\cm }{\centi \metre }\)

\(\newcommand {\dm }{\deci \metre }\)

\(\newcommand {\m }{\metre }\)

\(\newcommand {\km }{\kilo \metre }\)

\(\newcommand {\as }{\atto \second }\)

\(\newcommand {\fs }{\femto \second }\)

\(\newcommand {\ps }{\pico \second }\)

\(\newcommand {\ns }{\nano \second }\)

\(\newcommand {\us }{\micro \second }\)

\(\newcommand {\ms }{\milli \second }\)

\(\newcommand {\s }{\second }\)

\(\newcommand {\fmol }{\femto \mol }\)

\(\newcommand {\pmol }{\pico \mol }\)

\(\newcommand {\nmol }{\nano \mol }\)

\(\newcommand {\umol }{\micro \mol }\)

\(\newcommand {\mmol }{\milli \mol }\)

\(\newcommand {\mol }{\mol }\)

\(\newcommand {\kmol }{\kilo \mol }\)

\(\newcommand {\pA }{\pico \ampere }\)

\(\newcommand {\nA }{\nano \ampere }\)

\(\newcommand {\uA }{\micro \ampere }\)

\(\newcommand {\mA }{\milli \ampere }\)

\(\newcommand {\A }{\ampere }\)

\(\newcommand {\kA }{\kilo \ampere }\)

\(\newcommand {\ul }{\micro \litre }\)

\(\newcommand {\ml }{\milli \litre }\)

\(\newcommand {\l }{\litre }\)

\(\newcommand {\hl }{\hecto \litre }\)

\(\newcommand {\uL }{\micro \liter }\)

\(\newcommand {\mL }{\milli \liter }\)

\(\newcommand {\L }{\liter }\)

\(\newcommand {\hL }{\hecto \liter }\)

\(\newcommand {\mHz }{\milli \hertz }\)

\(\newcommand {\Hz }{\hertz }\)

\(\newcommand {\kHz }{\kilo \hertz }\)

\(\newcommand {\MHz }{\mega \hertz }\)

\(\newcommand {\GHz }{\giga \hertz }\)

\(\newcommand {\THz }{\tera \hertz }\)

\(\newcommand {\mN }{\milli \newton }\)

\(\newcommand {\N }{\newton }\)

\(\newcommand {\kN }{\kilo \newton }\)

\(\newcommand {\MN }{\mega \newton }\)

\(\newcommand {\Pa }{\pascal }\)

\(\newcommand {\kPa }{\kilo \pascal }\)

\(\newcommand {\MPa }{\mega \pascal }\)

\(\newcommand {\GPa }{\giga \pascal }\)

\(\newcommand {\mohm }{\milli \ohm }\)

\(\newcommand {\kohm }{\kilo \ohm }\)

\(\newcommand {\Mohm }{\mega \ohm }\)

\(\newcommand {\pV }{\pico \volt }\)

\(\newcommand {\nV }{\nano \volt }\)

\(\newcommand {\uV }{\micro \volt }\)

\(\newcommand {\mV }{\milli \volt }\)

\(\newcommand {\V }{\volt }\)

\(\newcommand {\kV }{\kilo \volt }\)

\(\newcommand {\W }{\watt }\)

\(\newcommand {\uW }{\micro \watt }\)

\(\newcommand {\mW }{\milli \watt }\)

\(\newcommand {\kW }{\kilo \watt }\)

\(\newcommand {\MW }{\mega \watt }\)

\(\newcommand {\GW }{\giga \watt }\)

\(\newcommand {\J }{\joule }\)

\(\newcommand {\uJ }{\micro \joule }\)

\(\newcommand {\mJ }{\milli \joule }\)

\(\newcommand {\kJ }{\kilo \joule }\)

\(\newcommand {\eV }{\electronvolt }\)

\(\newcommand {\meV }{\milli \electronvolt }\)

\(\newcommand {\keV }{\kilo \electronvolt }\)

\(\newcommand {\MeV }{\mega \electronvolt }\)

\(\newcommand {\GeV }{\giga \electronvolt }\)

\(\newcommand {\TeV }{\tera \electronvolt }\)

\(\newcommand {\kWh }{\kilo \watt \hour }\)

\(\newcommand {\F }{\farad }\)

\(\newcommand {\fF }{\femto \farad }\)

\(\newcommand {\pF }{\pico \farad }\)

\(\newcommand {\K }{\mathrm {K}}\)

\(\newcommand {\dB }{\mathrm {dB}}\)

\(\newcommand {\kibi }{\mathrm {Ki}}\)

\(\newcommand {\mebi }{\mathrm {Mi}}\)

\(\newcommand {\gibi }{\mathrm {Gi}}\)

\(\newcommand {\tebi }{\mathrm {Ti}}\)

\(\newcommand {\pebi }{\mathrm {Pi}}\)

\(\newcommand {\exbi }{\mathrm {Ei}}\)

\(\newcommand {\zebi }{\mathrm {Zi}}\)

\(\newcommand {\yobi }{\mathrm {Yi}}\)

\(\require {mhchem}\)

\(\require {cancel}\)

\(\newcommand {\fint }{âĺŊ}\)

\(\newcommand {\hdots }{\cdots }\)

\(\newcommand {\mathnormal }[1]{#1}\)

\(\newcommand {\vecs }[2]{\vec {#1}_{#2}}\)

\(\newcommand {\EE }{\mathbb {E}}\)

\(\newcommand {\PP }{\mathbb {P}}\)

\(\renewcommand {\C }{\mathcal {C}}\)

\(\renewcommand {\O }{\mathcal {O}}\)

\(\renewcommand {\P }{\mathcal {P}}\)

\(\renewcommand {\S }{\mathcal {S}}\)

\(\renewcommand {\U }{\mathcal {U}}\)

\(\renewcommand {\Cap }{\operatorname {cap}}\)

\(\newcommand {\val }{\operatorname {val}}\)

\(\newcommand {\dcut }{\operatorname {dcut}}\)

\(\newcommand {\opt }{\text {opt}}\)

\(\newcommand {\OPT }{\text {OPT}}\)

\(\newcommand {\OPTLP }{\text {OPT}_\text {LP}}\)

\(\newcommand {\OPTint }{\text {OPT}_\text {int}}\)

\(\newcommand {\OPTprimal }{\text {OPT}_\text {primal}}\)

\(\newcommand {\OPTdual }{\text {OPT}_\text {dual}}\)

\(\newcommand {\code }[1]{\texttt {#1}}\)

\(\newcommand {\name }[1]{\textsc {#1}}\)

\(\newcommand {\smallpmatrix }[1]{\left (\begin {smallmatrix}#1\end {smallmatrix}\right )}\)

\(\newcommand {\matlab }{{\fontfamily {bch}\scshape \selectfont {}Matlab}}\)

\(\newcommand {\innerproduct }[1]{\left \langle {#1}\right \rangle }\)

\(\newcommand {\norm }[1]{\left \Vert {#1}\right \Vert }\)

\(\renewcommand {\natural }{\mathbb {N}}\)

\(\newcommand {\integer }{\mathbb {Z}}\)

\(\newcommand {\rational }{\mathbb {Q}}\)

\(\newcommand {\real }{\mathbb {R}}\)

\(\newcommand {\complex }{\mathbb {C}}\)

\(\renewcommand {\d }{\mathop {}\!\mathrm {d}}\)

\(\newcommand {\dr }{\d {}r}\)

\(\newcommand {\ds }{\d {}s}\)

\(\newcommand {\dt }{\d {}t}\)

\(\newcommand {\du }{\d {}u}\)

\(\newcommand {\dv }{\d {}v}\)

\(\newcommand {\dw }{\d {}w}\)

\(\newcommand {\dx }{\d {}x}\)

\(\newcommand {\dy }{\d {}y}\)

\(\newcommand {\dz }{\d {}z}\)

\(\newcommand {\dsigma }{\d {}\sigma }\)

\(\newcommand {\dphi }{\d {}\phi }\)

\(\newcommand {\dvarphi }{\d {}\varphi }\)

\(\newcommand {\dtau }{\d {}\tau }\)

\(\newcommand {\dxi }{\d {}\xi }\)

\(\newcommand {\dtheta }{\d {}\theta }\)

\(\newcommand {\tp }{\mathrm {T}}\)

</div>

<style type="text/css">
.lwarp-contents li.list-item-f0::marker {
  font-style:italic;
  content:'(1)\00a0\00a0';
}
.lwarp-contents li.list-item-f1::marker {
  font-style:italic;
  content:'(2)\00a0\00a0';
}
.lwarp-contents li.list-item-f2::marker {
  font-style:italic;
  content:'(1)\00a0\00a0';
}
.lwarp-contents li.list-item-f3::marker {
  font-style:italic;
  content:'(2)\00a0\00a0';
}
.lwarp-contents li.list-item-f4::marker {
  font-style:italic;
  content:'(3)\00a0\00a0';
}
.lwarp-contents li.list-item-f5::marker {
  font-style:italic;
  content:'(4)\00a0\00a0';
}
.lwarp-contents li.list-item-f6::marker {
  font-style:italic;
  content:'(3)\00a0\00a0';
}
.lwarp-contents li.list-item-f7::marker {
  content:'•\00a0\00a0';
}
.lwarp-contents li.list-item-f8::marker {
  content:'•\00a0\00a0';
}
.lwarp-contents li.list-item-f9::marker {
  content:'–\00a0\00a0';
}
.lwarp-contents li.list-item-f10::marker {
  content:'–\00a0\00a0';
}
.lwarp-contents li.list-item-f11::marker {
  content:'–\00a0\00a0';
}
.lwarp-contents li.list-item-f12::marker {
  font-style:italic;
  content:'(1)\00a0\00a0';
}
.lwarp-contents li.list-item-f13::marker {
  font-style:italic;
  content:'(2)\00a0\00a0';
}
.lwarp-contents li.list-item-f14::marker {
  font-style:italic;
  content:'(3)\00a0\00a0';
}
.lwarp-contents li.list-item-f15::marker {
  content:'•\00a0\00a0';
}
.lwarp-contents li.list-item-f16::marker {
  content:'•\00a0\00a0';
}
.lwarp-contents li.list-item-f17::marker {
  font-style:italic;
  content:'(1)\00a0\00a0';
}
.lwarp-contents li.list-item-f18::marker {
  font-style:italic;
  content:'(2)\00a0\00a0';
}
.lwarp-contents li.list-item-f19::marker {
  font-style:italic;
  content:'(1)\00a0\00a0';
}
.lwarp-contents li.list-item-f20::marker {
  font-style:italic;
  content:'(2)\00a0\00a0';
}
.lwarp-contents li.list-item-f21::marker {
  font-style:italic;
  content:'(3)\00a0\00a0';
}
.lwarp-contents li.list-item-f22::marker {
  content:'•\00a0\00a0';
}
.lwarp-contents li.list-item-f23::marker {
  content:'•\00a0\00a0';
}
.lwarp-contents li.list-item-f24::marker {
  content:'•\00a0\00a0';
}
.lwarp-contents li.list-item-f25::marker {
  content:'•\00a0\00a0';
}
.lwarp-contents li.list-item-f26::marker {
  content:'•\00a0\00a0';
}
.lwarp-contents li.list-item-f27::marker {
  font-style:italic;
  content:'(1)\00a0\00a0';
}
.lwarp-contents li.list-item-f28::marker {
  font-style:italic;
  content:'(2)\00a0\00a0';
}
.lwarp-contents li.list-item-f29::marker {
  font-style:italic;
  content:'(3)\00a0\00a0';
}
.lwarp-contents li.list-item-f30::marker {
  font-style:italic;
  content:'(1)\00a0\00a0';
}
.lwarp-contents li.list-item-f31::marker {
  font-style:italic;
  content:'(2)\00a0\00a0';
}
.lwarp-contents li.list-item-f32::marker {
  font-style:italic;
  content:'(3)\00a0\00a0';
}
.lwarp-contents li.list-item-f33::marker {
  font-style:italic;
  content:'(4)\00a0\00a0';
}
.lwarp-contents li.list-item-f34::marker {
  font-style:italic;
  content:'(1)\00a0\00a0';
}
.lwarp-contents li.list-item-f35::marker {
  font-style:italic;
  content:'(2)\00a0\00a0';
}
.lwarp-contents li.list-item-f36::marker {
  font-style:italic;
  content:'(3)\00a0\00a0';
}
.lwarp-contents li.list-item-f37::marker {
  font-style:italic;
  content:'(1)\00a0\00a0';
}
.lwarp-contents li.list-item-f38::marker {
  font-style:italic;
  content:'(2)\00a0\00a0';
}
.lwarp-contents li.list-item-f39::marker {
  font-style:italic;
  content:'(3)\00a0\00a0';
}
.lwarp-contents li.list-item-f40::marker {
  font-style:italic;
  content:'(4)\00a0\00a0';
}
.lwarp-contents li.list-item-f41::marker {
  content:'•\00a0\00a0';
}
.lwarp-contents li.list-item-f42::marker {
  content:'•\00a0\00a0';
}
.lwarp-contents li.list-item-f43::marker {
  font-style:italic;
  content:'(1)\00a0\00a0';
}
.lwarp-contents li.list-item-f44::marker {
  font-style:italic;
  content:'(2)\00a0\00a0';
}
.lwarp-contents li.list-item-f45::marker {
  font-style:italic;
  content:'(1)\00a0\00a0';
}
.lwarp-contents li.list-item-f46::marker {
  font-style:italic;
  content:'(2)\00a0\00a0';
}
.lwarp-contents li.list-item-f47::marker {
  font-style:italic;
  content:'(3)\00a0\00a0';
}
.lwarp-contents li.list-item-f48::marker {
  font-style:italic;
  content:'(3)\00a0\00a0';
}
.lwarp-contents li.list-item-f49::marker {
  font-style:italic;
  content:'(4)\00a0\00a0';
}
.lwarp-contents li.list-item-f50::marker {
  font-style:italic;
  content:'(1)\00a0\00a0';
}
</style>
<p>

</p>


<p>
Im Folgenden werden Polynomialzeit-Algorithmen behandelt, die Approximationen fu&#x0308;r NP-schwere Optimierungsprobleme liefern und eine beweisbare Fehlerabscha&#x0308;tzung zulassen.
</p>



<h2 id="mengenueberdeckung-set-cover">Mengenüberdeckung (Set Cover)</h2>

</p>


<h3 id="problem">Problem</h3>

</p>


<p>
<b>Mengenu&#x0308;berdeckung</b>:<br />
Seien \(\U := \{u_1, \dotsc , u_n\}\) eine endliche Menge und \(\S := \{S_1, \dotsc , S_k\} \subset \P (\U )\) eine Familie von Teilmengen von \(\U \) mit \(\bigcup _{S_i \in \S } S_i = \U \).<br />
Dann heißt \(\S ’ \subset \S \) mit \(\bigcup _{S_i \in \S ’} S_i = \U \) <em><span class="dashuline" >Mengenu&#x0308;berdeckung</span></em> von \(\U \).
</p>

<p>
<b>Set-Cover-Problem</b>: Seien \(c_i &gt; 0\) die <em><span class="dashuline" >Kosten</span></em> von \(S_i\). Dann ist das <em><span class="dashuline" >Set-Cover-Problem (SC)</span></em>, eine
Mengenu&#x0308;berdeckung \(\S ’ \subset \S \) mit minimalen Kosten \(c(\S ’) := \sum _{S_i \in \S ’} c_i\) zu finden.<br />
Das SC-Problem ist NP-vollsta&#x0308;ndig.
</p>

<p>
Fu&#x0308;r das allgemeine Set-Cover-Problem existiert wahrscheinlich kein Polynomialzeit-Algorithmus, der eine Approximation \(\S ’\) mit \(c(\S ’) &lt; \log n \cdot c(\S _\opt )\) ausgibt. Das bedeutet insbesonders,
dass es fu&#x0308;r jede Konstante \(a &gt; 0\) wohl auch keinen Polynomialzeit-Algorithmus gibt, der eine Lo&#x0308;sung ausgibt, die ho&#x0308;chstens \(a\)-mal so groß ist als das Optimum (<em><span
class="dashuline" >\(a\)-Approximation</span></em>).
</p>

<p>
Ein einfacherer Spezialfall ist \(c_1 = \dotsb = c_k = 1\).
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b>SC als LP</b>: Fu&#x0308;r jedes \(S_i\) fu&#x0308;hre eine Variable \(x_i\) ein, wobei \(x_i = 1 \iff S_i\) wird fu&#x0308;r \(\S ’\) gewa&#x0308;hlt. Dann la&#x0308;sst sich das SC-Problem durch das LP<br />
\(\min \sum _{S_i \in \S } x_i c_i\), \(\forall _{u \in \U }\; \sum _{S_i \ni u} x_i \ge 1\), \(\forall _{S_i \in \S }\; x_i \in \{0, 1\}\) beschreiben.
</p>

<p>
<b>LP-Relaxation</b>: Von <em><span class="dashuline" >LP-Relaxation</span></em> spricht man, wenn man bei einem Ganzzahl-LP die Forderung der Ganzzahligkeit aufgibt. Beim SC-Problem ersetzt man z.&#x202f;B. \(x_i
\in \{0, 1\}\) durch \(x_i \ge 0\).
</p>

<p>
<b>duales Problem</b>: Das zur LP-Relaxation von SC duale Problem lautet<br />
\(\max \sum _{u \in \U } y_u\), \(\forall _{S_i \in \S }\; \sum _{u \in S_i} y_u \le c_i\), \(\forall _{u \in \U }\; y_u \ge 0\) (<em><span class="dashuline" >Packing-Problem</span></em>).
</p>



<h3 id="spezialfall-vertex-cover">Spezialfall Vertex Cover</h3>

</p>


<p>
<b>Knotenu&#x0308;berdeckung</b>: Gegeben sei ein ungerichteter Graph \(G = (V, E)\).<br />
Dann heißt \(C \subset V\) mit \(\forall _{e \in E}\; e \cap C \not = \emptyset \) <em><span class="dashuline" >Knotenu&#x0308;berdeckung</span></em>.
</p>

<p>
<b>Vertex-Cover-Problem</b>: Das <em><span class="dashuline" >Vertex-Cover-Problem (VC)</span></em> ist, zu \(G\) eine Knotenu&#x0308;berdeckung \(C\) mit \(|C|\) minimal zu finden. Das VC-Problem ist
NP-vollsta&#x0308;ndig.
</p>

<p>
<b>VC als SC</b>: VC ist ein Spezialfall von SC mit \(\U := E\) und \(\S := \{\{e \in E \;|\; e \ni v\} \;|\; v \in V\}\).
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b>VC als Ganzzahl-LP</b>: Fu&#x0308;r jedes \(v \in V\) fu&#x0308;hre eine Variable \(x_v\) ein, wobei \(x_v = 1 \iff v\) wird fu&#x0308;r \(C\) ausgewa&#x0308;hlt. Dann la&#x0308;sst sich das VC-Problem durch
das LP<br />
\(\min \sum _{v \in V} x_v\), \(\forall _{e = \{v, w\} \in E}\; x_v + x_w \ge 1\), \(\forall _{v \in V}\; x_v \in \{0, 1\}\) beschreiben.
</p>

<p>
<b>duales Problem</b>: Das duale Problem zur LP-Relaxation von VC lautet<br />
\(\max \sum _{e \in E} y_e\), \(\forall _{v \in V}\; \sum _{e \ni v} y_e \le 1\), \(\forall _{e \in E}\; y_e \ge 0\) (<em><span class="dashuline" >Matching-Problem</span></em>,<br />
wa&#x0308;hle so viele paarweise nicht-adjazente Kanten wie mo&#x0308;glich).
</p>



<h3 id="gieriger-algorithmus-greedy">Gieriger Algorithmus (Greedy)</h3>

</p>


<p>
<b>gieriger Algorithmus fu&#x0308;r SC</b>:
</p>
<ul style="list-style-type:none">

<li class="list-item-f0"><p>Setze \(C \leftarrow \emptyset \).
</p>
</li>
<li class="list-item-f1"><p>Solange \(C \not = \U \), wiederhole:
</p>
<ul style="list-style-type:none">

<li class="list-item-f2"><p>  Setze \(\alpha _i \leftarrow \frac {c_i}{|S_i \setminus C|}\) fu&#x0308;r alle \(S_i\) mit \(x_i = 0\).
</p>
</li>
<li class="list-item-f3"><p>  Wa&#x0308;hle \(S_j\), sodass \(\alpha _j = \min _i \alpha _i\).
</p>
</li>
<li class="list-item-f4"><p>  Setze \(x_j \leftarrow 1\).
</p>
</li>
<li class="list-item-f5"><p>  Fu&#x0308;r alle \(u \in S_j \setminus C\) setze \(C \leftarrow C \cup \{u\}\) und \(y_u \leftarrow \alpha _j\).
</p>
</li>
</ul>
</li>
<li class="list-item-f6"><p>  Gebe die Mengen \(S_i\) mit \(x_i = 1\) aus.
</p>
</li>
</ul>

<p>
Wie das folgende Lemma sagt, erzeugt der gierige Algorithmus eine Mengenu&#x0308;berdeckung, die ho&#x0308;chstens um den Faktor \(\O (\log n)\) teurer als eine optimale Lo&#x0308;sung ist. Der Ansatz heißt dabei
<em><span class="dashuline" >Dual Fitting</span></em>: Man findet zuna&#x0308;chst eine primale Lo&#x0308;sung, modifiziert die zugeho&#x0308;rige duale Lo&#x0308;sung so, dass sie zula&#x0308;ssig wird, und
scha&#x0308;tzt dann das Verha&#x0308;ltnis von primaler Lo&#x0308;sung zu modifizierter dualer Lo&#x0308;sung ab.
</p>

<p>
Es gibt Beispiele, bei denen der gierige Algorithmus tatsa&#x0308;chlich um \(\O (\log n)\) schlechter ist: Wa&#x0308;hle \(S_i\) fu&#x0308;r \(i = 1, \dotsc , k\) paarweise disjunkt (mit \(k \ge 3\)), sodass \(|S_i| =
2^i\) und \(\U = \bigcup _{i=1}^k S_i\). Teile nun noch jedes \(S_i\) in zwei Ha&#x0308;lften \(S_i’, S_i’’\) auf und setze \(S’ := \bigcup _{i=1}^k S_i’\) und \(S’’ := \bigcup _{i=1}^k S_i’’\). Dann ist die
optimale Mengenu&#x0308;berdeckung gegeben durch \(\{S’, S’’\}\) (d.&#x202f;h. minimale Gro&#x0308;ße \(2\)), der gierige Algorithmus gibt aber \(\{S_1, \dotsc , S_k\}\) zuru&#x0308;ck (mit \(k = \O (\log
n)\) wegen \(n = 2^{k+1} - 2\)).
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b>Lemma (Approximationsgu&#x0308;te des gierigen Algorithmus)</b>: Der gierige Algorithmus gibt eine Mengenu&#x0308;berdeckung \(\S ’ \subset \S \) aus mit Kosten \(c(\S ’) \le H_n \cdot c(\S _\opt ’)\),
wobei \(\S _\opt ’ \subset \S \) eine optimale Mengenu&#x0308;berdeckung und \(H_n := \sum _{i=1}^n \frac {1}{i} \le 1 + \log n\) die <em><span class="dashuline" >\(n\)-te harmonische Zahl</span></em>
ist.
</p>

<p>
<b>Beweis</b>: Der gierige Algorithmus erzeugt eine zula&#x0308;ssige Ganzzahl-Lo&#x0308;sung \(x\) des primalen Problems mit Kosten \(c(\S ’) = \sum _{S \in \S ’} x_S c_S\). Außerdem konstruiert er gleichzeitig
eine Lo&#x0308;sung \(y\) des dualen Problems mit exakt denselben Kosten (denn in jedem Durchlauf werden sowohl der primale als der duale Zielfunktionswert um genau \(c_j\) erho&#x0308;ht). Im Allgemeinen ist die duale
Lo&#x0308;sung aber nicht zula&#x0308;ssig!
</p>

<p>
Eine der dualen NBen \(\forall _{S \in \S }\; \sum _{u \in S} y_u \le c_S\) ist also evtl. verletzt. Im Folgenden wird gezeigt, dass immerhin \(\sum _{u \in S} y_u \le H_n c_S\) gilt. Dann kann man
na&#x0308;mlich die zula&#x0308;ssige duale Lo&#x0308;sung \(y’ := \frac {y}{H_n}\) definieren, die die Kosten \(\sum _{u \in \U } y_u’ = \frac {1}{H_n} \sum _{u \in \U } y_u = \frac {1}{H_n} c(\S ’)\)
besitzt. Weil alle zula&#x0308;ssigen Lo&#x0308;sungen des dualen Problems Zielfunktionswerte besitzen, die durch \(c(\S _\opt ’)\) nach oben beschra&#x0308;nkt sind (das duale Problem ist ein Maximierungsproblem und
opt. primaler/dualer Zielfkt.wert fallen zusammen), erha&#x0308;lt man daher \(c(\S ’) = H_n \sum _{u \in \U } y_u’ \le H_n \cdot c(\S _\opt ’)\).
</p>

<p>
Sei also \(S \in \S \) fest. Sortiere \(S := \{u_1, \dotsc , u_\ell \}\) in der Reihenfolge \(u_1, \dotsc , u_\ell \), in der die Elemente vom Algorithmus zu \(C\) hinzugefu&#x0308;gt werden. Fu&#x0308;r \(i \in
\{1, \dotsc , \ell \}\) fest betrachte man den Durchlauf des Algorithmus, bei dem \(u_i\) hinzugefu&#x0308;gt wurde. In diesem Durchlauf wurde eine Menge \(S’ \in \S \) ausgewa&#x0308;hlt, fu&#x0308;r die
\(\alpha _{S’} := \frac {c_{S’}}{|S’ \setminus C|}\) minimal war, und \(y_{u_i} := \alpha _{S’}\) gesetzt. Weil aber auch \(S\) ein „Kandidat“ war, gilt \(\alpha _{S’} \le \alpha _S\), wobei \(\alpha _S :=
\frac {c_S}{|S \setminus C|} \le \frac {c_S}{\ell - i + 1}\) gilt (weil \(u_i, u_{i+1}, \dotsc , u_\ell \in S \setminus C\) zu diesem Zeitpunkt aufgrund der Sortierung). Damit erha&#x0308;lt man \(y_{u_i}
\le \frac {c_S}{\ell - i + 1}\).
</p>

<p>
Durch Summation kommt man dann auf \(\sum _{u \in S} y_u \le \sum _{i=1}^\ell \frac {c_S}{\ell - i + 1} = H_\ell c_S \le H_n c_S\). &#x2003;&#x2003;
</p>



<h3 id="einfache-lp-rundung">Einfache LP-Rundung</h3>

</p>


<p>
<b>LP-Rundung</b>: Bei der <em><span class="dashuline" >LP-Rundung</span></em> erha&#x0308;lt man eine Approximation eines Ganzzahl-LPs, indem man die zugeho&#x0308;rige LP-Relaxation lo&#x0308;st, die
zugeho&#x0308;rige Lo&#x0308;sung in eine Ganzzahl-Lo&#x0308;sung umwandelt und schließlich beweist, dass die Lo&#x0308;sung nicht viel schlechter als das Ganzzahl-Optimum ist.
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b>einfache LP-Rundung fu&#x0308;r VC</b>: Sei \(x = (x_v)_{v \in V}\) die optimale Lo&#x0308;sung der LP-Relaxation. Dann wa&#x0308;hlt die <em><span class="dashuline" >einfache LP-Rundung</span></em>
fu&#x0308;r Vertex Cover \(C := \{v \in V \;|\; x_v &gt; 0\}\).
</p>

<p>
Dieser Algorithmus konstruiert auch fu&#x0308;r allgemeine SC-Probleme stets eine zula&#x0308;ssige Lo&#x0308;sung, wobei allerdings nicht klar ist, wie gut diese eine optimale Lo&#x0308;sung approximiert. Fu&#x0308;r
den VC-Spezialfall wird gezeigt, dass das Resultat eine \(2\)-Approximation ist, d.&#x202f;h. \(|C| \le 2 \cdot |C_\opt |\).
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b>Lemma (Halb-Ganzzahligkeit)</b>: Jede Ecke \(x\) des Zielbereichs der LP-Relaxation des VC-Problems, die durch die NBen \(\forall _{e = \{u, v\} \in E}\; x_u + x_v \ge 1\) definiert ist, erfu&#x0308;llt
\(\forall _{v \in V}\; x_v \in \{0, \frac {1}{2}, 1\}\).
</p>

<p>
<b>Beweis</b>: Sei \(x\) eine Ecke mit \(x_v \notin \{0, \frac {1}{2}, 1\}\) fu&#x0308;r ein \(v \in V\). Im Folgenden wird gezeigt, dass \(x = \frac {1}{2} (y + z)\) mit zwei zula&#x0308;ssigen Punkten \(y, z
\not = x\) gilt. Damit wa&#x0308;re \(x\) wegen der Konvexita&#x0308;t des Zielbereichs keine Ecke, ein Widerspruch.
</p>

<p>
Setze \(V^+ := \{v \in V \;|\; x_v \in (1/2, 1)\}\) und \(V^- := \{v \in V \;|\; x_v \in (0, 1/2)\}\). Wegen \(x_v \notin \{0, \frac {1}{2}, 1\}\) fu&#x0308;r ein \(v \in V\) ist \(V^+ \cup V^- \not =
\emptyset \). Definiere nun fu&#x0308;r \(\varepsilon &gt; 0\) die Punkte \(y, z\) mit \(y_v := x_v \pm \varepsilon \) fu&#x0308;r \(v \in V^\pm \) und \(y_v := x_v\) sonst sowie \(z_v := x_v \mp \varepsilon
\) fu&#x0308;r \(v \in V^\pm \) und \(z_v := x_v\) sonst. Wegen \(V^+ \cup V^- \not = \emptyset \) gilt \(y, z \not = x\) und man erha&#x0308;lt \(x = \frac {1}{2} (y + z)\).
</p>

<p>
Zu zeigen ist jetzt noch, dass \(y, z\) fu&#x0308;r \(\varepsilon &gt; 0\) klein genug zula&#x0308;ssige Lo&#x0308;sungen sind. Betrachte dazu alle NBen \(x_v + x_w \ge 1\) (erfu&#x0308;llt, da \(x\) zula&#x0308;ssig
ist).
</p>
<ul style="list-style-type:none">

<li class="list-item-f7"><p><em>Fall 1: \(x_v + x_w &gt; 1\)</em><br />
Wa&#x0308;hle \(\varepsilon &lt; \frac {1}{2} (x_v + x_w - 1)\). Dann gilt na&#x0308;mlich \(y_v + y_w \ge x_v + x_w - 2\varepsilon &gt; 1\).
</p>
</li>
<li class="list-item-f8"><p><em>Fall 2: \(x_v + x_w = 1\)</em>
</p>
<ul style="list-style-type:none">

<li class="list-item-f9"><p>\(x_v = x_w = \frac {1}{2}\): In diesem Fall gilt \(y_v = y_w = \frac {1}{2}\), d.&#x202f;h. \(y_v + y_w = 1\).
</p>
</li>
<li class="list-item-f10"><p>\(x_v = 0\), \(x_w = 1\): Dann gilt \(y_v = 0\), \(y_w = 1\), d.&#x202f;h. \(y_v + y_w = 1\) (analog \(x_v = 1\), \(x_w = 0\)).
</p>
</li>
<li class="list-item-f11"><p>\(v \in V^\pm \), \(w \in V^\mp \): In diesem Fall gilt \(y_v + y_w = (x_v \pm \varepsilon ) + (x_w \mp \varepsilon ) = x_v + x_w = 1\).
</p>
</li>
</ul>
</li>
</ul>

<p>
Analog sind auch die NBen \(z_v + z_w \ge 1\) fu&#x0308;r \(\varepsilon &gt; 0\) klein genug erfu&#x0308;llt. &#x2003;&#x2003;
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b>Lemma (2-Approximation von VC)</b>: Fu&#x0308;r das Resultat \(C\) der LP-Rundung fu&#x0308;r VC gilt \(|C| \le 2 \cdot |C_\opt |\) mit \(C_\opt \) einer optimalen Knotenu&#x0308;berdeckung.
</p>

<p>
<b>Beweis</b>: Sei \((x_v)_{v \in V}\) die Lo&#x0308;sung der LP-Relaxation des VC-Problems.
</p>

<p>
Es gilt \(\sum _{v \in V} x_v \le |C_\opt |\), weil \(|C_\opt |\) der Zielfunktionswert des Ganzzahl-LPs ist, sowie<br />
\(C = \{v \in V \;|\; x_v’ = 1\}\) mit \(x_v’ := 1\) fu&#x0308;r \(x_v &gt; 0\) und \(x_v’ := 0\) fu&#x0308;r \(x_v = 0\). Nach dem ersten Lemma ist \(x_v’ \le 2x_v\), also \(|C| = \sum _{v \in V} x_v’ \le
\sum _{v \in V} 2x_v \le 2 |C_\opt |\). &#x2003;&#x2003;
</p>



<h3 id="haeufigkeitsbasierte-lp-rundung">Häufigkeitsbasierte LP-Rundung</h3>

</p>


<p>
<b>ha&#x0308;ufigkeitsbasierte LP-Rundung fu&#x0308;r SC</b>:
</p>
<ul style="list-style-type:none">

<li class="list-item-f12"><p>Sei \(f := \max _{u \in \U } |\{S_i \in \S \;|\; S_i \ni u\}|\) (max. Mengenzahl, in der ein Element vorkommt).
</p>
</li>
<li class="list-item-f13"><p>Lo&#x0308;se die LP-Relaxation des SC-Problems.
</p>
</li>
<li class="list-item-f14"><p>Wa&#x0308;hle alle Mengen \(S_i\) mit \(x_i \ge \frac {1}{f}\).
</p>
</li>
</ul>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b>Lemma (\(f\)-Approximation von SC)</b>: Das Resultat \(\S ’\) der ha&#x0308;ufigkeitsbasierten LP-Rundung fu&#x0308;r SC ist eine Mengenu&#x0308;berdeckung mit \(c(\S ’) \le f \cdot c(\S ’_\opt )\), wobei
\(\S ’_\opt \) eine optimale Mengenu&#x0308;berdeckung ist.
</p>

<p>
<b>Beweis</b>: \(\S ’\) ist eine zula&#x0308;ssige Lo&#x0308;sung des SC-Problems, weil fu&#x0308;r \(u \in \U \) beliebig aus \(\sum _{S_i \ni u} x_i \ge 1\) und \(x_i \ge 0\) folgt, dass \(\exists _{S_j \ni
u}\; x_j \ge \frac {1}{f}\) (andernfalls wa&#x0308;re \(\sum _{S_i \ni u} x_i &lt; \frac {1}{f} \cdot |\{S_i \in \S \;|\; S_i \ni u\}| \le 1\)), d.&#x202f;h. \(S_j\) wird fu&#x0308;r \(\S ’\)
ausgewa&#x0308;hlt und \(u\) wird abgedeckt.
</p>

<p>
Außerdem gilt \(x_i’ \le f \cdot x_i\) mit \(x_i’ := 1\) fu&#x0308;r \(x_i \ge \frac {1}{f}\) und \(x_i’ := 0\) sonst, d.&#x202f;h.<br />
\(c(\S ’) = \sum _{S_i \in \S } c_i x_i’ \le f \cdot \sum _{S_i \in \S } c_i x_i \le f \cdot c(\S ’_\opt )\). &#x2003;&#x2003;
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
Fu&#x0308;r den VC-Spezialfall ist \(f = 2\) und man erha&#x0308;lt die einfache LP-Rundung von oben.
</p>



<h3 id="randomisierte-lp-rundung">Randomisierte LP-Rundung</h3>

</p>


<p>
<b>randomisierte LP-Rundung</b>: Sei \(x^\ast \) die optimale Lo&#x0308;sung der LP-Relaxation fu&#x0308;r SC und \(\OPTLP \) der zugeho&#x0308;rige Zielfunktionswert. Interpretiere die \(x_i^\ast \in [0, 1]\)
nun als Wahrscheinlichkeiten und wa&#x0308;hlen die Menge \(S_i\) mit Wahrscheinlichkeit \(x_i^\ast \).
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b>Kosten der rand. LP-Rundung</b>: Sei \(x’\) das Ergebnis der LP-Rundung. Dann sind die erwarteten Kosten des Resultats gleich \(\EE [\sum _{S_i \in \S } c_i x_i’] = \sum _{S_i \in \S } c_i \EE [x_i’] = \sum
_{S_i \in \S } c_i \PP [x_i’ = 1]\)<br />
\(= \sum _{S_i \in \S } c_i x_i^\ast = \OPTLP \).
</p>

<p>
Weil \(\OPTLP \) i.&#x202f;A. kleiner als \(\OPTint = c(\S ’_\opt )\) mit \(\S ’_\opt \) einer optimalen Mengenu&#x0308;berdeckung ist, wird das Ergebnis der randomisierten LP-Rundung i.&#x202f;A. keine
zula&#x0308;ssige Mengenu&#x0308;berd. sein.
</p>

<p>
<b>Lemma</b>: Sei \(u \in \U \). Dann ist die Wahrscheinlichkeit, dass \(u\) nicht abgedeckt wird, \(\le \frac {1}{e}\).
</p>

<p>
<b>Beweis</b>: Sei \(\ell \) die Anzahl der Mengen, die \(u\) enthalten. Wegen der NBen der LP-Relaxation gilt \(\sum _{S_i \ni u} x_i^\ast \ge 1\). Daraus folgt \(\PP [\text {$u$ nicht abgedeckt}] = \PP
[\forall _{S_i \ni u}\; \text {$S_i$ nicht gewählt}]\)<br />
\(= \prod _{S_i \ni u} \PP [\text {$S_i$ nicht gewählt}] = \prod _{S_i \ni u} (1 - x_i^\ast ) \le \left (1 - \frac {1}{\ell }\right )^\ell &lt; \frac {1}{e}\)<br />
(da \(e^x = \lim _{n \to \infty } \left (1 + \frac {x}{n}\right )^n\) streng monoton steigend). &#x2003;&#x2003;
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
Weil jedes \(u \in \U \) mit einer konstanten Wahrscheinlichkeit abgedeckt wird, kann man \(c \log n\) unabha&#x0308;ngige randomisierte LP-Rundungen durchfu&#x0308;hren und die Vereinigung \(\S ’\) der
gewa&#x0308;hlten Mengen bilden. Wa&#x0308;hlt man \(c \in \natural \) mit \(\left (\frac {1}{e}\right )^{c \log n} = \frac {1}{n^c} \le \frac {1}{4n}\), dann gilt<br />
\(\PP [\text {$u$ durch $\S ’$ nicht abgedeckt}] \le \left (\frac {1}{e}\right )^{c \log n} \le \frac {1}{4n}\). Somit erha&#x0308;lt man<br />
\(\PP [\text {$\S ’$ keine Mengenüberdeckung}] \le n \cdot \frac {1}{4n} = \frac {1}{4}\). Die erwarteten Kosten der so erhaltenen Lo&#x0308;sung sind \(\EE [c(\S ’)] \le c \log n \cdot \OPTLP \).
Wegen der Markov-Ungleichung \(\PP [X \ge t] \le \frac {\EE [X]}{t}\) (wobei \(t := 4c \log n \cdot \OPTLP \)) erha&#x0308;lt man \(\PP [c(\S ’) \ge 4c\log n \cdot \OPTLP ] \le \frac {1}{4}\).<br />
Daher gilt \(\PP [\text {$\S ’$ Mengenüberdeckung mit $c(\S ’) &lt; 4c \log n \cdot \OPTLP $}] \ge \frac {1}{2}\). Ist \(\S ’\) keine Mengenu&#x0308;berdeckung oder zu teuer (la&#x0308;sst sich leicht
u&#x0308;berpru&#x0308;fen), dann startet man neu, bis man eine zula&#x0308;ssige und „gu&#x0308;nstige“ Mengenu&#x0308;berdeckung erha&#x0308;lt (erwartete Wiederholungszahl \(\le 2\)).
</p>



<h3 id="primal-dual-schema">Primal-Dual-Schema</h3>

</p>


<p>
<b>Idee</b>: Starte mit einem Paar von Lo&#x0308;sungen \(x_0, y_0\) des primalen/dualen LPs, wobei \(x_0\) unzula&#x0308;ssig und \(y_0\) zula&#x0308;ssig ist. Vergro&#x0308;ßere nun duale Variablen,
wa&#x0308;hrend die Zula&#x0308;ssigkeit der dualen Lo&#x0308;sung erhalten bleibt. Beim Vergro&#x0308;ßern werden manche duale NBen <em><span class="dashuline" >scharf</span></em> (erfu&#x0308;llen
Gleichheit). Welche NBen scharf werden, bestimmt dann, welche primalen Variablen vergro&#x0308;ßert werden.
</p>

<p>
<b>Lemma (komplementa&#x0308;re Schlupf bedingung)</b>:<br />
Seien \(x^\ast , y^\ast \) optimale Lo&#x0308;sungen des primalen/dualen LPs. Dann gilt:
</p>
<ul style="list-style-type:none">

<li class="list-item-f15"><p>\(x_i^\ast &gt; 0 \iff \) entsprechende duale NB ist scharf
</p>
</li>
<li class="list-item-f16"><p>\(y_j^\ast &gt; 0 \iff \) entsprechende primale NB ist scharf
</p>
</li>
</ul>

<p>
<b>Beweis</b>: Sei \(y_j^\ast &gt; 0\). Dann ist die \(j\)-te primale NB \(h_j\) an der V-Form beteiligt (\(h_j \in B\)), die zur optimalen primalen Lo&#x0308;sung \(x^\ast \) geho&#x0308;rt (nach Konstruktion des
dualen Simplex-Algorithmus). Damit liegt \(x^\ast \) auf der Hyperebene, die zu \(h_j\) geho&#x0308;rt, und in der NB \(h_j\) gilt Gleichheit.<br />
Umgekehrt und fu&#x0308;r \(x_i\) argumentiert man analog. &#x2003;&#x2003;
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b>Primal-Dual-Schema fu&#x0308;r SC</b>:
</p>
<ul style="list-style-type:none">

<li class="list-item-f17"><p>Starte mit primaler Lo&#x0308;sung \(x := 0\) (unzula&#x0308;ssig) und dualer Lo&#x0308;sung \(y := 0\) (zula&#x0308;ssig).
</p>
</li>
<li class="list-item-f18"><p>Solange es ein noch nicht abgedecktes Element \(u \in \U \) gibt, wiederhole:
</p>
<ul style="list-style-type:none">

<li class="list-item-f19"><p>Wa&#x0308;hle ein \(u \in \U \), das noch nicht abgedeckt ist.
</p>
</li>
<li class="list-item-f20"><p>Vergro&#x0308;ßere die duale Variable \(y_u\) solange, bis duale NBen scharf werden.
</p>
</li>
<li class="list-item-f21"><p>Wa&#x0308;hle alle Mengen \(S_i \in \S \) (\(x_i := 1\)), die zu scharf gewordenen NBen geho&#x0308;ren.
</p>
</li>
</ul>
</li>
</ul>

<p>
<b>Lemma (Korrektheit)</b>:<br />
Der Algorithmus terminiert mit zula&#x0308;ssigen Lo&#x0308;sungen \(\widetilde {x}, \widetilde {y}\), wobei \(\widetilde {x}\) ganzzahlig ist.
</p>

<p>
<b>Beweis</b>: \(y\) ist immer eine zula&#x0308;ssige duale Lo&#x0308;sung wa&#x0308;hrend des Algorithmus. \(\widetilde {x}\) ist nach Konstruktion ebenfalls zula&#x0308;ssig. Es ko&#x0308;nnte allerdings sein, dass
\(y_u\) nicht vergro&#x0308;ßert werden kann (wobei \(u \in \U \) noch nicht abgedeckt ist), weil alle NBen schon scharf sind. Ist \(S_i \in \S \) mit \(u \in S_i\), dann wa&#x0308;re aber nach dem obigen Lemma
\(S_i\) schon gewa&#x0308;hlt worden (da \(x_i &gt; 0\)), ein Widerspruch dazu, dass \(u\) noch nicht abgedeckt ist. &#x2003;&#x2003;
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b>Lemma (\(f\)-Approximation von SC)</b>: Sei \(f := \max _{u \in \U } |\{S_i \in \S \;|\; S_i \ni u\}|\).<br />
Dann ist \(c^T \widetilde {x} \le f \cdot 1^\tp \widetilde {y}\). Insbesondere gilt \(c(\S ’) \le f \cdot c(\S ’_\opt )\), wobei \(\S ’\) das Ergebnis des Primal-Dual-Schemas und \(\S ’_\opt \) eine optimale
Mengenu&#x0308;berdeckung ist.
</p>

<p>
<b>Beweis</b>: Weil fu&#x0308;r \(S_i \in \S ’\) die NBen, die zu \(S_i\) geho&#x0308;ren, scharf sind, gilt \(\sum _{u \in S_i} \widetilde {y}_u = c_i\) und daher \(c^T \widetilde {x} = \sum _{S_i \in \S ’}
c_i = \sum _{S_i \in \S ’} \sum _{u \in S_i} \widetilde {y}_u \le f \cdot \sum _{u \in \U } \widetilde {y}_u = f \cdot 1^\tp \widetilde {y}\) (ein \(u \in \U \) kommt in ho&#x0308;chstens \(f\)
Mengen \(S_i \in \S ’\) vor). Daraus folgt \(c(\S ’) = c^\tp \widetilde {x} \le f \cdot 1^\tp \widetilde {y} \le f \cdot \OPTLP \le f \cdot c(\S ’_\opt )\). &#x2003;&#x2003;
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
In dem SC-Beispiel, bei dem der Greedy-Algorithmus \(\O (\log n)\)-viele Mengen wa&#x0308;hlt, obwohl die optimale Mengenu&#x0308;berdeckung nur zwei Mengen entha&#x0308;lt, schneidet das Primal-Dual-Schema
wesentlich besser ab: Es werden unabha&#x0308;ngig von \(n\) stets vier Mengen gewa&#x0308;hlt (\(f = 2\)).
</p>



<h2 id="uncapacitated-facility-location">Uncapacitated Facility Location</h2>

</p>


<h3 id="problem">Problem</h3>

</p>


<p>
<b>Uncapacitated Facility Location</b>: Beim <em><span class="dashuline" >UFL-Problem</span></em> ist \((V, F, D, f, c)\) gegeben mit
</p>
<ul style="list-style-type:none">

<li class="list-item-f22"><p>einer endlichen Menge \(V\) von <em><span class="dashuline" >Standorten</span></em>,
</p>
</li>
<li class="list-item-f23"><p>einer Teilmenge \(F \subset V\) von <em><span class="dashuline" >mo&#x0308;glichen Lagerstandorten</span></em>,
</p>
</li>
<li class="list-item-f24"><p>einer Teilmenge \(D := V \setminus F\) von <em><span class="dashuline" >Kundenstandorten</span></em>,
</p>
</li>
<li class="list-item-f25"><p>einer Abbildung \(f\colon F \to \real \) (<em><span class="dashuline" >Fixkosten</span></em>) und
</p>
</li>
<li class="list-item-f26"><p>einer Metrik \(c\) auf \(V\) (<em><span class="dashuline" >Verbindungskosten</span></em>).
</p>
</li>
</ul>

<p>
Gesucht ist eine Teilmenge \(F’ \subset F\) von Lagerstandorten und eine Abbildung \(\pi \colon D \to F’\), sodass die <em><span class="dashuline" >Gesamtkosten</span></em> \(c(F’, \pi ) := \sum _{i \in F’}
(f_i + \sum _{j \in \pi ^{-1}(i)} c_{i,j})\) minimiert werden, wobei \(f_i := f(i)\) und \(c_{i,j} := c(i, j)\) fu&#x0308;r \(i \in F\) und \(j \in D\).<br />
Das UFL-Problem ist NP-vollsta&#x0308;ndig.
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b>UFL als LP</b>: Fu&#x0308;hrt man bina&#x0308;re Variablen \(y_i\) und \(x_{i,j}\) ein mit \(y_i = 1 \iff \) „Lager \(i\) wird ero&#x0308;ffnet“ und \(x_{i,j} = 1 \iff \) „Kunde \(j\) wird Lager \(i\)
zugewiesen“, so erha&#x0308;lt man das Ganzzahl-LP \(\min \sum _{i \in F} (y_i f_i + \sum _{j \in D} x_{i,j} c_{i,j})\) mit \(\forall _{j \in D}\; \sum _{i \in F} x_{i,j} = 1\), \(\forall _{j \in D}
\forall _{i \in F}\; x_{i,j} \le y_i\) und \(x_{i,j}, y_i \in \{0, 1\}\).
</p>

<p>
<b>LP-Relaxation</b>: Die LP-Relaxation hat dieselbe Form, nur dass \(x_{i,j}, y_i \ge 0\).
</p>

<p>
<b>duales LP</b>: Das duale LP ist \(\max \sum _{j \in D} v_j\) mit \(\forall _{i \in F}\; \sum _{j \in D} w_{i,j} \le f_i\), \(\forall _{i \in F} \forall _{j \in D}\; v_j - w_{i,j} \le c_{i,j}\) und
\(w_{i,j} \ge 0\) (aber \(v_j \in \real \)).
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b>Lemma (komplementa&#x0308;re Schlupf bedingung)</b>:<br />
Seien \((x^\ast , y^\ast )\) und \((v^\ast , w^\ast )\) optimale Lo&#x0308;sungen fu&#x0308;r das primale bzw. duale LP.<br />
Dann gilt \(x_{i,j}^\ast &gt; 0 \implies c_{i,j} \le v_j^\ast \).
</p>

<p>
<b>Beweis</b>: Wegen der komplementa&#x0308;ren Schlupfbedingung gilt<br />
\(x_{i,j}^\ast &gt; 0 \iff v_j^\ast - w_{i,j}^\ast = c_{i,j} \implies v_j^\ast \ge c_{i,j}\), da \(w_{i,j}^\ast \ge 0\). &#x2003;&#x2003;
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b>benachbart</b>: Seien \(x^\ast \) eine LP-Lo&#x0308;sung, \(i \in F\) und \(j \in D\).<br />
Dann sind \(i\) und \(j\) <em><span class="dashuline" >benachbart</span></em>, falls \(x_{i,j}^\ast &gt; 0\).
</p>

<p>
<b>Nachbarschaften</b>: Seien \(x^\ast \) eine LP-Lo&#x0308;sung und \(j \in D\).<br />
Dann sind \(N(j) := \{i \in F \;|\; \text {$i$ und $j$ benachbart}\}\) und<br />
\(N^2(j) := \{k \in D \;|\; N(j) \cap N(k) \not = \emptyset \}\) die <em><span class="dashuline" >Nachbarschaften</span></em> von \(j\).
</p>



<h3 id="deterministische-rundung">Deterministische Rundung</h3>

</p>


<p>
<b>deterministische Rundung fu&#x0308;r UFL</b>:
</p>
<ul style="list-style-type:none">
<li class="list-item-f27"><p>Berechne optimale Lo&#x0308;sungen \((x^\ast , y^\ast )\) und \((v^\ast , w^\ast )\) des primalen bzw. dualen Problems.
</p>
</li>
<li class="list-item-f28"><p>Setze \(S \leftarrow D\).
</p>
</li>
<li class="list-item-f29"><p>Solange \(S \not = \emptyset \), wiederhole:
</p>
<ul style="list-style-type:none">

<li class="list-item-f30"><p>    Wa&#x0308;hle \(j \in S\) mit \(v_j^\ast \) minimal.
</p>
</li>
<li class="list-item-f31"><p>    Wa&#x0308;hle \(i \in N(j)\) mit \(f_i\) minimal und o&#x0308;ffne das Lager \(i\).
</p>
</li>
<li class="list-item-f32"><p>    Ordne \(j\) und alle Kunden in \(N^2(j)\), die bisher ohne Zuordnung sind, \(i\) zu.
</p>
</li>
<li class="list-item-f33"><p>    Setze \(S \leftarrow S \setminus N^2(j)\).
</p>
</li>
</ul>
</li>
</ul>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b>Satz (\(4\)-Approximation)</b>: Obiger Algorithmus erzeugt eine Lo&#x0308;sung, deren Kosten ho&#x0308;chstens vier Mal so groß sind wie die optimal mo&#x0308;glichen Kosten.
</p>

<p>
<b>Beweis</b>: Betrachte einen Durchlauf des Algorithmus, in dem der Kunde \(j \in S\) und der Lagerstandort \(i \in N(j)\) gewa&#x0308;hlt wurden. Dann gilt \(f_i = \sum _{\ell \in N(j)} x_{\ell ,j}^\ast
f_i\) wegen \(\sum _{\ell \in N(j)} x_{\ell ,j}^\ast = 1\) (primale NB). Wegen \(\forall _{\ell \in N(j)}\; f_i \le f_\ell \) nach Wahl von \(i\) und \(\forall _{\ell \in N(j)}\; x_{\ell ,j}^\ast \le
y_\ell ^\ast \) (primale NB) gilt \(f_i \le \sum _{\ell \in N(j)} y_\ell ^\ast f_\ell \). Anders gesagt ist die Ero&#x0308;ffnung des Lagers \(i\) nicht teurer als die Summe der rationalen Ero&#x0308;ffnungkosten
der Nachbarschaft von \(j\).
</p>

<p>
Wenn man diese Beziehung nun fu&#x0308;r alle Iterationen des Algorithmus summiert, so erha&#x0308;lt man \(\sum _{i \in F’} f_i \le \sum _{i \in F} y_i^\ast f_i\), weil die „\(N(j)\)-Mengen“ von zwei
verschiedenen Durchla&#x0308;ufen disjunkt sind (angenommen, es gibt \(\ell \in N(j_1) \cap N(j_2)\), wobei \(j_1\) in einer Iteration 1 gewa&#x0308;hlt wurde und \(j_2\) in einer spa&#x0308;teren Iteration 2, dann
wa&#x0308;re \(j_2 \in N^2(j_1)\), d.&#x202f;h. \(j_2\) wa&#x0308;re in der Iteration 1 aus \(S\) entfernt worden und ha&#x0308;tte nicht in Iteration 2 gewa&#x0308;hlt werden ko&#x0308;nnen, ein Widerspruch).<br
/>
Damit gilt \(\sum _{i \in F’} f_i \le \sum _{i \in F} y_i^\ast f_i \le \OPTprimal \).
</p>

<p>
Aufgrund des obigen Lemmas sind die Kosten, obiges \(j\) mit obigem \(i\) zu verbinden, gleich \(c_{i,j} \le v_j^\ast \), da \(i \in N(j)\). Die Kosten, die bisher nicht zugeordneten Kunden \(k \in N^2(j)\) mit \(i\) zu
verbinden, sind gleich \(c_{i,k} \le c_{\ell ,k} + c_{\ell ,j} + c_{i,j} \le 3v_k^\ast \) mit \(\ell \in N(j) \cap N(k)\), weil \(c_{\ell ,k} \le v_k^\ast \) und \(c_{\ell ,j}, c_{i,j} \le v_j^\ast \le
v_k^\ast \) nach Wahl von \(j\).
</p>

<p>
Damit sind die Gesamtkosten beschra&#x0308;nkt durch<br />
\(\sum _{i \in F’} f_i + \sum _{j \in D} 3v_j^\ast \le \OPTprimal + 3\OPTdual = 4\OPTprimal \le 4\OPTint \). &#x2003;&#x2003;
</p>



<h3 id="randomisierte-rundung">Randomisierte Rundung</h3>

</p>


<p>
<b>randomisierte Rundung fu&#x0308;r UFL</b>: Sei \(C_j^\ast := \sum _{i \in F} x_{i,j}^\ast c_{i,j}\).
</p>
<ul style="list-style-type:none">

<li class="list-item-f34"><p>Berechne optimale Lo&#x0308;sungen \((x^\ast , y^\ast )\) und \((v^\ast , w^\ast )\) des primalen bzw. dualen Problems.
</p>
</li>
<li class="list-item-f35"><p>Setze \(S \leftarrow D\).
</p>
</li>
<li class="list-item-f36"><p>Solange \(S \not = \emptyset \), wiederhole:
</p>
<ul style="list-style-type:none">

<li class="list-item-f37"><p>    Wa&#x0308;hle \(j \in S\) mit \(v_j^\ast + C_j^\ast \) minimal.
</p>
</li>
<li class="list-item-f38"><p>    Wa&#x0308;hle \(i \in N(j)\) gema&#x0308;ß den Wahrscheinlichkeiten \(x_{i,j}^\ast \) und o&#x0308;ffne das Lager \(i\).
</p>
</li>
<li class="list-item-f39"><p>    Ordne \(j\) und alle Kunden in \(N^2(j)\), die bisher ohne Zuordnung sind, \(i\) zu.
</p>
</li>
<li class="list-item-f40"><p>    Setze \(S \leftarrow S \setminus N^2(j)\).
</p>
</li>
</ul>
</li>
</ul>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b>Satz (\(3\)-Approximation)</b>: Obiger Algorithmus erzeugt eine Lo&#x0308;sung, deren Kosten ho&#x0308;chstens drei Mal so groß sind wie die optimal mo&#x0308;glichen Kosten.
</p>

<p>
<b>Beweis</b>: Betrachte wieder einen Durchlauf des Algorithmus, in dem der Kunde \(j \in S\) und der Lagerstandort \(i \in N(j)\) gewa&#x0308;hlt wurden. Bezeichnet die Zufallsvariable \(\widetilde {F}\) die
Ero&#x0308;ffnungskosten fu&#x0308;r diesen Durchlauf, so gilt \(\EE [\widetilde {F}] = \sum _{i \in N(j)} x_{i,j}^\ast f_i \le \sum _{i \in N(j)} y_i^\ast f_i\) (primale NB).
</p>

<p>
Sei \(A_k\) die Zufallsvariable der Verbindungskosten des Kunden \(k \in N^2(j)\) zu \(i\).
</p>
<ul style="list-style-type:none">

<li class="list-item-f41"><p>Dann gilt fu&#x0308;r die erwarteten Kosten fu&#x0308;r \(j\), dass \(\EE [A_j] = \sum _{i \in N(j)} x_{i,j}^\ast c_{i,j} = C_j^\ast \).
</p>
</li>
<li class="list-item-f42"><p>Fu&#x0308;r die erwarteten Kosten fu&#x0308;r \(k \in N^2(j) \setminus \{j\}\) sei \(\ell \in N(j) \cap N(k)\). Dann erha&#x0308;lt man \(\EE [A_k] \le c_{\ell ,k} + c_{\ell ,j} + C_j^\ast \le
v_k^\ast + (v_j^\ast + C_j^\ast ) \le 2v_k^\ast + C_k^\ast \) nach Wahl von \(j\) (und obiges Lemma).
</p>
</li>
</ul>

<p>
Die Gesamtkosten sind damit beschra&#x0308;nkt durch \(\sum _{i \in F} y_i^\ast f_i + \sum _{j \in D} (2v_j^\ast + C_j^\ast )\)<br />
\(= (\sum _{i \in F} y_i^\ast f_i + \sum _{j \in D} C_j^\ast ) + 2\sum _{j \in D} v_j^\ast = \OPTprimal + 2\OPTdual = 3\OPTprimal \le 3\OPTint \). &#x2003;&#x2003;
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
Eine Variante des natu&#x0308;rlichen Rundungsalgorithmus (bei dem man zufa&#x0308;llig Lager anhand der Wahrscheinlichkeiten \(y_i^\ast \) o&#x0308;ffnet und dann jeden Kunden mit dem na&#x0308;chstgelegenen
Lager verbindet) liefert eine \(1.736\)-Approximation. Man kann zeigen, dass kein Polynomialzeit-Algorithmus eine \(1.427\)-Approximation liefert, wenn \(\text {P} \not = \text {NP}\).
</p>



<h3 id="primal-dual-schema">Primal-Dual-Schema</h3>

</p>


<p>
<b>benachbart</b>: Seien \(x^\ast , y^\ast \) Lo&#x0308;sungen des primalen/dualen Problems, \(i \in F\) und \(j \in D\).<br />
Dann sind \(i\) und \(j\) <em><span class="dashuline" >benachbart</span></em>, falls \(v_j^\ast &gt; c_{i,j}\).
</p>

<p>
Diese Definition versta&#x0308;rkt die vorherige Definiton etwas, da \(x_{i,j}^\ast &gt; 0 \iff v_j^\ast \ge c_{i,j}\).<br />
Nachbarschaften sind analog wie vorher definiert.
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b>Primal-Dual-Schema fu&#x0308;r UFL</b>:
</p>
<ul style="list-style-type:none">

<li class="list-item-f43"><p>Setze \(v \leftarrow 0\), \(w \leftarrow 0\), \(A \leftarrow \emptyset \), \(\ell \leftarrow 0\) und \(S \leftarrow D\).
</p>
</li>
<li class="list-item-f44"><p>Solange \(S \not = \emptyset \), wiederhole:
</p>
<ul style="list-style-type:none">

<li class="list-item-f45"><p>Setze \(\ell \leftarrow \ell + 1\).
</p>
</li>
<li class="list-item-f46"><p>Vergro&#x0308;ßere \(v_j\) und \(w_{i,j}\) fu&#x0308;r alle \(j \in S\) und \(i \in N(j)\) glm., bis \(\exists _{i_\ell \in F}\; \sum _{j \in D} w_{i_\ell ,j} = f_{i_\ell }\).
</p>
</li>
<li class="list-item-f47"><p>Setze \(A \leftarrow A \cup \{i_\ell \}\) und \(S \leftarrow S \setminus N(i_\ell )\).
</p>
</li>
</ul>
</li>
</ul>

<p>
Weil in jeder Runde die dualen Variablen \(v_j\) aller Kunden \(j\) ohne Zuordnung und \(w_{i,j}\) fu&#x0308;r \(i \in N(j)\) gleichma&#x0308;ßig vergro&#x0308;ßert werden, bis eine duale NB fu&#x0308;r \(i_\ell
\in F\) scharf wird, bleibt die duale Lo&#x0308;sung immer zula&#x0308;ssig. Wenn man nun \(i_\ell \) o&#x0308;ffnen und alle \(j \in N(i_\ell )\) mit \(i_\ell \) verbinden wu&#x0308;rde, wu&#x0308;rde man
eine zula&#x0308;ssige primale Lo&#x0308;sung erhalten.
</p>

<p>
Leider kann es passieren, dass nach der Ausfu&#x0308;hrung des Algorithmus in der Nachbarschaft \(N(j)\) eines Kunden \(j \in D\) mehrere Lager geo&#x0308;ffnet haben, was die Analyse erschwert: Fu&#x0308;r die
O&#x0308;ffnungskosten gilt na&#x0308;mlich \(\sum _{i \in A} f_i = \sum _{i \in A} \sum _{j \in D} w_{i,j} = \sum _{i \in A} \sum _{j \in D} \max (v_j - c_{i,j}, 0)\)<br />
\(= \sum _{j \in D} \sum _{i \in N(j) \cap A} (v_j - c_{i,j})\). Wu&#x0308;rde nun \(\forall _{j \in D}\; |N(j) \cap A| = 1\) gelten mit \(N(j) \cap A =: \{i(j)\}\), so wa&#x0308;re dies gleich \(\sum
_{j \in D} (v_j - c_{i(j),j}) \le \sum _{j \in D} v_j \le \OPTdual \).
</p>

<p>
Leider gilt diese Eigenschaft nicht, aber man kann \(A\) so zu einer Menge \(A’\) von Lagerstandorten vera&#x0308;ndern, sodass \(A’\) diese Eigenschaft erfu&#x0308;llt, ohne dass die Verbindungskosten zu hoch werden:
</p>
<ul style="list-style-type:none">

<li class="list-item-f48"><p>Setze \(A’ \leftarrow A\).
</p>
</li>
<li class="list-item-f49"><p>Fu&#x0308;r \(k = 1, \dotsc , \ell \) wiederhole:
</p>
<ul style="list-style-type:none">

<li class="list-item-f50"><p>Wenn \(i_k \in A’\) ist, dann o&#x0308;ffne das Lager \(i_k\), ordne alle Kunden in \(N(i_k) \cup N^3(i_k)\), die bisher ohne Zuordnung sind, \(i_k\) zu und setze \(A’ \leftarrow A’ \setminus
N^2(i_k)\).
</p>
</li>
</ul>
</li>
</ul>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b>Lemma</b>: Sei \(F’\) die Menge der geo&#x0308;ffneten Lager. Dann gilt \(\forall _{j \in D}\; |F’ \cap N(j)| \le 1\).
</p>

<p>
<b>Beweis</b>: Angenommen, es gibt \(j \in D\) und \(i_a, i_b \in N(j)\) mit \(a &lt; b\). Dann gilt \(i_b \in N^2(i_a)\), d.&#x202f;h. in der Iteration \(a\) ist \(i_b\) aus \(A’\) entfernt werden, ein Widerspruch.
&#x2003;&#x2003;
</p>

<p>
<b>Satz (\(3\)-Approximation)</b>: Obiger Algorithmus erzeugt eine Lo&#x0308;sung, deren Kosten ho&#x0308;chstens drei Mal so groß sind wie die optimal mo&#x0308;glichen Kosten.
</p>

<p>
<b>Beweis</b>: Fu&#x0308;r die O&#x0308;ffnungskosten gilt wie vorher \(\sum _{i \in F’} f_i = \sum _{j \in D,\; |N(j) \cap F’| = 1} (v_j - c_{i(j),j})\).
</p>

<p>
Sei \(j \in D\) mit \(F’ \cap N(j) = \emptyset \). Zeige nun \(c_{i(j),j} \le 3v_j\), wobei \(i(j)\) das Lager ist, mit dem \(j\) verbunden wurde. Jedes Lager \(i \in A \cap N(j)\) hat einen ho&#x0308;heren Index
in \(A\) als \(i(j)\). Daraus folgt \(\forall _{k \in N(i(j))}\; v_j \ge v_k\). Es gilt \(j \in N(i(j)) \cap N^3(i(j))\). Im Fall \(j \in N(i(j))\) gilt \(c_{i(j),j} \le v_j \le 3v_j\) und im Fall \(j \in
N^3(i(j))\) erha&#x0308;lt man \(c_{i(j),j} \le c_{i’,j} + c_{i’,k} + c_{i(j),k} \le v_j + v_k + v_k \le 3v_j\) mit \(i’ \in N(j) \cap N(k)\) und \(i(j) \in N(k)\).
</p>

<p>
Damit gilt insgesamt \(\sum _{i \in F’} f_i + \sum _{j \in D,\; |N(j) \cap F’| \le 1} c_{i(j),j}\)<br />
\(\le \sum _{j \in D,\; |N(j) \cap F’| = 1} v_j + \sum _{j \in D,\; |N(j) \cap F’| = 0} c_{i(j),j} \le \sum _{j \in D,\; |N(j) \cap F’| = 1} v_j + \sum _{j \in D,\; |N(j) \cap F’| = 0}
3v_j\)<br />
\(\le 3\sum _{j \in D} v_j = 3\OPTdual \le 3\OPTprimal \le 3\OPTint \). &#x2003;&#x2003;
</p>

{% endraw %}
</div>
{:/nomarkdown}
