
{::nomarkdown}
<div class="lwarp-contents">
{% raw %}
<div class="hidden" >

\(\newcommand{\footnotename}{footnote}\)

\(\def \LWRfootnote {1}\)

\(\newcommand {\footnote }[2][\LWRfootnote ]{{}^{\mathrm {#1}}}\)

\(\newcommand {\footnotemark }[1][\LWRfootnote ]{{}^{\mathrm {#1}}}\)

\(\newcommand \ensuremath [1]{#1}\)

\(\newcommand {\LWRframebox }[2][]{\fbox {#2}} \newcommand {\framebox }[1][]{\LWRframebox } \)

\(\newcommand {\setlength }[2]{}\)

\(\newcommand {\addtolength }[2]{}\)

\(\newcommand {\setcounter }[2]{}\)

\(\newcommand {\addtocounter }[2]{}\)

\(\newcommand {\cline }[1]{}\)

\(\newcommand {\directlua }[1]{\text {(directlua)}}\)

\(\newcommand {\luatexdirectlua }[1]{\text {(directlua)}}\)

\(\newcommand {\protect }{}\)

\(\def \LWRabsorbnumber #1 {}\)

\(\def \LWRabsorbquotenumber &quot;#1 {}\)

\(\def \mathchar {\ifnextchar &quot;\LWRabsorbquotenumber \LWRabsorbnumber }\)

\(\def \mathcode #1={\mathchar }\)

\(\let \delcode \mathcode \)

\(\let \delimiter \mathchar \)

\(\let \LWRref \ref \)

\(\renewcommand {\ref }{\ifstar \LWRref \LWRref }\)

\(\newcommand {\intertext }[1]{\text {#1}\notag \\}\)

\(\newcommand {\mathllap }[2][]{{#1#2}}\)

\(\newcommand {\mathrlap }[2][]{{#1#2}}\)

\(\newcommand {\mathclap }[2][]{{#1#2}}\)

\(\newcommand {\mathmbox }[1]{#1}\)

\(\newcommand {\clap }[1]{#1}\)

\(\newcommand {\LWRmathmakebox }[2][]{#2}\)

\(\newcommand {\mathmakebox }[1][]{\LWRmathmakebox }\)

\(\newcommand {\cramped }[2][]{{#1#2}}\)

\(\newcommand {\crampedllap }[2][]{{#1#2}}\)

\(\newcommand {\crampedrlap }[2][]{{#1#2}}\)

\(\newcommand {\crampedclap }[2][]{{#1#2}}\)

\(\newenvironment {crampedsubarray}[1]{}{}\)

\(\newcommand {\crampedsubstack }{}\)

\(\newcommand {\smashoperator }[2][]{#2\limits }\)

\(\newcommand {\adjustlimits }{}\)

\(\newcommand {\SwapAboveDisplaySkip }{}\)

\(\require {extpfeil}\)

\(\Newextarrow \xleftrightarrow {10,10}{0x2194}\)

\(\Newextarrow \xLeftarrow {10,10}{0x21d0}\)

\(\Newextarrow \xhookleftarrow {10,10}{0x21a9}\)

\(\Newextarrow \xmapsto {10,10}{0x21a6}\)

\(\Newextarrow \xRightarrow {10,10}{0x21d2}\)

\(\Newextarrow \xLeftrightarrow {10,10}{0x21d4}\)

\(\Newextarrow \xhookrightarrow {10,10}{0x21aa}\)

\(\Newextarrow \xrightharpoondown {10,10}{0x21c1}\)

\(\Newextarrow \xleftharpoondown {10,10}{0x21bd}\)

\(\Newextarrow \xrightleftharpoons {10,10}{0x21cc}\)

\(\Newextarrow \xrightharpoonup {10,10}{0x21c0}\)

\(\Newextarrow \xleftharpoonup {10,10}{0x21bc}\)

\(\Newextarrow \xleftrightharpoons {10,10}{0x21cb}\)

\(\newcommand {\LWRdounderbracket }[3]{\underset {#3}{\underline {#1}}}\)

\(\newcommand {\LWRunderbracket }[2][]{\LWRdounderbracket {#2}}\)

\(\newcommand {\underbracket }[1][]{\LWRunderbracket }\)

\(\newcommand {\LWRdooverbracket }[3]{\overset {#3}{\overline {#1}}}\)

\(\newcommand {\LWRoverbracket }[2][]{\LWRdooverbracket {#2}}\)

\(\newcommand {\overbracket }[1][]{\LWRoverbracket }\)

\(\newcommand {\LaTeXunderbrace }[1]{\underbrace {#1}}\)

\(\newcommand {\LaTeXoverbrace }[1]{\overbrace {#1}}\)

\(\newenvironment {matrix*}[1][]{\begin {matrix}}{\end {matrix}}\)

\(\newenvironment {pmatrix*}[1][]{\begin {pmatrix}}{\end {pmatrix}}\)

\(\newenvironment {bmatrix*}[1][]{\begin {bmatrix}}{\end {bmatrix}}\)

\(\newenvironment {Bmatrix*}[1][]{\begin {Bmatrix}}{\end {Bmatrix}}\)

\(\newenvironment {vmatrix*}[1][]{\begin {vmatrix}}{\end {vmatrix}}\)

\(\newenvironment {Vmatrix*}[1][]{\begin {Vmatrix}}{\end {Vmatrix}}\)

\(\newenvironment {smallmatrix*}[1][]{\begin {matrix}}{\end {matrix}}\)

\(\newenvironment {psmallmatrix*}[1][]{\begin {pmatrix}}{\end {pmatrix}}\)

\(\newenvironment {bsmallmatrix*}[1][]{\begin {bmatrix}}{\end {bmatrix}}\)

\(\newenvironment {Bsmallmatrix*}[1][]{\begin {Bmatrix}}{\end {Bmatrix}}\)

\(\newenvironment {vsmallmatrix*}[1][]{\begin {vmatrix}}{\end {vmatrix}}\)

\(\newenvironment {Vsmallmatrix*}[1][]{\begin {Vmatrix}}{\end {Vmatrix}}\)

\(\newenvironment {psmallmatrix}[1][]{\begin {pmatrix}}{\end {pmatrix}}\)

\(\newenvironment {bsmallmatrix}[1][]{\begin {bmatrix}}{\end {bmatrix}}\)

\(\newenvironment {Bsmallmatrix}[1][]{\begin {Bmatrix}}{\end {Bmatrix}}\)

\(\newenvironment {vsmallmatrix}[1][]{\begin {vmatrix}}{\end {vmatrix}}\)

\(\newenvironment {Vsmallmatrix}[1][]{\begin {Vmatrix}}{\end {Vmatrix}}\)

\(\newcommand {\LWRmultlined }[1][]{\begin {multline*}}\)

\(\newenvironment {multlined}[1][]{\LWRmultlined }{\end {multline*}}\)

\(\let \LWRorigshoveleft \shoveleft \)

\(\renewcommand {\shoveleft }[1][]{\LWRorigshoveleft }\)

\(\let \LWRorigshoveright \shoveright \)

\(\renewcommand {\shoveright }[1][]{\LWRorigshoveright }\)

\(\newenvironment {dcases}{\begin {cases}}{\end {cases}}\)

\(\newenvironment {dcases*}{\begin {cases}}{\end {cases}}\)

\(\newenvironment {rcases}{\begin {cases}}{\end {cases}}\)

\(\newenvironment {rcases*}{\begin {cases}}{\end {cases}}\)

\(\newenvironment {drcases}{\begin {cases}}{\end {cases}}\)

\(\newenvironment {drcases*}{\begin {cases}}{\end {cases}}\)

\(\newenvironment {cases*}{\begin {cases}}{\end {cases}}\)

\(\newcommand {\MoveEqLeft }[1][]{}\)

\(\def \LWRAboxed #1&amp;#2&amp;#3!|!{\fbox {\(#1\)}&amp;\fbox {\(#2\)}} \newcommand {\Aboxed }[1]{\LWRAboxed #1&amp;&amp;!|!} \)

\( \newcommand {\LWRABLines }[1][\Updownarrow ]{#1 \notag \\}\newcommand {\ArrowBetweenLines }{\ifstar \LWRABLines \LWRABLines } \)

\(\newcommand {\shortintertext }[1]{\text {#1}\notag \\}\)

\(\newcommand {\vdotswithin }[1]{\hspace {.5em}\vdots }\)

\(\newcommand {\LWRshortvdotswithinstar }[1]{\vdots \hspace {.5em} &amp; \\}\)

\(\newcommand {\LWRshortvdotswithinnostar }[1]{&amp; \hspace {.5em}\vdots \\}\)

\(\newcommand {\shortvdotswithin }{\ifstar \LWRshortvdotswithinstar \LWRshortvdotswithinnostar }\)

\(\newcommand {\MTFlushSpaceAbove }{}\)

\(\newcommand {\MTFlushSpaceBelow }{\\}\)

\(\newcommand \lparen {(}\)

\(\newcommand \rparen {)}\)

\(\newcommand {\ordinarycolon }{:}\)

\(\newcommand {\vcentcolon }{\mathrel {\mathop \ordinarycolon }}\)

\(\newcommand \dblcolon {\vcentcolon \vcentcolon }\)

\(\newcommand \coloneqq {\vcentcolon =}\)

\(\newcommand \Coloneqq {\dblcolon =}\)

\(\newcommand \coloneq {\vcentcolon {-}}\)

\(\newcommand \Coloneq {\dblcolon {-}}\)

\(\newcommand \eqqcolon {=\vcentcolon }\)

\(\newcommand \Eqqcolon {=\dblcolon }\)

\(\newcommand \eqcolon {\mathrel {-}\vcentcolon }\)

\(\newcommand \Eqcolon {\mathrel {-}\dblcolon }\)

\(\newcommand \colonapprox {\vcentcolon \approx }\)

\(\newcommand \Colonapprox {\dblcolon \approx }\)

\(\newcommand \colonsim {\vcentcolon \sim }\)

\(\newcommand \Colonsim {\dblcolon \sim }\)

\(\newcommand {\nuparrow }{\mathrel {\cancel {\uparrow }}}\)

\(\newcommand {\ndownarrow }{\mathrel {\cancel {\downarrow }}}\)

\(\newcommand {\bigtimes }{\mathop {\Large \times }\limits }\)

\(\newcommand {\prescript }[3]{{}^{#1}_{#2}#3}\)

\(\newenvironment {lgathered}{\begin {gathered}}{\end {gathered}}\)

\(\newenvironment {rgathered}{\begin {gathered}}{\end {gathered}}\)

\(\newcommand {\splitfrac }[2]{{}^{#1}_{#2}}\)

\(\let \splitdfrac \splitfrac \)

\(\newcommand {\LWRoverlaysymbols }[2]{\mathord {\smash {\mathop {#2\strut }\limits ^{\smash {\lower 3ex{#1}}}}\strut }}\)

\(\newcommand{\alphaup}{\unicode{x03B1}}\)

\(\newcommand{\betaup}{\unicode{x03B2}}\)

\(\newcommand{\gammaup}{\unicode{x03B3}}\)

\(\newcommand{\digammaup}{\unicode{x03DD}}\)

\(\newcommand{\deltaup}{\unicode{x03B4}}\)

\(\newcommand{\epsilonup}{\unicode{x03F5}}\)

\(\newcommand{\varepsilonup}{\unicode{x03B5}}\)

\(\newcommand{\zetaup}{\unicode{x03B6}}\)

\(\newcommand{\etaup}{\unicode{x03B7}}\)

\(\newcommand{\thetaup}{\unicode{x03B8}}\)

\(\newcommand{\varthetaup}{\unicode{x03D1}}\)

\(\newcommand{\iotaup}{\unicode{x03B9}}\)

\(\newcommand{\kappaup}{\unicode{x03BA}}\)

\(\newcommand{\varkappaup}{\unicode{x03F0}}\)

\(\newcommand{\lambdaup}{\unicode{x03BB}}\)

\(\newcommand{\muup}{\unicode{x03BC}}\)

\(\newcommand{\nuup}{\unicode{x03BD}}\)

\(\newcommand{\xiup}{\unicode{x03BE}}\)

\(\newcommand{\omicronup}{\unicode{x03BF}}\)

\(\newcommand{\piup}{\unicode{x03C0}}\)

\(\newcommand{\varpiup}{\unicode{x03D6}}\)

\(\newcommand{\rhoup}{\unicode{x03C1}}\)

\(\newcommand{\varrhoup}{\unicode{x03F1}}\)

\(\newcommand{\sigmaup}{\unicode{x03C3}}\)

\(\newcommand{\varsigmaup}{\unicode{x03C2}}\)

\(\newcommand{\tauup}{\unicode{x03C4}}\)

\(\newcommand{\upsilonup}{\unicode{x03C5}}\)

\(\newcommand{\phiup}{\unicode{x03D5}}\)

\(\newcommand{\varphiup}{\unicode{x03C6}}\)

\(\newcommand{\chiup}{\unicode{x03C7}}\)

\(\newcommand{\psiup}{\unicode{x03C8}}\)

\(\newcommand{\omegaup}{\unicode{x03C9}}\)

\(\newcommand{\Alphaup}{\unicode{x0391}}\)

\(\newcommand{\Betaup}{\unicode{x0392}}\)

\(\newcommand{\Gammaup}{\unicode{x0393}}\)

\(\newcommand{\Digammaup}{\unicode{x03DC}}\)

\(\newcommand{\Deltaup}{\unicode{x0394}}\)

\(\newcommand{\Epsilonup}{\unicode{x0395}}\)

\(\newcommand{\Zetaup}{\unicode{x0396}}\)

\(\newcommand{\Etaup}{\unicode{x0397}}\)

\(\newcommand{\Thetaup}{\unicode{x0398}}\)

\(\newcommand{\Varthetaup}{\unicode{x03F4}}\)

\(\newcommand{\Iotaup}{\unicode{x0399}}\)

\(\newcommand{\Kappaup}{\unicode{x039A}}\)

\(\newcommand{\Lambdaup}{\unicode{x039B}}\)

\(\newcommand{\Muup}{\unicode{x039C}}\)

\(\newcommand{\Nuup}{\unicode{x039D}}\)

\(\newcommand{\Xiup}{\unicode{x039E}}\)

\(\newcommand{\Omicronup}{\unicode{x039F}}\)

\(\newcommand{\Piup}{\unicode{x03A0}}\)

\(\newcommand{\Varpiup}{\unicode{x03D6}}\)

\(\newcommand{\Rhoup}{\unicode{x03A1}}\)

\(\newcommand{\Sigmaup}{\unicode{x03A3}}\)

\(\newcommand{\Tauup}{\unicode{x03A4}}\)

\(\newcommand{\Upsilonup}{\unicode{x03A5}}\)

\(\newcommand{\Phiup}{\unicode{x03A6}}\)

\(\newcommand{\Chiup}{\unicode{x03A7}}\)

\(\newcommand{\Psiup}{\unicode{x03A8}}\)

\(\newcommand{\Omegaup}{\unicode{x03A9}}\)

\(\newcommand{\alphait}{\unicode{x1D6FC}}\)

\(\newcommand{\betait}{\unicode{x1D6FD}}\)

\(\newcommand{\gammait}{\unicode{x1D6FE}}\)

\(\newcommand{\digammait}{\mathit{\unicode{x03DD}}}\)

\(\newcommand{\deltait}{\unicode{x1D6FF}}\)

\(\newcommand{\epsilonit}{\unicode{x1D716}}\)

\(\newcommand{\varepsilonit}{\unicode{x1D700}}\)

\(\newcommand{\zetait}{\unicode{x1D701}}\)

\(\newcommand{\etait}{\unicode{x1D702}}\)

\(\newcommand{\thetait}{\unicode{x1D703}}\)

\(\newcommand{\varthetait}{\unicode{x1D717}}\)

\(\newcommand{\iotait}{\unicode{x1D704}}\)

\(\newcommand{\kappait}{\unicode{x1D705}}\)

\(\newcommand{\varkappait}{\unicode{x1D718}}\)

\(\newcommand{\lambdait}{\unicode{x1D706}}\)

\(\newcommand{\muit}{\unicode{x1D707}}\)

\(\newcommand{\nuit}{\unicode{x1D708}}\)

\(\newcommand{\xiit}{\unicode{x1D709}}\)

\(\newcommand{\omicronit}{\unicode{x1D70A}}\)

\(\newcommand{\piit}{\unicode{x1D70B}}\)

\(\newcommand{\varpiit}{\unicode{x1D71B}}\)

\(\newcommand{\rhoit}{\unicode{x1D70C}}\)

\(\newcommand{\varrhoit}{\unicode{x1D71A}}\)

\(\newcommand{\sigmait}{\unicode{x1D70E}}\)

\(\newcommand{\varsigmait}{\unicode{x1D70D}}\)

\(\newcommand{\tauit}{\unicode{x1D70F}}\)

\(\newcommand{\upsilonit}{\unicode{x1D710}}\)

\(\newcommand{\phiit}{\unicode{x1D719}}\)

\(\newcommand{\varphiit}{\unicode{x1D711}}\)

\(\newcommand{\chiit}{\unicode{x1D712}}\)

\(\newcommand{\psiit}{\unicode{x1D713}}\)

\(\newcommand{\omegait}{\unicode{x1D714}}\)

\(\newcommand{\Alphait}{\unicode{x1D6E2}}\)

\(\newcommand{\Betait}{\unicode{x1D6E3}}\)

\(\newcommand{\Gammait}{\unicode{x1D6E4}}\)

\(\newcommand{\Digammait}{\mathit{\unicode{x03DC}}}\)

\(\newcommand{\Deltait}{\unicode{x1D6E5}}\)

\(\newcommand{\Epsilonit}{\unicode{x1D6E6}}\)

\(\newcommand{\Zetait}{\unicode{x1D6E7}}\)

\(\newcommand{\Etait}{\unicode{x1D6E8}}\)

\(\newcommand{\Thetait}{\unicode{x1D6E9}}\)

\(\newcommand{\Varthetait}{\unicode{x1D6F3}}\)

\(\newcommand{\Iotait}{\unicode{x1D6EA}}\)

\(\newcommand{\Kappait}{\unicode{x1D6EB}}\)

\(\newcommand{\Lambdait}{\unicode{x1D6EC}}\)

\(\newcommand{\Muit}{\unicode{x1D6ED}}\)

\(\newcommand{\Nuit}{\unicode{x1D6EE}}\)

\(\newcommand{\Xiit}{\unicode{x1D6EF}}\)

\(\newcommand{\Omicronit}{\unicode{x1D6F0}}\)

\(\newcommand{\Piit}{\unicode{x1D6F1}}\)

\(\newcommand{\Rhoit}{\unicode{x1D6F2}}\)

\(\newcommand{\Sigmait}{\unicode{x1D6F4}}\)

\(\newcommand{\Tauit}{\unicode{x1D6F5}}\)

\(\newcommand{\Upsilonit}{\unicode{x1D6F6}}\)

\(\newcommand{\Phiit}{\unicode{x1D6F7}}\)

\(\newcommand{\Chiit}{\unicode{x1D6F8}}\)

\(\newcommand{\Psiit}{\unicode{x1D6F9}}\)

\(\newcommand{\Omegait}{\unicode{x1D6FA}}\)

\(\let \digammaup \Digammaup \)

\(\renewcommand {\digammait }{\mathit {\digammaup }}\)

\(\newcommand {\smallin }{\unicode {x220A}}\)

\(\newcommand {\smallowns }{\unicode {x220D}}\)

\(\newcommand {\notsmallin }{\LWRoverlaysymbols {/}{\unicode {x220A}}}\)

\(\newcommand {\notsmallowns }{\LWRoverlaysymbols {/}{\unicode {x220D}}}\)

\(\newcommand {\rightangle }{\unicode {x221F}}\)

\(\newcommand {\intclockwise }{\unicode {x2231}}\)

\(\newcommand {\ointclockwise }{\unicode {x2232}}\)

\(\newcommand {\ointctrclockwise }{\unicode {x2233}}\)

\(\newcommand {\oiint }{\unicode {x222F}}\)

\(\newcommand {\oiiint }{\unicode {x2230}}\)

\(\newcommand {\ddag }{\unicode {x2021}}\)

\(\newcommand {\P }{\unicode {x00B6}}\)

\(\newcommand {\copyright }{\unicode {x00A9}}\)

\(\newcommand {\dag }{\unicode {x2020}}\)

\(\newcommand {\pounds }{\unicode {x00A3}}\)

\(\newcommand {\iddots }{\unicode {x22F0}}\)

\(\newcommand {\utimes }{\overline {\times }}\)

\(\newcommand {\dtimes }{\underline {\times }}\)

\(\newcommand {\udtimes }{\overline {\underline {\times }}}\)

\(\newcommand {\leftwave }{\left \{}\)

\(\newcommand {\rightwave }{\right \}}\)

\(\newcommand {\toprule }[1][]{\hline }\)

\(\let \midrule \toprule \)

\(\let \bottomrule \toprule \)

\(\newcommand {\cmidrule }[2][]{}\)

\(\newcommand {\morecmidrules }{}\)

\(\newcommand {\specialrule }[3]{\hline }\)

\(\newcommand {\addlinespace }[1][]{}\)

\(\newcommand {\LWRsubmultirow }[2][]{#2}\)

\(\newcommand {\LWRmultirow }[2][]{\LWRsubmultirow }\)

\(\newcommand {\multirow }[2][]{\LWRmultirow }\)

\(\newcommand {\mrowcell }{}\)

\(\newcommand {\mcolrowcell }{}\)

\(\newcommand {\STneed }[1]{}\)

\( \newcommand {\multicolumn }[3]{#3}\)

\(\newcommand {\tothe }[1]{^{#1}}\)

\(\newcommand {\raiseto }[2]{{#2}^{#1}}\)

\(\newcommand {\ang }[2][]{(\mathrm {#2})\degree }\)

\(\newcommand {\num }[2][]{\mathrm {#2}}\)

\(\newcommand {\si }[2][]{\mathrm {#2}}\)

\(\newcommand {\LWRSI }[2][]{\mathrm {#1\LWRSInumber \,#2}}\)

\(\newcommand {\SI }[2][]{\def \LWRSInumber {#2}\LWRSI }\)

\(\newcommand {\numlist }[2][]{\mathrm {#2}}\)

\(\newcommand {\numrange }[3][]{\mathrm {#2\,\unicode {x2013}\,#3}}\)

\(\newcommand {\SIlist }[3][]{\mathrm {#2\,#3}}\)

\(\newcommand {\SIrange }[4][]{\mathrm {#2\,#4\,\unicode {x2013}\,#3\,#4}}\)

\(\newcommand {\tablenum }[2][]{\mathrm {#2}}\)

\(\newcommand {\ampere }{\mathrm {A}}\)

\(\newcommand {\candela }{\mathrm {cd}}\)

\(\newcommand {\kelvin }{\mathrm {K}}\)

\(\newcommand {\kilogram }{\mathrm {kg}}\)

\(\newcommand {\metre }{\mathrm {m}}\)

\(\newcommand {\mole }{\mathrm {mol}}\)

\(\newcommand {\second }{\mathrm {s}}\)

\(\newcommand {\becquerel }{\mathrm {Bq}}\)

\(\newcommand {\degreeCelsius }{\unicode {x2103}}\)

\(\newcommand {\coulomb }{\mathrm {C}}\)

\(\newcommand {\farad }{\mathrm {F}}\)

\(\newcommand {\gray }{\mathrm {Gy}}\)

\(\newcommand {\hertz }{\mathrm {Hz}}\)

\(\newcommand {\henry }{\mathrm {H}}\)

\(\newcommand {\joule }{\mathrm {J}}\)

\(\newcommand {\katal }{\mathrm {kat}}\)

\(\newcommand {\lumen }{\mathrm {lm}}\)

\(\newcommand {\lux }{\mathrm {lx}}\)

\(\newcommand {\newton }{\mathrm {N}}\)

\(\newcommand {\ohm }{\mathrm {\Omega }}\)

\(\newcommand {\pascal }{\mathrm {Pa}}\)

\(\newcommand {\radian }{\mathrm {rad}}\)

\(\newcommand {\siemens }{\mathrm {S}}\)

\(\newcommand {\sievert }{\mathrm {Sv}}\)

\(\newcommand {\steradian }{\mathrm {sr}}\)

\(\newcommand {\tesla }{\mathrm {T}}\)

\(\newcommand {\volt }{\mathrm {V}}\)

\(\newcommand {\watt }{\mathrm {W}}\)

\(\newcommand {\weber }{\mathrm {Wb}}\)

\(\newcommand {\day }{\mathrm {d}}\)

\(\newcommand {\degree }{\mathrm {^\circ }}\)

\(\newcommand {\hectare }{\mathrm {ha}}\)

\(\newcommand {\hour }{\mathrm {h}}\)

\(\newcommand {\litre }{\mathrm {l}}\)

\(\newcommand {\liter }{\mathrm {L}}\)

\(\newcommand {\arcminute }{^\prime }\)
\(\newcommand {\minute }{\mathrm {min}}\)

\(\newcommand {\arcsecond }{^{\prime \prime }}\)

\(\newcommand {\tonne }{\mathrm {t}}\)

\(\newcommand {\astronomicalunit }{au}\)

\(\newcommand {\atomicmassunit }{u}\)

\(\newcommand {\bohr }{\mathit {a}_0}\)

\(\newcommand {\clight }{\mathit {c}_0}\)

\(\newcommand {\dalton }{\mathrm {D}_\mathrm {a}}\)

\(\newcommand {\electronmass }{\mathit {m}_{\mathrm {e}}}\)

\(\newcommand {\electronvolt }{\mathrm {eV}}\)

\(\newcommand {\elementarycharge }{\mathit {e}}\)

\(\newcommand {\hartree }{\mathit {E}_{\mathrm {h}}}\)

\(\newcommand {\planckbar }{\mathit {\unicode {x210F}}}\)

\(\newcommand {\angstrom }{\mathrm {\unicode {x212B}}}\)

\(\let \LWRorigbar \bar \)

\(\newcommand {\bar }{\mathrm {bar}}\)

\(\newcommand {\barn }{\mathrm {b}}\)

\(\newcommand {\bel }{\mathrm {B}}\)

\(\newcommand {\decibel }{\mathrm {dB}}\)

\(\newcommand {\knot }{\mathrm {kn}}\)

\(\newcommand {\mmHg }{\mathrm {mmHg}}\)

\(\newcommand {\nauticalmile }{\mathrm {M}}\)

\(\newcommand {\neper }{\mathrm {Np}}\)

\(\newcommand {\yocto }{\mathrm {y}}\)

\(\newcommand {\zepto }{\mathrm {z}}\)

\(\newcommand {\atto }{\mathrm {a}}\)

\(\newcommand {\femto }{\mathrm {f}}\)

\(\newcommand {\pico }{\mathrm {p}}\)

\(\newcommand {\nano }{\mathrm {n}}\)

\(\newcommand {\micro }{\mathrm {\unicode {x00B5}}}\)

\(\newcommand {\milli }{\mathrm {m}}\)

\(\newcommand {\centi }{\mathrm {c}}\)

\(\newcommand {\deci }{\mathrm {d}}\)

\(\newcommand {\deca }{\mathrm {da}}\)

\(\newcommand {\hecto }{\mathrm {h}}\)

\(\newcommand {\kilo }{\mathrm {k}}\)

\(\newcommand {\mega }{\mathrm {M}}\)

\(\newcommand {\giga }{\mathrm {G}}\)

\(\newcommand {\tera }{\mathrm {T}}\)

\(\newcommand {\peta }{\mathrm {P}}\)

\(\newcommand {\exa }{\mathrm {E}}\)

\(\newcommand {\zetta }{\mathrm {Z}}\)

\(\newcommand {\yotta }{\mathrm {Y}}\)

\(\newcommand {\percent }{\mathrm {\%}}\)

\(\newcommand {\meter }{\mathrm {m}}\)

\(\newcommand {\metre }{\mathrm {m}}\)

\(\newcommand {\gram }{\mathrm {g}}\)

\(\newcommand {\kg }{\kilo \gram }\)

\(\newcommand {\of }[1]{_{\mathrm {#1}}}\)

\(\newcommand {\squared }{^2}\)

\(\newcommand {\square }[1]{\mathrm {#1}^2}\)

\(\newcommand {\cubed }{^3}\)

\(\newcommand {\cubic }[1]{\mathrm {#1}^3}\)

\(\newcommand {\per }{/}\)

\(\newcommand {\celsius }{\unicode {x2103}}\)

\(\newcommand {\fg }{\femto \gram }\)

\(\newcommand {\pg }{\pico \gram }\)

\(\newcommand {\ng }{\nano \gram }\)

\(\newcommand {\ug }{\micro \gram }\)

\(\newcommand {\mg }{\milli \gram }\)

\(\newcommand {\g }{\gram }\)

\(\newcommand {\kg }{\kilo \gram }\)

\(\newcommand {\amu }{\mathrm {u}}\)

\(\newcommand {\nm }{\nano \metre }\)

\(\newcommand {\um }{\micro \metre }\)

\(\newcommand {\mm }{\milli \metre }\)

\(\newcommand {\cm }{\centi \metre }\)

\(\newcommand {\dm }{\deci \metre }\)

\(\newcommand {\m }{\metre }\)

\(\newcommand {\km }{\kilo \metre }\)

\(\newcommand {\as }{\atto \second }\)

\(\newcommand {\fs }{\femto \second }\)

\(\newcommand {\ps }{\pico \second }\)

\(\newcommand {\ns }{\nano \second }\)

\(\newcommand {\us }{\micro \second }\)

\(\newcommand {\ms }{\milli \second }\)

\(\newcommand {\s }{\second }\)

\(\newcommand {\fmol }{\femto \mol }\)

\(\newcommand {\pmol }{\pico \mol }\)

\(\newcommand {\nmol }{\nano \mol }\)

\(\newcommand {\umol }{\micro \mol }\)

\(\newcommand {\mmol }{\milli \mol }\)

\(\newcommand {\mol }{\mol }\)

\(\newcommand {\kmol }{\kilo \mol }\)

\(\newcommand {\pA }{\pico \ampere }\)

\(\newcommand {\nA }{\nano \ampere }\)

\(\newcommand {\uA }{\micro \ampere }\)

\(\newcommand {\mA }{\milli \ampere }\)

\(\newcommand {\A }{\ampere }\)

\(\newcommand {\kA }{\kilo \ampere }\)

\(\newcommand {\ul }{\micro \litre }\)

\(\newcommand {\ml }{\milli \litre }\)

\(\newcommand {\l }{\litre }\)

\(\newcommand {\hl }{\hecto \litre }\)

\(\newcommand {\uL }{\micro \liter }\)

\(\newcommand {\mL }{\milli \liter }\)

\(\newcommand {\L }{\liter }\)

\(\newcommand {\hL }{\hecto \liter }\)

\(\newcommand {\mHz }{\milli \hertz }\)

\(\newcommand {\Hz }{\hertz }\)

\(\newcommand {\kHz }{\kilo \hertz }\)

\(\newcommand {\MHz }{\mega \hertz }\)

\(\newcommand {\GHz }{\giga \hertz }\)

\(\newcommand {\THz }{\tera \hertz }\)

\(\newcommand {\mN }{\milli \newton }\)

\(\newcommand {\N }{\newton }\)

\(\newcommand {\kN }{\kilo \newton }\)

\(\newcommand {\MN }{\mega \newton }\)

\(\newcommand {\Pa }{\pascal }\)

\(\newcommand {\kPa }{\kilo \pascal }\)

\(\newcommand {\MPa }{\mega \pascal }\)

\(\newcommand {\GPa }{\giga \pascal }\)

\(\newcommand {\mohm }{\milli \ohm }\)

\(\newcommand {\kohm }{\kilo \ohm }\)

\(\newcommand {\Mohm }{\mega \ohm }\)

\(\newcommand {\pV }{\pico \volt }\)

\(\newcommand {\nV }{\nano \volt }\)

\(\newcommand {\uV }{\micro \volt }\)

\(\newcommand {\mV }{\milli \volt }\)

\(\newcommand {\V }{\volt }\)

\(\newcommand {\kV }{\kilo \volt }\)

\(\newcommand {\W }{\watt }\)

\(\newcommand {\uW }{\micro \watt }\)

\(\newcommand {\mW }{\milli \watt }\)

\(\newcommand {\kW }{\kilo \watt }\)

\(\newcommand {\MW }{\mega \watt }\)

\(\newcommand {\GW }{\giga \watt }\)

\(\newcommand {\J }{\joule }\)

\(\newcommand {\uJ }{\micro \joule }\)

\(\newcommand {\mJ }{\milli \joule }\)

\(\newcommand {\kJ }{\kilo \joule }\)

\(\newcommand {\eV }{\electronvolt }\)

\(\newcommand {\meV }{\milli \electronvolt }\)

\(\newcommand {\keV }{\kilo \electronvolt }\)

\(\newcommand {\MeV }{\mega \electronvolt }\)

\(\newcommand {\GeV }{\giga \electronvolt }\)

\(\newcommand {\TeV }{\tera \electronvolt }\)

\(\newcommand {\kWh }{\kilo \watt \hour }\)

\(\newcommand {\F }{\farad }\)

\(\newcommand {\fF }{\femto \farad }\)

\(\newcommand {\pF }{\pico \farad }\)

\(\newcommand {\K }{\mathrm {K}}\)

\(\newcommand {\dB }{\mathrm {dB}}\)

\(\newcommand {\kibi }{\mathrm {Ki}}\)

\(\newcommand {\mebi }{\mathrm {Mi}}\)

\(\newcommand {\gibi }{\mathrm {Gi}}\)

\(\newcommand {\tebi }{\mathrm {Ti}}\)

\(\newcommand {\pebi }{\mathrm {Pi}}\)

\(\newcommand {\exbi }{\mathrm {Ei}}\)

\(\newcommand {\zebi }{\mathrm {Zi}}\)

\(\newcommand {\yobi }{\mathrm {Yi}}\)

\(\require {mhchem}\)

\(\require {cancel}\)

\(\newcommand {\fint }{âĺŊ}\)

\(\newcommand {\hdots }{\cdots }\)

\(\newcommand {\mathnormal }[1]{#1}\)

\(\newcommand {\vecs }[2]{\vec {#1}_{#2}}\)

\(\renewcommand {\O }{\ensuremath {\mathcal {O}}}\)

\(\newcommand {\vol }{\ensuremath {\operatorname {vol}}}\)

\(\renewcommand {\i }{\ensuremath {\mathrm {i}}}\)

\(\newcommand {\FFT }{\ensuremath {\operatorname {FFT}}}\)

\(\newcommand {\IFFT }{\ensuremath {\operatorname {IFFT}}}\)

\(\newcommand {\diag }{\ensuremath {\operatorname {diag}}}\)

\(\newcommand {\grad }{\ensuremath {\operatorname {grad}}}\)

\(\newcommand {\const }{\ensuremath {\operatorname {const}}}\)

\(\newcommand {\name }[1]{\textsc {#1}}\)

\(\newcommand {\smallpmatrix }[1]{\left (\begin {smallmatrix}#1\end {smallmatrix}\right )}\)

\(\newcommand {\matlab }{{\fontfamily {bch}\scshape \selectfont {}Matlab}}\)

\(\newcommand {\innerproduct }[1]{\left \langle {#1}\right \rangle }\)

\(\newcommand {\norm }[1]{\left \Vert {#1}\right \Vert }\)

\(\renewcommand {\natural }{\mathbb {N}}\)

\(\newcommand {\integer }{\mathbb {Z}}\)

\(\newcommand {\rational }{\mathbb {Q}}\)

\(\newcommand {\real }{\mathbb {R}}\)

\(\newcommand {\complex }{\mathbb {C}}\)

\(\renewcommand {\d }{\mathop {}\!\mathrm {d}}\)

\(\newcommand {\dr }{\d {}r}\)

\(\newcommand {\ds }{\d {}s}\)

\(\newcommand {\dt }{\d {}t}\)

\(\newcommand {\du }{\d {}u}\)

\(\newcommand {\dv }{\d {}v}\)

\(\newcommand {\dw }{\d {}w}\)

\(\newcommand {\dx }{\d {}x}\)

\(\newcommand {\dy }{\d {}y}\)

\(\newcommand {\dz }{\d {}z}\)

\(\newcommand {\dsigma }{\d {}\sigma }\)

\(\newcommand {\dphi }{\d {}\phi }\)

\(\newcommand {\dvarphi }{\d {}\varphi }\)

\(\newcommand {\dtau }{\d {}\tau }\)

\(\newcommand {\dxi }{\d {}\xi }\)

\(\newcommand {\dtheta }{\d {}\theta }\)

\(\newcommand {\tp }{\mathrm {T}}\)

</div>

<style type="text/css">
.lwarp-contents li.list-item-f0::marker {
  content:'•\00a0\00a0';
}
.lwarp-contents li.list-item-f1::marker {
  content:'•\00a0\00a0';
}
.lwarp-contents li.list-item-f2::marker {
  content:'•\00a0\00a0';
}
.lwarp-contents li.list-item-f3::marker {
  content:'•\00a0\00a0';
}
.lwarp-contents li.list-item-f4::marker {
  content:'•\00a0\00a0';
}
</style>
<p>

</p>


<h2 id="interpolation-mit-polynomen">Interpolation mit Polynomen</h2>

</p>

<h3 id="lagrange-form-und-4-punkt-formel"><span style="font-variant: small-caps;">Lagrange</span>-Form und 4-Punkt-Formel</h3>

</p>

<p>
Gegeben seien \(n + 1\) paarweise verschiedene Stu&#x0308;tzstellen \(x_0, \dotsc , x_n\) mit Funktionswerten<br />
\(f_0, \dotsc , f_n\). Dann ko&#x0308;nnen diese eindeutig durch ein Polynom \(p\) mit Grad \(\le n\) interpoliert werden (<b>polynomiale Interpolation</b>):
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                  p(x k ) = f k             für        k = 0, . . . , n.



-->


<p>

\begin{align*}
p(x_k) = f_k \quad \text { fÃijr }\quad k = 0, \dotsc , n.
\end{align*}
Das Interpolationspolynom \(p\) la&#x0308;sst sich in der <b><span class="textsc" >Lagrange</span>-Form</b> darstellen:
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                       n
                                                                                                                       X                                        Y x − xj
                                                                                                       p(x) =                   f k qk (x),       qk (x) =                           .
                                                                                                                       k=0                                      j6=k
                                                                                                                                                                        xk − x j



-->


<p>

\begin{align*}
p(x) = \sum _{k=0}^n f_k q_k(x), \quad q_k(x) = \prod _{j \not = k} \frac {x - x_j}{x_k - x_j}.
\end{align*}
Die \(q_k\) heißen dabei <b><span class="textsc" >Lagrange</span>-Polynome</b>. Sie haben in \(x_k\) den Wert \(1\) und verschwinden in allen anderen Punkten \(x_j\), d.&#x202f;h. \(q_k(x_j) =
\delta _{kj}\).
</p>
<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
<b>Generation von Zwischenwerten mittels kubischer Interpolation (4-Punkt-Formel)</b>:<br />
Sind die \(f_k\) an a&#x0308;quidistanten Stu&#x0308;tzstellen gegeben, d.&#x202f;h. \(x_k = kh\) mit \(h\) Gitterweite, \(k = 0, \dotsc , n\), so kann man Zwischenwerte an den Stu&#x0308;tzstellen \(x_{k +
1/2} = (k + 1/2)h\) durch kubische Interpolation approximieren. Zur Interpolation verwendet man dazu die vier benachbarten Stu&#x0308;tzstellen \(x_{k-1}, x_k, x_{k+1}, x_{k+2}\). Dabei ergibt sich die
Formel
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                           f k+1/2 = (− f k−1 + 9 f k + 9 f k+1 − f k+2 )/16.



-->


<p>

\begin{align*}
f_{k + 1/2} = (-f_{k-1} + 9f_k + 9f_{k+1} - f_{k+2}) / 16.
\end{align*}
Den Prozess kann man solange wiederholen, bis genu&#x0308;gend Daten erzeugt wurden. Die Gewichte \(-\frac {1}{16}, \frac {9}{16}, \frac {9}{16}, -\frac {1}{16}\) sind die Werte der
Lagrange-Polynome an der neuen Stu&#x0308;tzstelle \(x_{k + 1/2}\). Um \(x_{1/2}\) bzw. \(x_{n - 1/2}\) zu approximieren, verwendet man die Stu&#x0308;tzstellen \(x_0, x_1, x_2, x_3\) bzw.<br />
\(x_{n-3}, x_{n-2}, x_{n-1}, x_n\) (fu&#x0308;r \(x_{1/2}\) ergibt sich z.&#x202f;B. \(f_{1/2} = (5f_0 + 15f_1- 5f_2 + f_3) / 16\)).
</p>
<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
<b>Scha&#x0308;tzformel fu&#x0308;r zweite Ableitung</b>:<br />
Fu&#x0308;r die erste Ableitung \(f’\) einer Funktion \(f\) gilt \(f’(x) \approx \frac {f(x) - f(x - h)}{h}\). Daraus folgt fu&#x0308;r die zweite Ableitung durch Taylorentwicklung (\(f(x + h) = f(x)
+ f’(x)h + \frac {1}{2} f”(x) h^2 + o(h^2)\), \(h \to 0\))
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                   f (x + h) − f (x) − f 0 (x)h   f (x + h) − 2 f (x) + f (x − h)
                                                                                      f 00 (x) ≈                                ≈                                 .
                                                                                                               h2                               h2


-->


<p>

\begin{align*}
f”(x) \approx \frac {f(x + h) - f(x) - f’(x)h}{h^2} \approx \frac {f(x + h) - 2f(x) + f(x - h)}{h^2}.
\end{align*}

</p>


<h3 id="schema-von-aitken-neville">Schema von <span style="font-variant: small-caps;">Aitken</span>-<span style="font-variant: small-caps;">Neville</span></h3>

</p>

<p>
Gegeben seien wieder \(n + 1\) Datenpunkte \((x_i, f_i)\), \(i = 0, \dotsc , n\) mit \(x_0 &lt; \dotsb &lt; x_n\).<br />
Dann la&#x0308;sst sich der Wert \(p(x)\) des Interpolationspolynoms an der Stelle \(x \in [x_0, x_n]\) mithilfe eines Dreiecksschemas (<b>Schema von <span class="textsc" >Aitken</span>-<span
class="textsc" >Neville</span></b>) berechnen:
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                      f0 = p00
                                                                                     &                                                                              mit
                                                                       f1 = p10      →       p01                                                                        j         x i+ j − x     j−1         x − x i j−1
                                                                                                                                                                    pi :=                      pi      +               p ,
                                                                          ..                          ..                                                                   x i+ j − x i                    x i+ j − x i i+1
                                                                           .                               .
                                                                                                                                                                    pi0 := f i ,
                                                                    f n−1 = pn−1
                                                                              0
                                                                                             ···                 p0n−1
                                                                                     &                                       &                                      j = 1, . . . , n,          i = 0, . . . , n − j.
                                                                      f n = pn0      →       1
                                                                                            pn−1      ···        p1n−1       →          p0n = p(x)


-->


<p>

\begin{align*}
\begin{array}{ccccccc} f_0 = p_0^0 \\ &amp; \searrow \\ f_1 = p_1^0 &amp; \rightarrow &amp; p_0^1 \\ \vdots &amp; &amp; &amp; \ddots \\ f_{n-1} = p_{n-1}^0
&amp; &amp; \cdots &amp; &amp; p_0^{n-1} \\ &amp; \searrow &amp; &amp; &amp; &amp; \searrow \\ f_n = p_n^0 &amp; \rightarrow &amp; p_{n-1}^1 &amp; \cdots
&amp; p_1^{n-1} &amp; \rightarrow &amp; p_0^n = p(x) \end {array}\qquad \begin{array}{l} \text {mit} \\ p_i^j := \dfrac {x_{i+j} - x}{x_{i+j} - x_i}
p_i^{j-1} + \dfrac {x - x_i}{x_{i+j} - x_i} p_{i+1}^{j-1}, \\ p_i^0 := f_i, \\[3mm] j = 1, \dotsc , n,\quad i = 0, \dotsc , n - j. \end {array}
\end{align*}

</p>
<p>
Dabei ist \(p_i^j = p_i^j(x)\) ein Polynom vom Grad \(\le j\), das an den Punkten \(x_i, \dotsc , x_{i+j}\) interpoliert. Der Vorteil dieses Dreiecksschemas ist, dass zur Verbesserung der Genauigkeit weitere
Datenpunkte sehr einfach als neue Zeile am unteren Rand hinzugefu&#x0308;gt werden ko&#x0308;nnen, ohne alle Werte neu zu berechnen (anders als z.&#x202f;B. mit Lagrange-Polynomen).
</p>
<p>
Das Aitken-Neville-Schema kann auch dazu benutzt werden, algorithmisch die Koeffizienten des Interpolationspolynoms zu berechnen. Dazu berechnet man das Schema spaltenweise und speichert in einer Matrix die Koeffizienten der
Polynome der vorherigen Spalte. Die neuen Koeffizienten ko&#x0308;nnen dann mithilfe der Definition von \(p_i^j\) berechnet werden.
</p>


<h3 id="polynome-in-newton-form-horner-schema">Polynome in <span style="font-variant: small-caps;">Newton</span>-Form, <span style="font-variant: small-caps;">Horner</span>-Schema</h3>

</p>

<p>
Seien ein Polynom \(p\) vom Grad \(\le n\) und \(n\) Punkte \(x_0, \dotsc , x_{n-1}\) gegeben.<br />
Dann ist die <b><span class="textsc" >Newton</span>-Form</b> von \(p\) bezu&#x0308;glich der Punktfolge \(x_0, \dotsc , x_{n-1}\)
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                              p(x) = a0 + a1 (x − x 0 ) + · · · + an (x − x 0 ) · · · (x − x n−1 ).



-->


<p>

\begin{align*}
p(x) = a_0 + a_1 (x - x_0) + \dotsb + a_n (x - x_0) \dotsm (x - x_{n-1}).
\end{align*}
Dies kann als verallgemeinerte Taylor-Darstellung aufgefasst werden, denn fu&#x0308;r \(x_0 = \dotsb = x_{n-1}\) erha&#x0308;lt man insbesondere die Taylor-Entwicklung von \(p\) im Punkt \(x_0\).
</p>
<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
Die Auswertung eines Polynoms in Newton-Form kann mittels <b><span class="textsc" >Horner</span>-Schema</b> erfolgen:
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                     p(x) = (· · · (an yn−1 + an−1 ) yn−2 + · · · ) y0 + a0



-->


<p>

\begin{align*}
p(x) = (\dotsb (a_n y_{n-1} + a_{n-1}) y_{n-2} + \dotsb ) y_0 + a_0
\end{align*}
mit \(y_k = x - x_k\), \(k = 0, \dotsc , n - 1\).<br />
Durch die geschachtelte Multiplikation beno&#x0308;tigt man nur \(3n\) Operationen:<br />
Anfangs setzt man \(p := a_n\) und dann berechnet man \(p \leftarrow p y_k + a_k\) fu&#x0308;r \(k = n - 1, \dotsc , 0\).
</p>
<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
<b>Umwandlung eines Polynoms von Normalform \(\sum _{k=0}^n c_k x^k\) in <span class="textsc" >Newton</span>-Form</b>:<br />
Der Koeffizient \(a_n\) der Newton-Form ist der Koeffizient von \(x^n\), denn \(p(x) = a_n x^n + \O (x^{n-1})\). So kann man die Newton-Form rekursiv berechnen: \(a_n\) ist der ho&#x0308;chste Koeffizient von
\(p(x)\), dann subtrahiert man den letzten Summanden \(q(x) = p(x) - a_n (x - x_0) \dotsm (x - x_{n-1})\). \(a_{n-1}\) ist wiederum der ho&#x0308;chste Koeffizient dieses Restterms \(q(x)\) usw.
</p>


<h3 id="hermite-interpolation"><span style="font-variant: small-caps;">Hermite</span>-Interpolation</h3>

</p>

<p>
Seien eine glatte Funktion \(f\) und \(n + 1\) Punkte \(x_0, \dotsc , x_n\) (nicht notwendig verschieden) gegeben.<br />
Dann gibt es genau ein Polynom \(p\) vom Grad \(\le n\) mit
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                 p( j) (x k ) = f ( j) (x k ),           0 ≤ j < mk ,



-->


<p>

\begin{align*}
p^{(j)}(x_k) = f^{(j)}(x_k), \quad 0 \le j &lt; m_k,
\end{align*}
wobei \(m_k\) die Vielfachheit des Punktes \(x_k\) ist (\(k = 0, \dotsc , n\)). Tritt also ein Punkt mehrfach auf, so werden nicht nur Funktionswerte, sondern auch Ableitungen interpoliert. Dieses Interpolationsverfahren
heißt <b><span class="textsc" >Hermite</span>-Interpolation</b>.
</p>
<p>
Im Schaubild werden Vielfachheiten durch eng nebeneinander liegende Markierungen auf der \(x\)-Achse oder zusa&#x0308;tzliche Kreise um die Interpolationspunkte angedeutet.
</p>
<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
Sind Daten in der Form \((x_k, f_k)\) gegeben, so verwendet man meistens die Konvention, dass \(f_k = p^{(j)}(x_k)\), wobei \(j\) die Anzahl der Punkte \(x_i\) mit \(x_i = x_k\) und \(i &lt; k\) ist.
</p>
<p>
Im Beispiel \((1, 3), (2, 1), (2, 0), (2, 2), (4, 2), (4, 1)\) interpoliert das Polynom der Hermite-Interpolation \(f(1), f(2), f’(2), f”(2), f(4), f’(4)\).
</p>


<h3 id="dividierte-differenzen">Dividierte Differenzen</h3>

</p>

<p>
Die <b>Dividierte Differenz</b> ist eine Verallgemeinerung des Differenzenquotienten
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                                                f (a) − f (b)
                                                                                                                           ∆(a, b) f =                        .
                                                                                                                                                    a−b


-->


<p>

\begin{align*}
\Delta (a, b)f = \frac {f(a) - f(b)}{a - b}.
\end{align*}
Sie ist rekursiv definiert:
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                           ∆(x 1 , . . . , x n ) f − ∆(x 0 , . . . , x n−1 ) f
                                                                              ∆(x 0 , . . . , x n ) f :=                                                                        für x 0 6= x n         sowie
                                                                                                                                 x n − x0


-->


<p>

\begin{align*}
\Delta (x_0, \dotsc , x_n)f := \frac {\Delta (x_1, \dotsc , x_n)f - \Delta (x_0, \dotsc , x_{n-1})f}{x_n - x_0} \quad \text { fÃijr } x_0 \not = x_n \quad
\text { sowie }
\end{align*}

</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                                             1 (n)
                                                                                                                       ∆(x, . . . , x ) f :=    f (x).
                                                                                                                         | {z }              n!
                                                                                                                                n+1-mal



-->


<p>

\begin{align*}
\Delta (\underbrace {x, \dotsc , x}_{n + 1 \text {-mal}})f := \frac {1}{n!} f^{(n)}(x).
\end{align*}
Insbesondere ist \(\Delta (x)f = f(x)\).
</p>
<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
Die Dividierten Differenzen
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                                                              j−1           j−1
                                                                                                                  j                                       ∆i+1 − ∆i
                                                                                                               ∆i := ∆(x i , . . . , x i+ j ) =
                                                                                                                                                              x i+ j − x i


-->


<p>

\begin{align*}
\Delta _i^j := \Delta (x_i, \dotsc , x_{i+j}) = \frac {\Delta _{i+1}^{j-1} - \Delta _i^{j-1}}{x_{i+j} - x_i}
\end{align*}
ko&#x0308;nnen in einem <b>Dreiecksschema</b> berechnet werden:
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                           x0         ∆00     ∆10       ∆20     ∆30
                                                                                                                           x1         ∆01     ∆11       ∆21
                                                                                                                           x2         ∆02     ∆12
                                                                                                                           x3         ∆03


-->


<p>

\begin{align*}
\begin{array}{c||cccc} x_0 &amp; \Delta _0^0 &amp; \Delta _0^1 &amp; \Delta _0^2 &amp; \Delta _0^3 \\ x_1 &amp; \Delta _1^0 &amp; \Delta _1^1 &amp; \Delta
_1^2 \\ x_2 &amp; \Delta _2^0 &amp; \Delta _2^1 \\ x_3 &amp; \Delta _3^0 \end {array}
\end{align*}
Dabei ha&#x0308;ngt der Eintrag \(\Delta _i^j\) vom Eintrag links (\(\Delta _i^{j-1}\)) und links unten (\(\Delta _{i+1}^{j-1}\)) ab.<br />
Die Daten mu&#x0308;ssen vorgegeben sein, falls es keine zwei verschiedene Stellen in \(\Delta _i^j\) gibt. Startwerte sind dabei Funktionswerte oder bei Vielfachheiten Ableitungswerte von \(f\) an den Punkten \(x_k\).
Dabei schreibt man in die \(j\)-te Spalte \(\frac {1}{j!} f^{(j)}(x_k)\) (nach Definition der Dividierten Differenz).<br />
Ansonsten, falls es zwei verschiedene Stellen in \(\Delta _i^j\) gibt, kann man den Eintrag mittels der Definition der Dividierten Differenz berechnen.
</p>


<h3 id="integraldarstellung-dividierter-differenzen">Integraldarstellung Dividierter Differenzen</h3>

</p>

<p>
Die Dividierte Differenz \(\Delta (x_0, \dotsc , x_n)f\) la&#x0308;sst sich als Integral u&#x0308;ber den von den Einheitsvektoren aufgespannten Simplex darstellen (<b>Formel von <span class="textsc"
>Hermite</span>-<span class="textsc" >Genocchi</span></b>):
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--

                                                                                                                                 
                                                                                               ∆(x 0 , . . . , x n ) f =                             f (n) (s0 x 0 + · · · + sn x n ) ds.
                                                                                                                                     s0 +···+sn =1




-->


<p>

\begin{align*}
\Delta (x_0, \dotsc , x_n)f = \int _{s_0 + \dotsb + s_n = 1} f^{(n)}(s_0 x_0 + \dotsb + s_n x_n)\ds .
\end{align*}
Daraus folgt insbesondere, dass Dividierte Differenzen fu&#x0308;r glatte Funktionen \(f\) stetig von den Punkten \(x_k\) abha&#x0308;ngen und
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                                 f (n) (ξ)
                                                                                              ∆(x 0 , . . . , x n ) f =                         mit ξ ∈ [min x k , max x k ].
                                                                                                                                    n!


-->


<p>

\begin{align*}
\Delta (x_0, \dotsc , x_n)f = \frac {f^{(n)}(\xi )}{n!} \quad \text {mit}\quad \xi \in [\min x_k, \max x_k].
\end{align*}

</p>
<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
Ein \(n\)-dimensionaler <b>Simplex</b> ist dabei die konvexe Hu&#x0308;lle \(S\) von \(n + 1\) Punkten \(p_0, \dotsc , p_n\), die nicht alle in einem \(n - 1\)-dimensionalen Unterraum liegen:
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--

                                                                                                                       (                                                    )
                                                                                                                           n
                                                                                                                           X                 n
                                                                                                                                             X
                                                                                                               S=                αj pj               α j = 1, α j ≥ 0 .
                                                                                                                           j=0                j=0




-->


<p>

\begin{align*}
S = \left \{\left .\sum _{j=0}^n \alpha _j p_j \;\right |\; \sum _{j=0}^n \alpha _j = 1,\; \alpha _j \ge 0\right \}.
\end{align*}
Das Volumen eines Simplex la&#x0308;sst sich durch die Vektoren \(p_i - p_0\), \(i = 1, \dotsc , n\) ausdru&#x0308;cken:
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                            1
                                                                                                               vol S =         · | det(p1 − p0 , . . . , pn − p0 )|.
                                                                                                                            n!


-->


<p>

\begin{align*}
\vol S = \frac {1}{n!} \cdot |\det (p_1 - p_0, \dotsc , p_n - p_0)|.
\end{align*}

</p>


<h3 id="newton-form-und-dividerte-differenzen"><span style="font-variant: small-caps;">Newton</span>-Form und Dividerte Differenzen</h3>

</p>

<p>
Die <b>Newton-Form</b> des Polynoms \(p\) vom Grad \(\le n\), das eine Funktion \(f\) an den Punkten \(x_0, \dotsc , x_n\) interpoliert, la&#x0308;sst sich <b>mithilfe Dividerter Differenzen</b> angeben:
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                     p(x) = a0 + a1 (x − x 0 ) + · · · + an (x − x 0 ) · · · (x − x n−1 ),                             ak = ∆(x 0 , . . . , x k ) f , k = 0, . . . , n.



-->


<p>

\begin{align*}
p(x) = a_0 + a_1 (x - x_0) + \dotsb + a_n (x - x_0) \dotsm (x - x_{n-1}), \quad \; a_k = \Delta (x_0, \dotsc , x_k)f,\;\; k = 0, \dotsc , n.
\end{align*}
Dabei werden an einem Punkt mit Vielfachheit \(m\) zusa&#x0308;tzlich auch alle Ableitungen der Ordnung \(&lt; m\) interpoliert.
</p>
<p>
Die Newton-Form ist insbesondere geeignet, wenn man weitere Interpolationspunkte hinzufu&#x0308;gen will. Die Darstellung braucht dann jeweils um nur einen weiteren Term erga&#x0308;nzt zu werden, die vorherigen Terme
bleiben inklusive Koeffizienten gleich. Das Schema zur Berechnung des neuen ho&#x0308;chsten Koeffizienten als Dividerte Differenz wird um eine neue Diagonale erga&#x0308;nzt.<br />
Außerdem ko&#x0308;nnen Ableitungen mit der Newton-Form einfach interpoliert werden.
</p>


<h3 id="fehler-bei-der-interpolation-glatter-funktionen">Fehler bei der Interpolation glatter Funktionen</h3>

</p>

<p>
Der <b>Fehler des Polynoms</b> \(p\) vom Grad \(\le n\), das eine glatte Funktion an den Punkten \(x_0, \dotsc , x_n\) interpoliert, la&#x0308;sst sich darstellen in der Form
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                f (n+1) (ξ)
                                                                            f (x) − p(x) =                  (x − x 0 ) · · · (x − x n )                   mit       ξ ∈ [min{x, x k }, max{x, x k }] .
                                                                                                 (n + 1)!


-->


<p>

\begin{align*}
f(x) - p(x) = \frac {f^{(n+1)}(\xi )}{(n + 1)!} (x - x_0) \dotsm (x - x_n) \quad \text {mit}\quad \xi \in \left [\min \{x, x_k\}, \max \{x, x_k\}\right ].
\end{align*}
Insbesondere gilt fu&#x0308;r a&#x0308;quidistante Punkte \(x_k = x_0 + kh\), \(k = 0, \dotsc , n\)
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                   | f (x) − p(x)| = O (hn+1 ),                       h → 0,           x0 ≤ x ≤ x n.



-->


<p>

\begin{align*}
|f(x) - p(x)| = \O (h^{n+1}),\quad h \to 0, \quad x_0 \le x \le x_n.
\end{align*}
Fu&#x0308;r \(x_0 = \dotsb = x_n\) erha&#x0308;lt man die Formel fu&#x0308;r das Taylor-Restglied.
</p>
<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
Wie man in der Fehlerformel sieht, ha&#x0308;ngt der Fehler stark davon ab, welche Stu&#x0308;tzpunkte man fu&#x0308;r eine gegebene zu approximierende Funktion wa&#x0308;hlt. Setzt man die Punkte
a&#x0308;quidistant, so weicht die Approximation zu den Ra&#x0308;ndern hin stark von der Funktion ab und „pendelt“ hin und her. Dies kann man vermeiden, indem man am Rand mehr Punkte (also dichter) wa&#x0308;hlt, da
dort Informationen im Vergleich zur Mitte „fehlen“.
</p>
<p>
Mit den <b><span class="textsc" >Tschebyscheff</span>-Polynomen</b>
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                               Tn (x) = cos(n arccos x),                      x ∈ [−1, 1]



-->


<p>

\begin{align*}
T_n(x) = \cos (n \arccos x),\quad x \in [-1, 1]
\end{align*}
la&#x0308;sst sich besser approxmieren, indem man die Nullstellen von \(T_n\)
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                            2i + 1
                                                                                                                                   
                                                                                                            (n)
                                                                                                           ξi         = cos        π ,                   i = 0, . . . , n − 1
                                                                                                                             2n


-->


<p>

\begin{align*}
\xi _i^{(n)} = \cos \left (\frac {2i + 1}{2n} \pi \right ),\quad i = 0, \dotsc , n - 1
\end{align*}
als Stu&#x0308;tzpunkte verwendet. Diese heißen <b>Tschebyscheff-Knoten</b> und basieren auf einer a&#x0308;quidistanten Winkelunterteilung im Halbkreis. Sie sind daher am Rand dichter verteilt wie in der Mitte.
Verwendet man die Tschebyscheff-Knoten als Stu&#x0308;tzstellen bei der Interpolation, so verringert sich der Fehler an den Ra&#x0308;ndern deutlich.
</p>


<h3 id="polynominterpolation-mit-matlab">Polynominterpolation mit MATLAB</h3>

</p>

<p>
Die Koeffizienten eines Polynoms \(p(x) = a_1 x^n + \dotsb + a_n x + a_{n+1}\) vom Grad \(\le n\), das die Daten \((x_k, y_k)\) interpoliert, ko&#x0308;nnen in M ATLAB mit <span
class="inlineprogramlisting">a = polyfit(x, y, n</span>); ermittelt werden. Wenn \(n\) kleiner ist als die Anzahl der Datenpunkte minus \(1\), so wird das Polynom, das die Fehlerquadratsumme
minimiert, bestimmt. Mit <span class="inlineprogramlisting">p = polyval(a, x</span>); kann das Polynom in den Punkten \(x_k\) ausgewertet werden (d.&#x202f;h. \(p_k = p(x_k)\)).
</p>


<h2 id="orthogonale-polynome">Orthogonale Polynome</h2>

</p>

<h3 id="allgemeines">Allgemeines</h3>

</p>

<p>
Zu jeder auf einem Intervall \((a, b)\) positiven Gewichtsfunktion \(w\) existiert eine bzgl. des Skalarprodukts \(\innerproduct {f, g} := \int _a^b f g w\) orthogonale Folge von Polynomen
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                pn (x) = αn x n + O (x n−1 ),                    αn 6= 0.



-->


<p>

\begin{align*}
p_n(x) = \alpha _n x^n + \O (x^{n-1}),\quad \alpha _n \not = 0.
\end{align*}
Bis auf die Normierungsfaktoren \(\alpha _n\) sind die <b>orthogonalen Polynome</b> durch die Orthogonalita&#x0308;tsbedingungen \(\innerproduct {p_m, p_n} = 0\) fu&#x0308;r \(m \not = n\)
eindeutig bestimmt und ko&#x0308;nnen mit dem Orthongalisierungsverfahren von <span class="textsc" >Gram</span>-<span class="textsc" >Schmidt</span> bestimmt werden.
</p>
<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
<b>Orthogonalisierungsverfahren von <span class="textsc" >Gram</span>-<span class="textsc" >Schmidt</span></b>: Sei \(b_1, \dotsc , b_n\) Basis eines Vektorraums \(V\). Dann kann
man eine orthogonale Basis \(u_1, \dotsc , u_n\) durch
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                               j−1
                                                                                                                               X   b j , uk
                                                                                                          u j := b j −                               uk ,       j = 1, . . . , n
                                                                                                                               k=1
                                                                                                                                        〈uk , uk 〉


-->


<p>

\begin{align*}
u_j := b_j - \sum _{k=1}^{j-1} \frac {\innerproduct {b_j, u_k}}{\innerproduct {u_k, u_k}} u_k, \quad j = 1, \dotsc , n
\end{align*}
konstruieren.
</p>
<p>
Beim analogen <b>Orthonormalisierungsverfahren von <span class="textsc" >Gram</span>-<span class="textsc" >Schmidt</span></b> vereinfacht sich die Rekursion, da man die Basisvektoren nach
jedem Schritt normiert:
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                   j−1
                                                                                                                   X                                           uj
                                                                                          u j := b j −                      b j , uk uk ,         uj ←                  ,           j = 1, . . . , n.
                                                                                                                   k=1                                         uj


-->


<p>

\begin{align*}
u_j := b_j - \sum _{k=1}^{j-1} \innerproduct {b_j, u_k} u_k, \quad u_j \leftarrow \frac {u_j}{\norm {u_j}}, \quad j = 1, \dotsc , n.
\end{align*}

</p>
<p>
Im Falle der orthogonalen Polynome geht man von der Monom-Basis \(\alpha _0 x^0, \dotsc , \alpha _n x^n\) aus.
</p>
<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
Zur Bestimmung der orthogonalen Polynome fu&#x0308;r \((a, b) = (0, 1)\), \(w(x) \equiv 1\) kann man auch anders vorgehen: Die eine Methode berechnet iterativ das Polynom \(p_n\) aus den vorhergehenden,
schon bekannten Polynomen \(p_k\), \(k = 0, \dotsc , n - 1\).<br />
Dabei wird \(p_n(x) = \alpha _n x^n + c_{n-1} x^{n-1} + \dotsb + c_1 x + c_0\) allgemein angesetzt (\(\alpha _n\) bekannter Normierungsfaktor). Aus den
Orthogonalita&#x0308;tsbedingungen<br />
\(0 = \innerproduct {p_n, p_k} = \int _0^1 \left (\alpha _n x^n + \sum _{i=0}^{n-1} c_i x^i\right ) p_k(x) \dx \) fu&#x0308;r \(k = 0, \dotsc , n - 1\) folgen dann
\(n\) Gleichungen fu&#x0308;r die \(n\) Unbekannten \(c_0, \dotsc , c_{n-1}\). Das Lo&#x0308;sen des LGS liefert die gesuchten Koeffizienten.
</p>
<p>
Mit der anderen Art kann das Polynom \(p_n\) auch direkt bestimmt werden, ohne die vorherigen \(p_k\), \(k = 0, \dotsc , n - 1\) zu kennen. Da man weiß, dass \(p_n(x) = \alpha _n x^n + \sum
_{k=0}^{n-1} c_k x^k\) zu allen Polynomen vom Grad \(&lt; n\) und damit auch zu den Monomen \(x^j\), \(j = 0, \dotsc , n - 1\) orthogonal ist, setzt man
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                 1              n−1
                                                                                                                                                             n−1
                                                                                                  X                                                           X       1            αn
                                                                                       αn x n +            ck x k x j dx = 0                      ⇔                       ck = −
                                                                                 0                k=0                                                         k=0
                                                                                                                                                                    j+k+1        n+ j+1


-->


<p>

\begin{align*}
\int _0^1 \left (\alpha _n x^n + \sum _{k=0}^{n-1} c_k x^k\right ) x^j \dx = 0 \quad \Leftrightarrow \quad \sum _{k=0}^{n-1} \frac {1}{j + k + 1} c_k = -
\frac {\alpha _n}{n + j + 1}
\end{align*}
und erha&#x0308;lt die Koeffizienten durch Lo&#x0308;sen des LGS mit der sog. <b><span class="textsc" >Hilbert</span>-Matrix</b>
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                                             1          1                           1
                                                                                                                                                                 ...
                                                                                                                                                                                          
                                                                                                                                              1          2                           n
                                                                                                                                              1          1                           1
                                                                                                      
                                                                                                             1
                                                                                                                            n               2          3       ...                n+1 
                                                                                                                                     =
                                                                                                                                       ..               ..                          .. 
                                                                                                                                                                                        .
                                                                                                          i+ j−1              i, j=1     .                .                           .
                                                                                                                                              1        1                          1
                                                                                                                                              n       n+1        ...            2n−1



-->


<p>

\begin{align*}
\left (\frac {1}{i + j - 1}\right )_{i,j=1}^n = \begin{pmatrix} \frac {1}{1} &amp; \frac {1}{2} &amp; \dots &amp; \frac {1}{n} \\ \frac {1}{2} &amp; \frac
{1}{3} &amp; \dots &amp; \frac {1}{n + 1} \\ \vdots &amp; \vdots &amp; &amp; \vdots \\ \frac {1}{n} &amp; \frac {1}{n + 1} &amp; \dots &amp; \frac {1}{2n -
1} \end {pmatrix}.
\end{align*}

</p>


<h3 id="dreigliedrige-rekursion-fuer-orthogonale-polynome">Dreigliedrige Rekursion für orthogonale Polynome</h3>

</p>

<p>
Die orthogonalen Polynome \(q_n = x^n + \O (x^{n-1})\) mit Nomierungsfaktor \(1\) zu einer Gewichtsfunktion \(w\) auf einem Intervall \((a, b)\) ko&#x0308;nnen rekursiv berechnet werden:
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--



                                                                                                            qn+1 = (ξ − βn )qn − γn qn−1 ,                                  n≥2



-->


<p>

\begin{align*}
q_{n+1} = (\xi - \beta _n) q_n - \gamma _n q_{n-1},\quad n \ge 2
\end{align*}
mit \(\xi (x) := x\) (<b>dreigliedrige Rekursion</b>). Die Koeffizienten \(\beta _n\) und \(\gamma _n\) lassen sich mithilfe des Skalarprodukts \(\innerproduct {f, g} = \int _a^b f g w\)
ausdru&#x0308;cken:
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                       〈ξqn , qn 〉                            %n
                                                                                          βn :=                    ,             γn :=                        mit %n := 〈qn , qn 〉 .
                                                                                                          %n                                 %n−1


-->


<p>

\begin{align*}
\beta _n := \frac {\innerproduct {\xi q_n, q_n}}{\varrho _n},\quad \gamma _n := \frac {\varrho _n}{\varrho _{n-1}} \quad \text {mit}\quad \varrho _n :=
\innerproduct {q_n, q_n}.
\end{align*}

</p>
<p>
Fu&#x0308;r orthogonale Polynome \(p_n(x) = \alpha _n x^n + \O (x^{n-1})\) mit allgemeinem Normierungsfaktor \(\alpha _n\) gilt die Rekursion
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                        αn+1                αn−1 αn+1 0
                                                                                                      pn+1 =                 (ξ − βn0 )pn −          γn pn−1 ,
                                                                                                                         αn                    α2n


-->


<p>

\begin{align*}
p_{n+1} = \frac {\alpha _{n+1}}{\alpha _n} (\xi - \beta ’_n) p_n - \frac {\alpha _{n-1} \alpha _{n+1}}{\alpha _n^2} \gamma ’_n p_{n-1},
\end{align*}
wobei die Formeln fu&#x0308;r \(\beta ’_n, \gamma ’_n\) aus denen von \(\beta _n, \gamma _n\) entstehen, wenn man \(q_n\) durch \(p_n\) ersetzt.
</p>


<h3 id="nullstellen-orthogonaler-polynome">Nullstellen orthogonaler Polynome</h3>

</p>

<p>
Das orthogonale Polynom \(p_n\) vom Grad \(n\) zu einer Gewichtsfunktion \(w\) auf \((a, b)\) hat \(n\) einfache Nullstellen in \((a, b)\). (Diese liegen zwischen denen von \(p_{n+1}\).)
</p>


<h3 id="legendre-polynome"><span style="font-variant: small-caps;">Legendre</span>-Polynome</h3>

</p>

<p>
Die <b><span class="textsc" >Legendre</span>-Polynome</b>
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                    1        dn               (2n)! n
                                                                                           pn (x) :=                             (x 2 − 1)n = n      x + O (x n−1 )
                                                                                                                   2n n!    d xn             2 (n!)2


-->


<p>

\begin{align*}
p_n(x) := \frac {1}{2^n n!} \frac {d^n}{dx^n} (x^2 - 1)^n = \frac {(2n)!}{2^n (n!)^2} x^n + \O (x^{n-1})
\end{align*}
sind bzgl. des Skalarprodukts \(\innerproduct {f, g} = \int _{-1}^1 f g\) orthogonal.<br />
Sie sind Lo&#x0308;sungen der Differentialgleichung
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--



                                                                                                                        ((1 − ξ2 )pn0 )0 = −n(n + 1)pn



-->


<p>

\begin{align*}
((1 - \xi ^2) p’_n)’ = -n (n + 1) p_n
\end{align*}
mit \(\xi (x) = x\) und erfu&#x0308;llen die dreigliedrige Rekursion
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--



                                                                                                            (n + 1)pn+1 = (2n + 1)ξpn − npn−1 .



-->


<p>

\begin{align*}
(n + 1) p_{n+1} = (2n + 1) \xi p_n - n p_{n-1}.
\end{align*}

</p>


<h3 id="tschebyscheff-polynome"><span style="font-variant: small-caps;">Tschebyscheff</span>-Polynome</h3>

</p>

<p>
Die <b><span class="textsc" >Tschbyscheff</span>-Polynome</b> entstehen durch Transformation der Kosinus-Funktionen:
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--



                                                                                                                    pn (x) := cos(nt),                   x = cos(t).



-->


<p>

\begin{align*}
p_n(x) := \cos (nt), \quad x = \cos (t).
\end{align*}
Einem Argument \(x \in [-1, 1]\) entspricht der Winkel \(t = \arccos (x) \in [0,\pi ]\), der den Wert des Polynoms als \(\cos (nt)\) bestimmt. Das Polynom \(p_n\) hat in \([0,1]\) \(n\) Nullstellen
\(\xi _k\) (\(k = 1, \dotsc , n\)) und \(n + 1\) Extrema \(\eta _k\) (\(k = 0, \dotsc , n\)), na&#x0308;mlich
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                  (2k − 1)π
                                                                                                                                                         
                                                                                                                                                         kπ
                                                                                 ξk := cos                    ,                   ηk := cos                   , wobei pn (ηk ) = (−1)k .
                                                                                                     2n                                                   n


-->


<p>

\begin{align*}
\xi _k := \cos \left (\frac {(2k - 1)\pi }{2n}\right ), \quad \eta _k := \cos \left (\frac {k\pi }{n}\right ), \text { wobei } p_n(\eta _k) = (-1)^k.
\end{align*}
Die Tschebyscheff-Polynome erfu&#x0308;llen die Orthogonalita&#x0308;tsrelation
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                          π                                               m=n=0
                                                                                                                           
                                                                                                      1
                                                                                                                     dx
                                                                                                      pm (x)pn (x) p      = π/2                                             m=n>0
                                                                                                   −1               1 − x2 
                                                                                                                            0                                               sonst,


-->


<p>

\begin{align*}
\int _{-1}^1 p_m(x) p_n(x) \frac {\dx }{\sqrt {1 - x^2}} = \begin{cases}\pi &amp; m = n = 0 \\ \pi /2 &amp; m = n &gt; 0 \\ 0 &amp; \text {sonst}, \end
{cases}
\end{align*}
d.&#x202f;h. \([a,b] = [-1, 1]\) und \(w(x) = \frac {1}{\sqrt {1 - x^2}}\). Dies impliziert die dreigliedrige Rekursion
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--



                                                                                               pn+1 = 2ξpn − pn−1 ,                           n≥1              mit              ξ(x) = x.



-->


<p>

\begin{align*}
p_{n+1} = 2 \xi p_n - p_{n-1}, \quad n \ge 1 \quad \text { mit } \quad \xi (x) = x.
\end{align*}

</p>
<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
Die <b>Tschebyscheff-Entwicklung einer Funktion</b> \(f\)
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                         ∞
                                                                                                                         X   〈 f , pn 〉
                                                                                                          f (x) ∼                       pn (x),                %n = 〈pn , pn 〉
                                                                                                                         n=0
                                                                                                                                %n


-->


<p>

\begin{align*}
f(x) \sim \sum _{n=0}^\infty \frac {\innerproduct {f, p_n}}{\varrho _n} p_n(x), \quad \varrho _n = \innerproduct {p_n, p_n}
\end{align*}
entspricht der Fourier-Reihe der transformierten Funktion \(g(t) = f(x)\), \(x = \cos (t)\), d.&#x202f;h.
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                      ∞      π
                                                                                                          1
                                                                                                      X                              
                                                                                               g(t) ∼            f (cos t) cos(nt) dt cos(nt).
                                                                                                         %
                                                                                                      n=0 n   0




-->


<p>

\begin{align*}
g(t) \sim \sum _{n=0}^\infty \frac {1}{\varrho _n} \left (\int _0^\pi f(\cos t) \cos (nt) \dt \right ) \cos (nt).
\end{align*}
Damit kann die schnelle Fourier-Transformation zur na&#x0308;herungsweisen Berechnung der<br />
Entwicklungs-Koeffizienten herangezogen werden.
</p>


<h3 id="minimalitaet-der-tschebyscheff-polynome">Minimalität der <span style="font-variant: small-caps;">Tschebyscheff</span>-Polynome</h3>

</p>

<p>
Das Tschebyscheff-Polynom \(p_n(x) = \cos (n \arccos (x))\) <b>minimiert</b>
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--



                                                                                                                                        max |q(x)|
                                                                                                                                   x∈[−1,1]




-->


<p>

\begin{align*}
\max _{x \in [-1,1]} |q(x)|
\end{align*}
(eindeutig) unter allen Polynomen \(q\) vom Grad \(n\) mit gleichem ho&#x0308;chsten Koeffizienten. Anders formuliert ist die Maxiumum-Norm des Produkts
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                                       n
                                                                                                                                       Y
                                                                                                                                         (x − ξk )
                                                                                                                                       k=1



-->


<p>

\begin{align*}
\prod _{k=1}^n (x - \xi _k)
\end{align*}
auf dem Intervall \([-1,1]\) fu&#x0308;r die Nullstellen \(\xi _k\) von \(p_n\) minimal.
</p>


<h2 id="diskrete-fourier-transformation">Diskrete <span style="font-variant: small-caps;">Fourier</span>-Transformation</h2>

</p>

<h3 id="einschub-fourier-reihen">Einschub: <span style="font-variant: small-caps;">Fourier</span>-Reihen</h3>

</p>

<p>
Sei \(f\) eine \(2\pi \)-periodische Funktion, d.&#x202f;h. \(\forall _{x \in \real }\; f(x + 2\pi ) = f(x)\). Dann ist die <b>komplexe <span class="textsc" >Fourier</span>-Reihe</b>
von \(f\) die Entwicklung nach dem Orthonormalsystem \(e_k(x) = e^{\i kx}\), \(k \in \integer \):
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                                                                                   2π
                                                                                                  X                                                               1
                                                                                      f (x) ∼              ck ek (x),            ck = 〈 f , ek 〉2π :=                                    f (t)ek (t) dt.
                                                                                                  k∈Z
                                                                                                                                                                 2π             0




-->


<p>

\begin{align*}
f(x) \sim \sum _{k \in \integer } c_k e_k(x), \quad c_k = \innerproduct {f, e_k}_{2\pi } := \frac {1}{2\pi } \int _0^{2\pi } f(t) \overline {e_k(t)} \dt .
\end{align*}
Die Art der Konvergenz der Reihe ha&#x0308;ngt dabei von der Glattheit von \(f\) bzw. dem Abfallverhalten <b><span class="textsc" >Fourier</span>-Koeffizienten</b> \(c_k\) ab. Hinreichend fu&#x0308;r
gleichma&#x0308;ßige Konvergenz ist \(\sum _{k \in \integer } |c_k| &lt; \infty \).
</p>
<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
Ist \(f\) eine reellwertige \(2\pi \)-periodische Funktion, so ist die <b>reelle <span class="textsc" >Fourier-Reihe</span></b> von \(f\) die Entwicklung nach dem Orthogonalsystem der Kosinus- und
Sinusfunktionen:
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                                  ∞
                                                                                                                         a0 X
                                                                                                      f (x) ∼              +   (ak cos(kx) + bk sin(kx)),
                                                                                                                         2 k=1


-->


<p>

\begin{align*}
f(x) \sim \frac {a_0}{2} + \sum _{k=1}^\infty (a_k \cos (kx) + b_k \sin (kx)),
\end{align*}

</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                          π                                                               π
                                                                                                  1                                                            1
                                                                                       ak :=                       f (t) cos(kt) dt,               bk :=                        f (t) sin(kt) dt.
                                                                                                  π       −π                                                   π        −π




-->


<p>

\begin{align*}
a_k := \frac {1}{\pi } \int _{-\pi }^\pi f(t) \cos (kt) \dt , \quad b_k := \frac {1}{\pi } \int _{-\pi }^\pi f(t) \sin (kt) \dt .
\end{align*}
Wiederum ha&#x0308;ngt die Art der Konvergenz der Reihe von der Glattheit von \(f\) ab. Hinreichend fu&#x0308;r absolute Konvergenz ist, dass die <span class="textsc" >Fourier</span>-Koeffizienten \(a_k\)
und \(b_k\) absolut konvergente Reihen bilden.
</p>
<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
Auch eine konvergente Fourier-Reihe muss i.&#x202f;A. nicht an allen Stellen den Funktionswert als Grenzwert annehmen. An Unstetigkeitsstellen konvergiert die Reihe meist gegen den Mittelwert aus links- und rechtsseitigem
Grenzwert.<br />
Daher schreibt man oft \(f(x) \sim \sum \dotsb \) statt \(f(x) = \sum \dotsb \).
</p>


<h3 id="komplexe-einheitswurzeln">Komplexe Einheitswurzeln</h3>

</p>

<p>
Die Gleichung \(z^n = 1\), \(z \in \complex \) hat genau \(n\) Lo&#x0308;sungen
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--



                                                                                             zk = wkn ,                  w n := exp(2πi/n),                     k = 0, . . . , n − 1,



-->


<p>

\begin{align*}
z_k = w_n^k, \quad w_n := \exp (2 \pi \i / n), \quad k = 0, \dotsc , n - 1,
\end{align*}
die als <b>Einheitswurzeln</b> bezeichnet werden, wobei \(w_n^n = 1\) und \(w_n^{k + nm} = w_n^k\) fu&#x0308;r \(m \in \integer \). Die Einheitswurzeln \(w_n^k\) bilden ein dem Einheitskreis
einbeschriebenes regelma&#x0308;ßiges \(n\)-Eck.
</p>


<h3 id="fourier-matrix"><span style="font-variant: small-caps;">Fourier</span>-Matrix</h3>

</p>

<p>
Durch Bilden von Potenzen der Einheitswurzel \(w_n = \exp (2 \pi \i / n)\) erha&#x0308;lt man die <b><span class="textsc" >Fourier</span>-Matrix</b>
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                                                          
                                                                                                     w0·0
                                                                                                       n                               ...        w0·(n−1)
                                                                                                                                                   n
                                                                                                    .                                                ..
                                                                                             Wn :=  ..                                                .    = (w n )k,`=0 .
                                                                                                                                                                 k` n−1
                                                                                                                                                           

                                                                                                    w(n−1)·0
                                                                                                     n                                 ...   w(n−1)·(n−1)
                                                                                                                                              n




-->


<p>

\begin{align*}
W_n := \begin{pmatrix} w_n^{0 \cdot 0} &amp; \dots &amp; w_n^{0 \cdot (n - 1)} \\ \vdots &amp; &amp; \vdots \\ w_n^{(n - 1) \cdot 0} &amp; \dots &amp;
w_n^{(n - 1) \cdot (n - 1)} \end {pmatrix} = (w_n^{k\ell })_{k,\ell =0}^{n-1}.
\end{align*}
Dabei ist \(W_n/\sqrt {n}\) unita&#x0308;r, d.&#x202f;h. \(W_n^\ast W_n/n\) ist die Einheitsmatrix.
</p>


<h3 id="diskrete-fourier-transformation">Diskrete <span style="font-variant: small-caps;">Fourier</span>-Transformation</h3>

</p>

<p>
Die Multiplikation eines Vektors \(c = (c_0, \dotsc , c_{n-1})^t\) mit der Fourier-Matrix \(W_n\) wird als<br />
<b>diskrete <span class="textsc" >Fourier</span>-Transformation</b> bezeichnet:
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                                                               1 ∗
                                                                                                                        f = Wn c             ⇔       c=         W f.
                                                                                                                                                               n n


-->


<p>

\begin{align*}
f = W_n c \quad \Leftrightarrow \quad c = \frac {1}{n} W_n^\ast f.
\end{align*}
Komponentenweise gilt also
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                    n−1                                             n−1
                                                                                                                    X                                     1X
                                                                                                          fj =              ck w njk         ⇔       ck =       f j w−k
                                                                                                                                                                     n
                                                                                                                                                                        j

                                                                                                                    k=0
                                                                                                                                                          n j=0



-->


<p>

\begin{align*}
f_j = \sum _{k=0}^{n-1} c_k w_n^{jk} \quad \Leftrightarrow \quad c_k = \frac {1}{n} \sum _{j=0}^{n-1} f_j w_n^{-kj}
\end{align*}
mit \(k, j = 0, \dotsc , n - 1\), \(w_n = \exp (2 \pi \i / n)\) und \(f = (f_0, \dotsc , f_{n-1})^t\).
</p>
<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
Die diskrete Fourier-Transformation entspricht der<br />
<b>Auswertung des trigonometrischen Polynoms</b>
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                                              n−1
                                                                                                                                              X
                                                                                                                                 p(x) =              ck eikx
                                                                                                                                              k=0



-->


<p>

\begin{align*}
p(x) = \sum _{k=0}^{n-1} c_k e^{\i k x}
\end{align*}
an den Punkten \(x_j = 2 \pi j / n\), d.&#x202f;h. \(f_j = p(x_j)\) fu&#x0308;r \(j = 0, \dotsc , n - 1\).
</p>
<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
Die inverse Transformation kann als <b>Riemann-Summe fu&#x0308;r die Fourier-Koeffizienten</b><br />
interpretiert werden:
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                  2π                                    n−1
                                                                                                   1                                               1X
                                                                                 〈 f , ek 〉2π =                         f (x)e−ikx dx ≈                  f (x j )e−ikx j ,                    x j = 2π j/n.
                                                                                                  2π           0                                   n j=0



-->


<p>

\begin{align*}
\innerproduct {f, e_k}_{2\pi } = \frac {1}{2\pi } \int _0^{2\pi } f(x) e^{-\i k x} \dx \approx \frac {1}{n} \sum _{j=0}^{n-1} f(x_j) e^{-\i k x_j}, \quad
x_j = 2 \pi j / n.
\end{align*}
Diese Approximation ist fu&#x0308;r glatte Funktionen und \(n \gg |k|\) sehr genau.
</p>


<h3 id="schnelle-fourier-transformation">Schnelle <span style="font-variant: small-caps;">Fourier</span>-Transformation</h3>

</p>

<p>
Die diskrete Fourier-Transformation \(f_j = \sum _{k=0}^{n-1} c_k w_n^{jk}\) eines Vektors \(c = (c_0, \dotsc , c_{n-1})\) mit \(w_n = e^{2\pi \i /n}\) kann fu&#x0308;r \(n = 2^\ell \)
mit der <b>schnellen <span class="textsc" >Fourier</span>-Transformation (FFT)</b> in<br />
\(2n\ell = 2 n \log _2 n\) Operationen berechnet werden.
</p>
<p>
In der rekursiven Version hat der Algorithmus die folgende Form:
</p>
<pre class="programlisting">
function f = FFT(c)
   n = length(c);
   if n = 1;
      f = c;
   else;
      g = FFT(c_0, c_2, ..., c_{n-2});
      h = FFT(c_1, c_3, ..., c_{n-1});
      p = (1, w_n, w_n^2, ..., w_n^{n/2-1});
      f = (g + p .* h, g - p .* h);
   end;
</pre>


<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
Die inverse Fourier-Transformation \(c_k = \frac {1}{n} \sum _{j=0}^{n-1} f_j w_n^{-jk}\) eines Vektors \(f = (f_0, \dotsc , f_{n-1})\) kann vollkommen analog berechnet werden. Man
bezeichnet den entsprechenden Algorithmus als <b>inverse schnelle <span class="textsc" >Fourier</span>-Transformation (IFFT)</b>.
</p>
<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
Das <b>Produkt \(r\) zweier Polynome</b>
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                           mp                            mq
                                                                                                           X                             X
                                                                                             p(x) =                  k
                                                                                                                 pk x ,     q(x) =               qk x k
                                                                                                           k=0                           k=0



-->


<p>

\begin{align*}
p(x) = \sum _{k=0}^{m_p} p_k x^k, \quad q(x) = \sum _{k=0}^{m_q} q_k x^k
\end{align*}
kann mithilfe der FFT berechnet werden werden. Man wertet die Polynome an den komplexen Einheitswurzeln aus, multipliziert diese Werte und erha&#x0308;lt die Koeffizienten \(r_k\) von \(r\) durch
Ru&#x0308;cktransformation.<br />
Genauer wa&#x0308;hlt man zuna&#x0308;chst \(n = 2^\ell &gt; m_p + m_q\) und erga&#x0308;nzt die Koeffizienten der Polynome mit Nullen zu Vektoren \(\widetilde {p}\) und \(\widetilde {q}\) der
La&#x0308;nge \(n\). Dann wird die diskrete Fourier-Transformation der Koeffizientenvektoren gebildet, d.&#x202f;h. \(\widehat {p} = \FFT (\widetilde {p})\), \(\widehat {q} = \FFT (\widetilde
{q})\). Schließlich wird der Vektor der Produkte \(\widehat {r}_j = \widehat {p}_j \widehat {q}_j\), \(j = 0, \dotsc , n - 1\) berechnet und zuru&#x0308;cktransformiert, d.&#x202f;h.
\(\widetilde {r} = \IFFT (\widehat {r})\) ist der Koeffizientenvektor des Produktpolynoms \(r\).<br />
Insgesamt werden \(\O (n \log n)\) Operationen beno&#x0308;tigt, wa&#x0308;hrend die direkte Berechnung der Koeffizienten \(\O (n^2)\) Operationen erfordert.
</p>


<h3 id="trigonometrische-interpolation">Trigonometrische Interpolation</h3>

</p>

<p>
Fu&#x0308;r \(n = 2^\ell \) ko&#x0308;nnen die Koeffizienten des <b>trigonometrischen Polynoms</b>
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                          X
                                                                                        p(x) = cm cos(mx) +                       ck eikx ,      m = n/2,
                                                                                                                          |k|<m




-->


<p>

\begin{align*}
p(x) = c_m \cos (mx) + \sum _{|k| &lt; m} c_k e^{\i k x}, \quad m = n/2,
\end{align*}
das die Daten
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                     2π j
                                                                                         f j = f (x j ),     xj =         ,         j = 0, . . . , n − 1
                                                                                                                      n


-->


<p>

\begin{align*}
f_j = f(x_j), \quad x_j = \frac {2\pi j}{n}, \quad j = 0, \dotsc , n - 1
\end{align*}
interpoliert, mit der inversen schnellen Fourier-Transformation berechnet werden:
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--



                                                                                           (c0 , . . . , cm , c−m+1 , . . . , c−1 ) = IFFT( f ).



-->


<p>

\begin{align*}
(c_0, \dotsc , c_m, c_{-m+1}, \dotsc , c_{-1}) = \IFFT (f).
\end{align*}

</p>
<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
Die trigonometrische Interpolation in Verbindung mit der diskreten Fourier-Transformation kann zum <b>Ausblenden hochfrequenter Sto&#x0308;rungen in Signalen</b> verwendet werden. Man bildet zu den Daten \(f_j
\approx f(x_j)\), \(x_j = \frac {2\pi j}{n}\), \(j = 0, \dotsc , n - 1\), \(n = 2^\ell \) zuna&#x0308;chst mithilfe der IFFT das trigonometrische Interpolationspolynom \(p(x) = c_m \cos
(mx) + \sum _{|j| &lt; m} c_j e^{\i j x}\), \(m = n/2\).<br />
Dann wa&#x0308;hlt man eine Bandbreite \(k\) und setzt alle Koeffizienten \(c_j\) mit \(|j| &gt; k\) null.<br />
Mit diesem Tiefpass werden fu&#x0308;r hinreichend kleines \(k\) im Allgemeinen Sto&#x0308;rungen unterdru&#x0308;ckt.<br />
Eine zu kleine Bandbreite fu&#x0308;hrt dabei zu einem unerwu&#x0308;nschten Genauigkeitsverlust.
</p>


<h3 id="fourier-transformation-zyklischer-gleichungssysteme"><span style="font-variant: small-caps;">Fourier</span>-Transformation zyklischer Gleichungssysteme</h3>

</p>

<p>
Eine <b>zyklische Matrix</b>
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                                   ...
                                                                                                                                                 
                                                                                                      a0                 an−1                 a1
                                                                                                    a1                   a0       ...        a2 
                                                                                                 A=
                                                                                                    ..                    ..                  .. 
                                                                                                       .                    .                   .
                                                                                                     an−1                an−2      ...        a0


-->


<p>

\begin{align*}
A = \begin{pmatrix} a_0 &amp; a_{n-1} &amp; \dots &amp; a_1 \\ a_1 &amp; a_0 &amp; \dots &amp; a_2 \\ \vdots &amp; \vdots &amp; &amp; \vdots \\ a_{n-1}
&amp; a_{n-2} &amp; \dots &amp; a_0 \end {pmatrix}
\end{align*}
besitzt die Eigenwerte
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                   n−1
                                                                                                   X
                                                                                            λj =           ak w−k
                                                                                                               n ,
                                                                                                                  j
                                                                                                                            w n = exp(2πi/n)
                                                                                                   k=0



-->


<p>

\begin{align*}
\lambda _j = \sum _{k=0}^{n-1} a_k w_n^{-kj}, \quad w_n = \exp (2 \pi i / n)
\end{align*}
und kann durch die Fourier-Matrix diagonalisiert werden:
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                               1 ∗
                                                                                                W AWn = diag(λ),                      λ = Wn∗ a.
                                                                                               n n


-->


<p>

\begin{align*}
\frac {1}{n} W_n^\ast A W_n = \diag (\lambda ), \quad \lambda = W_n^\ast a.
\end{align*}
Folglich la&#x0308;sst sich die Lo&#x0308;sung eines zyklischen Gleichungssystems \(Ax = b\) berechnen in der Form
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--



                                                                                                   x = Wn diag(λ)−1 (Wn∗ b/n).



-->


<p>

\begin{align*}
x = W_n \diag (\lambda )^{-1} (W_n^\ast b / n).
\end{align*}
Fu&#x0308;r \(n = 2^\ell \) ist die FFT anwendbar, und man erha&#x0308;lt den folgenden Lo&#x0308;sungsalgorithmus:
</p>
<pre class="programlisting">
c = IFFT(b);
lambda = n * IFFT(a);
y_j = c_j / lambda_j, j = 0, ..., n - 1;
x = FFT(y);
</pre>


<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
Das <b>Produkt \(C = AB\) zweier zyklischer Matrizen</b> der Dimension \(n = 2^\ell \) la&#x0308;sst sich mithilfe der FFT berechnen. Zuna&#x0308;chst bestimmt man dazu mit der mit \(n\) multiplizierten IFFT
die Eigenwerte von \(A\) und \(B\):
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                              n−1
                                                                                                                              X                                       n−1
                                                                                                                                                                      X
                                                                                                                      λAj =         ak w−n jk ,             λBj =            bk w−n jk ,
                                                                                                                              k=0                                     k=0



-->


<p>

\begin{align*}
\lambda _j^A = \sum _{k=0}^{n-1} a_k w_n^{-jk}, \quad \lambda _j^B = \sum _{k=0}^{n-1} b_k w_n^{-jk},
\end{align*}
wobei \(a\) bzw. \(b\) die erste Spalte von \(A\) bzw. \(B\) ist. Dann sind
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                                             λCj = λAjλBj



-->


<p>

\begin{align*}
\lambda _j^C = \lambda _j^A \lambda _j^B
\end{align*}
die Eigenwerte von \(C\), und man erha&#x0308;lt durch die mit \(1/n\) multiplizierte FFT von \(\lambda ^C\)
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                                                          n−1
                                                                                                                                                  1 X C jk
                                                                                                                                     ck =              λ w
                                                                                                                                                  n j=0 j n


-->


<p>

\begin{align*}
c_k = \frac {1}{n} \sum _{j=0}^{n-1} \lambda _j^C w_n^{jk}
\end{align*}
die Elemente der ersten Spalte von \(C\). Damit ist \(C\) berechnet, denn \(C\) ist als Produkt zyklischer Matrizen wieder zyklisch.
</p>


<h2 id="splines">Splines</h2>

</p>

<h3 id="kubische-hermite-interpolation">Kubische <span style="font-variant: small-caps;">Hermite</span>-Interpolation</h3>

</p>

<p>
Funktionswerte und Ableitungen an zwei Punkten ko&#x0308;nnen durch ein kubisches Polynom interpoliert werden. Der Interpolant (<b><span class="textsc" >Hermite</span>-Spline</b>) besitzt die Darstellung
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                         p = f (a)ua + f (b)u b + (b − a)( f 0 (a)va + f 0 (b)vb )



-->


<p>

\begin{align*}
p = f(a) u_a + f(b) u_b + (b - a)(f’(a) v_a + f’(b) v_b)
\end{align*}
mit den Lagrange-Funktionen
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                          ua (x) = (1 + 2s)(1 − s)2 ,                  u b (x) = (3 − 2s)s2 ,                        va (x) = s(1 − s)2 ,        vb (x) = −s2 (1 − s)



-->


<p>

\begin{align*}
u_a(x) = (1 + 2s)(1 - s)^2, \quad u_b(x) = (3 - 2s)s^2, \quad v_a(x) = s(1 - s)^2, \quad v_b(x) = -s^2 (1 - s)
\end{align*}
und \(s = (x - a) / (b - a)\).
</p>
<p>
Sind Funktionswerte und Ableitungen an mehreren Punkten \(x_0 &lt; \dotsb &lt; x_n\) gegeben, so bilden die kubischen Hermite-Interpolaten einen stetig differenzierbaren <b>kubischen <span class="textsc"
>Hermite</span>-Spline</b> \(q\). Nach Konstruktion ist \(q\) dabei eindeutig durch die Daten \(f(x_j), f’(x_j)\), \(j = 0, \dotsc , n\) bestimmt.
</p>


<h3 id="kubische-splines">Kubische Splines</h3>

</p>

<p>
Ein <b>kubischer Spline</b> \(p\) zu einer Partition \(a = x_0 &lt; \dotsb &lt; x_n = b\) eines Intervalls \([a, b]\) kann (alternativ zur sog. B-Spline-Darstellung) durch seine Werte \(f_{k-1}\), \(f_k\)
und Ableitungen \(d_{k-1}^+\), \(d_k^-\) an den Endpunkten der Teilintervalle \([x_{k-1}, x_k]\) festgelegt werden. Aus diesen Daten ko&#x0308;nnen die kubischen Polynome \(p_k\) auf den Intervallen
\([x_{k-1}, x_k]\) mit kubischer Hermite-Interpolation berechnet werden.
</p>
<p>
Soll \(p\) an den Stu&#x0308;tzstellen glatt, d.&#x202f;h. differenzierbar sein, so werden Bedingungen an \(f_k\) und \(d_k^\pm \) gestellt. Stetige Differenzierbarkeit bei \(x_k\) ist a&#x0308;quivalent zu
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                                       dk− = dk = dk+ .



-->


<p>

\begin{align*}
d_k^{-} = d_k = d_k^{+}.
\end{align*}
Soll auch die zweite Ableitung bei \(x_k\) stetig sein, so ist die Bedingung \(p_k”(x_k^-) = p_{k+1}”(x_k^+)\) a&#x0308;quivalent zu einer linearen Gleichung zwischen \(f_{k-1}, f_k, f_{k+1}\) und
\(d_{k-1}^+, d_k, d_{k+1}^-\):
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                  1 +         2   2           1          3                   3
                                                                                                     
                                                                                                                   −
                                                                                     dk−1 +     +       dk +      dk+1 = 2 ( f k − f k−1 ) + 2 ( f k+1 − f k )
                                                                                  ∆k          ∆k ∆k+1        ∆k+1       ∆k                  ∆k+1


-->


<p>

\begin{align*}
\frac {1}{\Delta _k} d_{k-1}^+ + \left (\frac {2}{\Delta _k} + \frac {2}{\Delta _{k+1}}\right ) d_k + \frac {1}{\Delta _{k+1}} d_{k+1}^- = \frac {3}{\Delta
_k^2} (f_k - f_{k-1}) + \frac {3}{\Delta _{k+1}^2} (f_{k+1} - f_k)
\end{align*}
mit \(\Delta _k := x_k - x_{k-1}\).
</p>


<h3 id="natuerliche-spline-interpolation">Natürliche Spline-Interpolation</h3>

</p>

<p>
Der <b>natu&#x0308;rliche Spline-Interpolant</b> der Daten \((x_i, f_i)\), \(a = x_0 &lt; \dotsb &lt; x_n = b\) ist ein kubischer Spline \(p\), der an den Stu&#x0308;tzstellen \(x_i\) zweifach stetig
differenzierbar ist und die Randbedingungen \(p”(x_0) = p”(x_n) = 0\) erfu&#x0308;llt.
</p>
<p>
Er minimiert unter allen glatten Interpolanten \(f\) das Integral
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                                            b
                                                                                                                                                 | f 00 (x)|2 dx,
                                                                                                                                         a




-->


<p>

\begin{align*}
\int _a^b |f”(x)|^2 \dx ,
\end{align*}
das als Maß fu&#x0308;r die Sta&#x0308;rke der Oszillation angesehen werden kann.
</p>
<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
Die Ableitungen \(d_i = p’(x_i)\), die den Spline zusammen mit den Daten \(f_i\) festlegen, berechnen sich aus den Glattheitsbedingungen fu&#x0308;r \(i = 1, \dotsc , n - 1\), na&#x0308;mlich
\(p_i”(x_i) = p_{i+1}”(x_i)\) bzw.
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                   1           2   2           1          3                   3
                                                                                                      
                                                                                      di−1 +     +       di +      di+1 = 2 ( f i − f i−1 ) + 2 ( f i+1 − f i ),
                                                                                   ∆i          ∆i ∆i+1        ∆i+1       ∆i                  ∆i+1


-->


<p>

\begin{align*}
\frac {1}{\Delta _i} d_{i-1} + \left (\frac {2}{\Delta _i} + \frac {2}{\Delta _{i+1}}\right ) d_i + \frac {1}{\Delta _{i+1}} d_{i+1} = \frac {3}{\Delta
_i^2} (f_i - f_{i-1}) + \frac {3}{\Delta _{i+1}^2} (f_{i+1} - f_i),
\end{align*}
und den Randbedingungen \(p”(x_0) = p”(x_n) = 0\) bzw.
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                         3                                                      3
                                                                                                     2d0 + d1 =             ( f1 − f0 ),                  dn−1 + 2dn =             ( f n − f n−1 )
                                                                                                                         ∆1                                                     ∆n


-->


<p>

\begin{align*}
2d_0 + d_1 = \frac {3}{\Delta _1} (f_1 - f_0), \quad d_{n-1} + 2d_n = \frac {3}{\Delta _n} (f_n - f_{n-1})
\end{align*}
mit \(\Delta _i = x_i - x_{i-1}\).
</p>
<p>
Alternativ kann man auch die Randbedingungen \(p’(a) = \alpha \), \(p’(b) = \beta \) stellen. Der resultierende eingespannte natu&#x0308;rliche Spline minimiert dann ebenfalls obiges Integral.
</p>
<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
Betrachtet man Splines \(p\), die die Lagrange-Daten \((x_k, \delta _{kj})\), \(k = 0, \dotsc , n\), \(j \in \{0, \dotsc , n\}\) interpolieren, so stellt man fest, dass \(p(x)\) schnell mit zunehmender
Entfernung von \(x_j\) abklingt. Dieses numerisch gu&#x0308;nstige Verhalten ist typisch fu&#x0308;r Splines.
</p>
<p>
Außerdem ko&#x0308;nnen mit Splines auch gut Daten mit nicht-a&#x0308;quidistanten Stu&#x0308;tzstellen interpoliert werden. Nicht-a&#x0308;quidistante Stu&#x0308;tzstellen sind bspw. sinnvoll, falls die Daten Bereiche
aufweisen, in denen sie unterschiedlich schnell schwanken.
</p>


<h3 id="splineinterpolation-mit-matlab">Splineinterpolation mit MATLAB</h3>

</p>

<p>
Ein kubischer Spline-Interpolant zu den Daten \((x_k, y_k)\) kann in M ATLAB mit dem Befehl<br />
<span class="inlineprogramlisting">p = spline(x, y</span>); berechnet und mit <span class="inlineprogramlisting">pt = ppval(p, t</span>); an den Punkten \(t_j\)
ausgewertet werden. Der Spline wird als Struktur gespeichert, die unter anderem in dem Feld <span class="inlineprogramlisting"></span>coefs die Koeffizienten der einzelnen Polynomsegmente
entha&#x0308;lt: Die Polynome werden dabei zeilenweise mit dem ho&#x0308;chsten Koeffizienten zuerst gespeichert, wobei statt \(x\) der Term \(x - x_k\) mit \(x_k\) der unteren \(x\)-Stelle eingesetzt wird. Beispielsweise
entspricht die Zeile \((1, -2, 0, 1)\) fu&#x0308;r das Intervall \([2, 3]\) dem Polynom \(p(x) = (x - 2)^3 - 2(x - 2)^2 + 1\).<br />
Das Feld <span class="inlineprogramlisting"></span>breaks entha&#x0308;lt die Stu&#x0308;tzstellen.
</p>
<p>
M ATLAB verwendet dabei nicht die Randbedingungen \(p”(x_0) = p”(x_n) = 0\), sondern fordert stattdessen die Stetigkeit der dritten Ableitung an den Punkten \(x_1\) und \(x_{n-1}\)
(<b>Not-A-Knot-Bedingung</b>). Dadurch ergibt sich ein genauerer Interpolant, jedoch geht dabei die oben erwa&#x0308;hnte Minimal-Eigenschaft verloren. Der Unterschied zwischen den beiden verschiedenen Methoden ist
fu&#x0308;r gro&#x0308;ßere \(n\) allerdings fast zu vernachla&#x0308;ssigen.
</p>
<p>
Alternativ dazu kann man den Datenvektor \(y\) um zwei Werte erweitern. Hat \(y\) genau zwei Eintra&#x0308;ge mehr als \(x\), so werden der erste und letzte Wert von \(y\) als Randbedingung fu&#x0308;r die Steigungen an
den Enden der Kurve verwendet.
</p>
<p>
Die Auswertung kann auch unmittelbar mit dem Befehl <span class="inlineprogramlisting"></span>spline erfolgen. Daru&#x0308;ber hinaus ist die simultane Interpolation vektorwertiger Daten
mo&#x0308;glich.<br />
In <span class="inlineprogramlisting">curve = spline(t, y, t_plt</span>); stehen dabei in \(y\) spaltenweise die Funktionswerte in den Stu&#x0308;tzstellen \(x\), und in \(t_\text {plt}\)
wird der Spline ausgewertet.
</p>


<h2 id="b-splines">B-Splines</h2>

</p>

<h3 id="knotenfolge">Knotenfolge</h3>

</p>

<p>
Eine <b>Knotenfolge</b>
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                          τ: · · · ≤ τ−1 ≤ τ0 ≤ τ1 ≤ · · ·



-->


<p>

\begin{align*}
\tau \colon \dotsb \le \tau _{-1} \le \tau _0 \le \tau _1 \le \dotsb
\end{align*}
ist eine bi-infinite monoton wachsende Folge \(\{\tau _k\}_{k \in \integer }\) reeller Zahlen mit \(\lim _{k \to \pm \infty } \tau _k = \pm \infty \). Endliche Teilfolgen von \(\tau \) heißen
<b>Knotenvektoren</b>. Die <b>Vielfachheit</b> \(\#\tau _k\) eines Knotens \(\tau _k\) ist die maximale Anzahl der Wiederholungen von \(\tau _k\) in der Folge bzw. Vektor \(\tau \). Man spricht dann von
einfachen oder doppelten Knoten usw.
</p>


<h3 id="rekursion-fuer-b-splines">Rekursion für B-Splines</h3>

</p>

<p>
Zu einer Knotenfolge \(\tau \) definiert man die <b>B-Splines</b> \(b_k^n\) vom Grad \(n\) durch die Rekursion
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                                                                                       t − τk
                                                                                                     bkn := γnk bkn−1 + (1 − γnk+1 )bk+1
                                                                                                                                     n−1
                                                                                                                                         ,                                γnk (t) =             ,
                                                                                                                                                                                      τk+n − τk


-->


<p>

\begin{align*}
b_k^n := \gamma _k^n b_k^{n-1} + (1 - \gamma _{k+1}^n)b_{k+1}^{n-1}, \qquad \gamma _k^n(t) = \frac {t - \tau _k}{\tau _{k+n} - \tau _k},
\end{align*}
ausgehend von den charakteristischen Funktionen \(b_0^k := \chi _{\left [\tau _k, \tau _{k+1}\right )}\) der Knotenintervalle<br />
\(\left [\tau _k, \tau _{k+1}\right )\), d.&#x202f;h.
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--

                                                                                                                                             ¨
                                                                                                                                                 1         τk ≤ t < τk+1
                                                                                                                          b0k (t)    :=
                                                                                                                                                 0         sonst.


-->


<p>

\begin{align*}
b_0^k(t) := \begin{cases}1 &amp; \tau _k \le t &lt; \tau _{k+1} \\ 0 &amp; \text {sonst}.\end {cases}
\end{align*}
Terme, fu&#x0308;r die der Nenner verschwindet, werden dabei nicht beru&#x0308;cksichtigt.
</p>
<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
Jeder B-Spline \(b_k^n\) wird durch seinen Knotenvektor \((\tau _k, \dotsc , \tau _{k+n+1})\) eindeutig festgelegt und verschwindet außerhalb von \(\left [\tau _k, \tau _{k+n+1}\right )\). Auf
jeden nicht-leeren Knotenintervall \(\left [\tau _i, \tau _{i+1}\right )\),<br />
\(k \le i \le k + n\) ist er ein nicht-negatives Polynom vom Grad \(n\).
</p>


<h3 id="stetige-abhaengigkeit-vom-knotenvektor">Stetige Abhängigkeit vom Knotenvektor</h3>

</p>

<p>
Ist der Knotenvektor \(\tau = (\tau _k, \dotsc , \tau _{k+n+1})\) eines B-Splines \(b_k^n\) der Grenzwert einer Folge von Knotenvektoren \(\tau _\ell \), \(\ell \in \natural \) und bezeichnet
\(b_{k,\ell }^n\) die zugeho&#x0308;rigen B-Splines, so gilt
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                                         n
                                                                                                                                    lim bk,` (t) = bkn (t)
                                                                                                                                   t→∞




-->


<p>

\begin{align*}
\lim _{t \to \infty } b_{k,\ell }^n(t) = b_k^n(t)
\end{align*}
fu&#x0308;r alle \(t\), die nicht gleich einem der Knoten \(\tau _i\) sind. Die Konvergenz ist gleichma&#x0308;ßig auf jedem Intervall \([\alpha , \beta ]\), das keinen der Knoten von \(b_k^n\) entha&#x0308;lt.
</p>
<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
Die stetige Abha&#x0308;ngigkeit von den Knoten ist nu&#x0308;tzlich fu&#x0308;r das Beweisen von Identita&#x0308;ten fu&#x0308;r Linearkombinationen von B-Splines. Gilt eine Gleichung \(\sum _k c_k(\tau )
b_k^n(t) = f(t, \tau )\) fu&#x0308;r einfache Knoten, so la&#x0308;sst sie sich durch ein Approximationsargument auf beliebige Knoten verallgemeinern. Dabei kann der Summationsbereich unendlich sein, da
fu&#x0308;r jedes beschra&#x0308;nkte Intervall nur endlich viele B-Splines nicht null sind.
</p>


<h3 id="ableitung-von-b-splines">Ableitung von B-Splines</h3>

</p>

<p>
Die Ableitung eines B-Splines vom Grad \(n\) zu einer Knotenfolge \(\tau \) ist eine gewichtete Differenz von zwei B-Splines vom Grad \(n - 1\). Auf jedem Knotenintervall \([\tau _i, \tau _{i+1})\) gilt
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                                                                                       n
                                                                                                          (bkn )0 = αnk bkn−1 − αnk+1 bk+1
                                                                                                                                       n−1
                                                                                                                                           ,                           αnk :=                ,
                                                                                                                                                                                   τk+n − τk


-->


<p>

\begin{align*}
(b_k^n)’ = \alpha _k^n b_k^{n-1} - \alpha _{k+1}^n b_{k+1}^{n-1}, \qquad \alpha _k^n := \frac {n}{\tau _{k+n} - \tau _k},
\end{align*}
wobei Terme, die B-Splines mit leerem Tra&#x0308;ger enthalten, weggelassen werden.
</p>
<p>
Aus der Rekursion folgt, dass \(b_k^n\) an einem Knoten \(\tau _i\) \(n - m\)-mal stetig differenzierbar ist, falls \(\tau _i\) in der Folge \(\tau _k, \dotsc , \tau _{k+n+1}\) Vielfachheit \(m \le n\) hat.
Insbesondere ist \(b_k^n\) stetig auf \(\real \), wenn keiner seiner Knoten Vielfachheit \(n + 1\) hat.
</p>


<h3 id="uniforme-b-splines">Uniforme B-Splines</h3>

</p>

<p>
Der <b>uniforme B-Spline</b> \(b^n\) vom Grad \(n &gt; 0\) kann ausgehend von der charakteristischen Funktion \(b^0 := \chi _{[0,1)}\) des Intervalls \([0, 1]\) durch die Rekursion
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                                                     1
                                                                                                                           b n (x) :=                     b n−1 (x − y) d y
                                                                                                                                                 0




-->


<p>

\begin{align*}
b^n(x) := \int _0^1 b^{n-1} (x - y) \dy
\end{align*}
definiert werden. Diese Identita&#x0308;t ist a&#x0308;quivalent zu der Ableitungsformel
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                       d n
                                                                                                                          b (x) = b n−1 (x) − b n−1 (x − 1)
                                                                                                                       dx


-->


<p>

\begin{align*}
\frac {d}{dx} b^n(x) = b^{n-1}(x) - b^{n-1}(x - 1)
\end{align*}
mit \(b^n(0) = 0\).
</p>
<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
Als Spezialfall des allgemeinen B-Splines mit dem Knotenvektor \(\xi = (0, 1, \dotsc , n + 1)\) ist \(b^n\)
</p>
<ul style="list-style-type:none">

<li class="list-item-f0"><p>positiv auf \((0, n + 1)\) und null außerhalb des Intervalls,
</p>
</li>
<li class="list-item-f1"><p>ein Polynom vom Grad \(n\) auf jedem Knotenintervall \([k, k + 1]\) und
</p>
</li>
<li class="list-item-f2"><p>\(n - 1\)-stetig differenzierbar.
</p>
</li>
</ul>
<p>
Daru&#x0308;ber hinaus gilt die Rekursionsformel
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                               nb n (x) = x b n−1 (x) + (n + 1 − x)b n−1 (x − 1).



-->


<p>

\begin{align*}
n b^n(x) = x b^{n-1}(x) + (n + 1 - x) b^{n-1}(x - 1).
\end{align*}
Die B-Splines zu einer allgemeinen Knotenfolge \(\xi \colon \dotsc , -h, 0, h, \dotsc \) sind skalierte Translate von \(b^n\), d.&#x202f;h. \(b_k^n(x) = b^n(x/h - k)\), \(k \in \integer \).
</p>


<h3 id="marsden-identitaet"><span style="font-variant: small-caps;">Marsden</span>-Identität</h3>

</p>

<p>
Fu&#x0308;r eine beliebige Knotenfolge \(\tau \) kann jedes Polynom vom Grad \(\le n\) als Linearkombination von B-Splines dargestellt werden. Insbesondere gilt fu&#x0308;r alle \(s \in \real \) die <b><span
class="textsc" >Marsden</span>-Identita&#x0308;t</b>
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--

                                                                                                                X
                                                                                            (t − s)n =                ψnk (s)bkn (t),                     ψnk (s) := (τk+1 − s) · · · (τk+n − s).
                                                                                                                k∈Z



-->


<p>

\begin{align*}
(t - s)^n = \sum _{k \in \integer } \psi _k^n(s) b_k^n(t), \qquad \psi _k^n(s) := (\tau _{k+1} - s) \dotsm (\tau _{k+n} - s).
\end{align*}

</p>
<p>
Durch Ableiten der Identita&#x0308;t nach \(s\) und Nullsetzen von \(s\) erha&#x0308;lt man explizite Formeln fu&#x0308;r die Monome \(t^m\). Beispielsweise ist
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--

                                                                                                                              X                                      X
                                                                                                                       1=           bkn (t),                    t=         τnk bkn (t)
                                                                                                                               k                                      k



-->


<p>

\begin{align*}
1 = \sum _k b_k^n(t), \qquad t = \sum _k \tau _k^n b_k^n(t)
\end{align*}
mit \(\tau _k^n := (\tau _{k+1} + \dotsb + \tau _{k+n}) / n\) den sogenannten Knotenmitteln.
</p>


<h3 id="splines">Splines</h3>

</p>

<p>
Die <b>Splines</b> \(S_\tau ^n\) vom Grad \(\le n\) zu einer Knotenfolge \(\tau \) sind Linearkombinationen von B-Splines:
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--

                                                                                                                                                            X
                                                                                                                                    Sτn 3 p :=                    ck bkn .
                                                                                                                                                            k∈Z



-->


<p>

\begin{align*}
S_\tau ^n \ni p := \sum _{k \in \integer } c_k b_k^n.
\end{align*}
Anders ausgedru&#x0308;ckt besteht \(S_\tau ^n\) aus allen Funktionen \(t \mapsto p(t)\), \(t \in \real \), die auf jedem Intervall \([\tau _k, \tau _{k+1})\) Polynome vom Grad \(\le n\) sind und
an einem Knoten mit Vielfachheit \(m \le n\) mindestens \(n - m\)-mal stetig differenzierbar sind.
</p>
<p>
Splines \(S_\tau ^n(D)\) auf beschra&#x0308;nkten Intervallen \(D\) erha&#x0308;lt man, indem die Variable \(t\) auf \(D\) eingeschra&#x0308;nkt wird. Es sind nur die B-Splines \(b_k^n\), die auf einem Teilintervall
von \(D\) nicht null sind, und ihre Knotenvektoren \((\tau _k, \dotsc , \tau _{k+n+1})\) relevant. Die entsprechenden Indizes werden mit \(k \sim D\) bezeichnet:
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--

                                                                                                                                         X
                                                                                                                           p(t) =                 ck bkn (t),             t ∈ D.
                                                                                                                                       k∼D



-->


<p>

\begin{align*}
p(t) = \sum _{k \sim D} c_k b_k^n(t), \quad t \in D.
\end{align*}
Insbesondere sind \(k = \ell - n, \dotsc , \ell \) die relevanten Indizes fu&#x0308;r ein nicht-leeres Knotenintervall \(D = [\tau _\ell , \tau _{\ell +1})\).
</p>


<h3 id="auswertung-von-splines-de-boor-algorithmus">Auswertung von Splines (<span style="font-variant: small-caps;">de-Boor</span>-Algorithmus)</h3>

</p>

<p>
Ein Spline
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--

                                                                                                                                                 X
                                                                                                                                    p=                    ck bkn ∈ Sτn
                                                                                                                                                  k



-->


<p>

\begin{align*}
p = \sum _k c_k b_k^n \in S_\tau ^n
\end{align*}
kann in \(t \in [\tau _\ell , \tau _{\ell +1})\) durch Bilden von Konvexkombinationen der Koeffizienten der relevanten B-Splines \(b_k^n\), \(k \sim t\), ausgewertet werden (<b><span
class="textsc" >de-Boor</span>-Algorithmus</b>).
</p>
<p>
Beginnend mit
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                              pk0 := ck ,             k = ` − n, . . . , `



-->


<p>

\begin{align*}
p_k^0 := c_k, \quad k = \ell - n, \dotsc , \ell
\end{align*}
berechnet man sukzessive fu&#x0308;r \(m = 0, \dotsc , n - 1\)
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                pkm+1 := γn−m
                                                                                                          k   pkm + (1 − γn−m
                                                                                                                          k   )pk−1
                                                                                                                                m
                                                                                                                                    ,                                 k = ` − n + m + 1, . . . , `



-->


<p>

\begin{align*}
p_k^{m+1} := \gamma _k^{n-m} p_k^m + (1 - \gamma _k^{n-m}) p_{k-1}^m, \quad k = \ell - n + m + 1, \dotsc , \ell
\end{align*}
mit
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                                                         t − τk
                                                                                                                                   γn−m :=
                                                                                                                                    k
                                                                                                                                                      τk+n−m − τk


-->


<p>

\begin{align*}
\gamma _k^{n-m} := \frac {t - \tau _k}{\tau _{k+n-m} - \tau _k}
\end{align*}
und erha&#x0308;lt \(p(t)\) als den letzten Wert \(p_\ell ^n\).
</p>
<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
Die \(p_k^m\) ko&#x0308;nnen in einem Dreiecksschema berechnet werden. Fu&#x0308;r \(t = \tau _\ell \) vereinfacht es sich etwas: Hat \(\tau _\ell \) Vielfachheit \(r\), dann ist \(p(t) = p_{\ell
-r}^{n-r}\), d.&#x202f;h. nur \(n - r\) Schritte der Rekurstion werden beno&#x0308;tigt.
</p>


<h3 id="ableitung-von-splines">Ableitung von Splines</h3>

</p>

<p>
Sei \(\tau \) eine Knotenfolge mit Vielfachheiten \(\le n\). Die Ableitung eines Splines in \(S_\tau ^n\) ist ein Spline vom Grad \(\le n - 1\) zur gleichen Knotenfolge:
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                               0
                                                                                 X                       X                                                                       n
                                                                                       ck bkn        =         αnk ∇ck bkn−1 ∈ Sτn−1                  mit         αnk :=               ,     ∇ck := ck − ck−1 .
                                                                                 k∈Z                     k∈Z
                                                                                                                                                                             τk+n − τk


-->


<p>

\begin{align*}
\left (\sum _{k \in \integer } c_k b_k^n\right )’ = \sum _{k \in \integer } \alpha _k^n \nabla c_k b_k^{n-1} \in S_\tau ^{n-1} \quad \text {mit}\quad
\alpha _k^n := \frac {n}{\tau _{k+n} - \tau _k}, \quad \nabla c_k := c_k - c_{k-1}.
\end{align*}
Entha&#x0308;lt \(\tau \) Knoten mit Vielfachheiten \(&gt; n\), an denen die Splines in \(S_\tau ^n\) Spru&#x0308;nge haben ko&#x0308;nnen, so beha&#x0308;lt die Gleichung auf jedem Intervall, auf dem der Spline
stetig ist, ihre Gu&#x0308;ltigkeit. In diesem Fall werden Ausdru&#x0308;cke mit verschwindenen Nennern, die B-Splines mit leerem Tra&#x0308;ger entsprechen, weggelassen.
</p>
<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>
<p>
Fu&#x0308;r Splines auf einem beschra&#x0308;nkten Parameterintervall \([\alpha , \beta ]\) beschra&#x0308;nkt man die Summation auf die relevanten B-Splines. Genauer sind fu&#x0308;r eine Knotenfolge mit
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--



                                                                                     τ0 ≤ τ1 < α = τn < τn+1 ≤ · · · ≤ τm−1 < τm = β < τm+n−1 ≤ τm+n



-->


<p>

\begin{align*}
\tau _0 \le \tau _1 &lt; \alpha = \tau _n &lt; \tau _{n+1} \le \dotsb \le \tau _{m-1} &lt; \tau _m = \beta &lt; \tau _{m+n-1} \le \tau _{m+n}
\end{align*}
die B-Splines
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--



                                                                                    bkn   mit     k = 0, . . . , m − 1                        und             bkn−1           mit      k = 1, . . . , m − 1



-->


<p>

\begin{align*}
b_k^n \quad \text {mit}\quad k = 0, \dotsc , m - 1 \qquad \text {und}\qquad b_k^{n-1} \quad \text {mit}\quad k = 1, \dotsc , m - 1
\end{align*}
relevant. Dies ist konsistent zur Differenzbildung bei den Koeffizienten, die den Bereich der Indizes um Eins reduziert.
</p>


<h3 id="schoenberg-schema"><span style="font-variant: small-caps;">Schoenberg</span>-Schema</h3>

</p>

<p>
<b><span class="textsc" >Schoenberg</span>s Schema</b> benutzt Funktionswerte an den Knotenmitteln<br />
\(\tau _k^n := (\tau _{k+1} + \dotsb + \tau _{k+n})/n\) als Koeffizienten<br />
einer Spline-Approximation einer glatten Funktion \(f\):
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                                              X
                                                                                                                    f 7→ Q f :=                     f (τnk )bkn ∈ Sτn .
                                                                                                                                              k∈Z



-->


<p>

\begin{align*}
f \mapsto Qf := \sum _{k \in \integer } f(\tau _k^n) b_k^n \in S_\tau ^n.
\end{align*}
Es hat die Fehlerordnung zwei, d.&#x202f;h.
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                                                   1 00
                                                                                                            | f (t) − Q f (t)| ≤                     f         ∞, Dt
                                                                                                                                                                            h(t)2
                                                                                                                                                   2


-->


<p>

\begin{align*}
|f(t) - Qf(t)| \le \frac {1}{2} \norm {f”}_{\infty ,\; D_t} h(t)^2
\end{align*}
mit \(\tau _\ell \le t &lt; \tau _{\ell +1}\) und
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--



                                                                                                   Dt := [τ`−n
                                                                                                           n
                                                                                                               , τ`n ],                        h(t) :=             max |τnk − t|.
                                                                                                                                                              k=`−n,...,`




-->


<p>

\begin{align*}
D_t := [\tau _{\ell -n}^n, \tau _\ell ^n], \qquad h(t) := \max _{k=\ell -n,\dotsc ,\ell } |\tau _k^n - t|.
\end{align*}

</p>
<p>
Der Schoenberg-Operator erha&#x0308;lt Positivita&#x0308;t, Monotonie und Konvexita&#x0308;t, d.&#x202f;h.
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--



                                                                                                                        f (m) ≥ 0             ⇒        (Q f )(m) ≥ 0



-->


<p>

\begin{align*}
f^{(m)} \ge 0 \quad \Rightarrow \quad (Qf)^{(m)} \ge 0
\end{align*}
fu&#x0308;r \(m \le 2\), falls beide Ableitungen existieren. Fu&#x0308;r eine a&#x0308;quidistante Knotenfolge bleibt das Vorzeichen aller Ableitungen bis zur Ordnung \(n\) erhalten.
</p>


<h3 id="quasi-interpolant">Quasi-Interpolant</h3>

</p>

<p>
Ein lineares Approximationsschema
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                                              X
                                                                                                                        f 7→ Q f :=            (Q k f )bkn ∈ Sτn
                                                                                                                                              k∈Z



-->


<p>

\begin{align*}
f \mapsto Qf := \sum _{k \in \integer } (Q_k f) b_k^n \in S_\tau ^n
\end{align*}
fu&#x0308;r stetige Funktionen \(f\) bezeichnet man als <b>Quasi-Interpolant</b>, falls
</p>
<ul style="list-style-type:none">

<li class="list-item-f3"><p>\(Q_k\) lokale beschra&#x0308;nkte lineare Funktionale sind, d.&#x202f;h.
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>

<!--


                                                                                                                             |Q k f | ≤ kQk · k f k∞, Dk


-->

<p>

\begin{align*}
|Q_k f| \le \norm {Q} \cdot \norm {f}_{\infty ,\; D_k}
\end{align*}
mit \(\norm {f}_{\infty ,\; D_k} := \sup _{\tau \in [\tau _k, \tau _{k+n+1})} |f(t)|\), und
</p>
</li>
<li class="list-item-f4"><p>\(Q\) fu&#x0308;r Polynome \(p\) vom Grad \(\le n\) exakt ist, d.&#x202f;h. \(Qp = p\).
</p>
</li>
</ul>
<p>
A&#x0308;quivalent zur zweiten Bedingung ist, dass \(Q_k p = \psi _k(s)\) fu&#x0308;r alle \(s \in \real \) mit \(p(t) := (t - s)^n\) und \(\psi _k(s) := (\xi _{k+1} - s) \dotsm (\xi
_{k+n} - s)\). Diese Identita&#x0308;t fu&#x0308;r Polynome vom Grad \(\le n\) kann man durch Koeffizientenvergleich oder durch Auswertung an \(n + 1\) Punkten pru&#x0308;fen.
</p>


<h3 id="fehler-der-quasi-interpolation">Fehler der Quasi-Interpolation</h3>

</p>

<p>
Fu&#x0308;r den Fehler eines Quasi-Interpolanten
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                                              X
                                                                                                                        f 7→ Q f =             (Q k f )bkn ∈ Sτn
                                                                                                                                               k



-->


<p>

\begin{align*}
f \mapsto Qf = \sum _k (Q_k f) b_k^n \in S_\tau ^n
\end{align*}
gilt
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                                             kQk
                                                                                                 | f (t) − (Q f )(t)| ≤                             f (n+1)                          h(t)n+1
                                                                                                                                           (n + 1)!                        ∞, Dt




-->


<p>

\begin{align*}
|f(t) - (Qf)(t)| \le \frac {\norm {Q}}{(n + 1)!} \norm {f^{(n+1)}}_{\infty ,\; D_t} h(t)^{n+1}
\end{align*}
mit \(D_t\) der Vereinigung der Tra&#x0308;ger aller fu&#x0308;r \(t\) relevanten B-Splines und \(h(t) := \max _{s \in D_t} |s - t|\).
</p>
<p>
Ist das lokale Gitterverha&#x0308;ltnis
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--


                                                                                                                                τk+1 − τk τ j − τ j−1
                                                                                                                                                                                              
                                                                                                 rτ :=         sup          max            ,
                                                                                                       τ j−1 <τ j =τk <τk+1     τ j − τ j−1 τk+1 − τk


-->


<p>

\begin{align*}
r_\tau := \sup _{\tau _{j-1} &lt; \tau _j = \tau _k &lt; \tau _{k+1}} \max \left ( \frac {\tau _{k+1} - \tau _k}{\tau _j - \tau _{j-1}}, \frac {\tau _j -
\tau _{j-1}}{\tau _{k+1} - \tau _k}\right )
\end{align*}
beschra&#x0308;nkt, so la&#x0308;sst sich ebenfalls der Fehler der Ableitungen abscha&#x0308;tzen:
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--



                                                                                          | f ( j) (t) − (Q f )( j) (t)| ≤ const(n, r) kQk f (n+1)                                   ∞, Dt
                                                                                                                                                                                              h(t)n+1− j



-->


<p>

\begin{align*}
|f^{(j)}(t) - (Qf)^{(j)}(t)| \le \const (n, r) \norm {Q} \norm {f^{(n+1)}}_{\infty ,\; D_t} h(t)^{n+1-j}
\end{align*}
fu&#x0308;r alle \(j \le n\), fu&#x0308;r die die Ableitungen existieren.
</p>


<h3 id="loesbarkeit-von-interpolationsproblemen-mit-b-splines">Lösbarkeit von Interpolationsproblemen mit B-Splines</h3>

</p>

<p>
Die Koeffizienten eines Splines \(p = \sum _{k=1}^m c_k b_k^n\), der die Daten \(f_i\) an einer monoton wachsenden Folge von Punkten \(t_i\) interpoliert, werden durch das LGS
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--



                                                                                                                             Ac = f ,          ai,k := bkn (t i )



-->


<p>

\begin{align*}
Ac = f, \quad a_{i,k} := b_k^n(t_i)
\end{align*}
bestimmt. Eine eindeutige Lo&#x0308;sung existiert fu&#x0308;r alle Daten \(f\) genau dann, wenn
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--



                                                                                                                        bkn (t k ) > 0,             k = 1, . . . , m.



-->


<p>

\begin{align*}
b_k^n(t_k) &gt; 0, \quad k = 1, \dotsc , m.
\end{align*}

</p>

{% endraw %}
</div>
{:/nomarkdown}
