
{::nomarkdown}
<div class="lwarp-contents">
{% raw %}
<div class="hidden" >

\(\newcommand{\footnotename}{footnote}\)

\(\def \LWRfootnote {1}\)

\(\newcommand {\footnote }[2][\LWRfootnote ]{{}^{\mathrm {#1}}}\)

\(\newcommand {\footnotemark }[1][\LWRfootnote ]{{}^{\mathrm {#1}}}\)

\(\newcommand \ensuremath [1]{#1}\)

\(\newcommand {\LWRframebox }[2][]{\fbox {#2}} \newcommand {\framebox }[1][]{\LWRframebox } \)

\(\newcommand {\setlength }[2]{}\)

\(\newcommand {\addtolength }[2]{}\)

\(\newcommand {\setcounter }[2]{}\)

\(\newcommand {\addtocounter }[2]{}\)

\(\newcommand {\cline }[1]{}\)

\(\newcommand {\directlua }[1]{\text {(directlua)}}\)

\(\newcommand {\luatexdirectlua }[1]{\text {(directlua)}}\)

\(\newcommand {\protect }{}\)

\(\def \LWRabsorbnumber #1 {}\)

\(\def \LWRabsorbquotenumber &quot;#1 {}\)

\(\def \mathchar {\ifnextchar &quot;\LWRabsorbquotenumber \LWRabsorbnumber }\)

\(\def \mathcode #1={\mathchar }\)

\(\let \delcode \mathcode \)

\(\let \delimiter \mathchar \)

\(\let \LWRref \ref \)

\(\renewcommand {\ref }{\ifstar \LWRref \LWRref }\)

\(\newcommand {\intertext }[1]{\text {#1}\notag \\}\)

\(\newcommand {\mathllap }[2][]{{#1#2}}\)

\(\newcommand {\mathrlap }[2][]{{#1#2}}\)

\(\newcommand {\mathclap }[2][]{{#1#2}}\)

\(\newcommand {\mathmbox }[1]{#1}\)

\(\newcommand {\clap }[1]{#1}\)

\(\newcommand {\LWRmathmakebox }[2][]{#2}\)

\(\newcommand {\mathmakebox }[1][]{\LWRmathmakebox }\)

\(\newcommand {\cramped }[2][]{{#1#2}}\)

\(\newcommand {\crampedllap }[2][]{{#1#2}}\)

\(\newcommand {\crampedrlap }[2][]{{#1#2}}\)

\(\newcommand {\crampedclap }[2][]{{#1#2}}\)

\(\newenvironment {crampedsubarray}[1]{}{}\)

\(\newcommand {\crampedsubstack }{}\)

\(\newcommand {\smashoperator }[2][]{#2\limits }\)

\(\newcommand {\adjustlimits }{}\)

\(\newcommand {\SwapAboveDisplaySkip }{}\)

\(\require {extpfeil}\)

\(\Newextarrow \xleftrightarrow {10,10}{0x2194}\)

\(\Newextarrow \xLeftarrow {10,10}{0x21d0}\)

\(\Newextarrow \xhookleftarrow {10,10}{0x21a9}\)

\(\Newextarrow \xmapsto {10,10}{0x21a6}\)

\(\Newextarrow \xRightarrow {10,10}{0x21d2}\)

\(\Newextarrow \xLeftrightarrow {10,10}{0x21d4}\)

\(\Newextarrow \xhookrightarrow {10,10}{0x21aa}\)

\(\Newextarrow \xrightharpoondown {10,10}{0x21c1}\)

\(\Newextarrow \xleftharpoondown {10,10}{0x21bd}\)

\(\Newextarrow \xrightleftharpoons {10,10}{0x21cc}\)

\(\Newextarrow \xrightharpoonup {10,10}{0x21c0}\)

\(\Newextarrow \xleftharpoonup {10,10}{0x21bc}\)

\(\Newextarrow \xleftrightharpoons {10,10}{0x21cb}\)

\(\newcommand {\LWRdounderbracket }[3]{\underset {#3}{\underline {#1}}}\)

\(\newcommand {\LWRunderbracket }[2][]{\LWRdounderbracket {#2}}\)

\(\newcommand {\underbracket }[1][]{\LWRunderbracket }\)

\(\newcommand {\LWRdooverbracket }[3]{\overset {#3}{\overline {#1}}}\)

\(\newcommand {\LWRoverbracket }[2][]{\LWRdooverbracket {#2}}\)

\(\newcommand {\overbracket }[1][]{\LWRoverbracket }\)

\(\newcommand {\LaTeXunderbrace }[1]{\underbrace {#1}}\)

\(\newcommand {\LaTeXoverbrace }[1]{\overbrace {#1}}\)

\(\newenvironment {matrix*}[1][]{\begin {matrix}}{\end {matrix}}\)

\(\newenvironment {pmatrix*}[1][]{\begin {pmatrix}}{\end {pmatrix}}\)

\(\newenvironment {bmatrix*}[1][]{\begin {bmatrix}}{\end {bmatrix}}\)

\(\newenvironment {Bmatrix*}[1][]{\begin {Bmatrix}}{\end {Bmatrix}}\)

\(\newenvironment {vmatrix*}[1][]{\begin {vmatrix}}{\end {vmatrix}}\)

\(\newenvironment {Vmatrix*}[1][]{\begin {Vmatrix}}{\end {Vmatrix}}\)

\(\newenvironment {smallmatrix*}[1][]{\begin {matrix}}{\end {matrix}}\)

\(\newenvironment {psmallmatrix*}[1][]{\begin {pmatrix}}{\end {pmatrix}}\)

\(\newenvironment {bsmallmatrix*}[1][]{\begin {bmatrix}}{\end {bmatrix}}\)

\(\newenvironment {Bsmallmatrix*}[1][]{\begin {Bmatrix}}{\end {Bmatrix}}\)

\(\newenvironment {vsmallmatrix*}[1][]{\begin {vmatrix}}{\end {vmatrix}}\)

\(\newenvironment {Vsmallmatrix*}[1][]{\begin {Vmatrix}}{\end {Vmatrix}}\)

\(\newenvironment {psmallmatrix}[1][]{\begin {pmatrix}}{\end {pmatrix}}\)

\(\newenvironment {bsmallmatrix}[1][]{\begin {bmatrix}}{\end {bmatrix}}\)

\(\newenvironment {Bsmallmatrix}[1][]{\begin {Bmatrix}}{\end {Bmatrix}}\)

\(\newenvironment {vsmallmatrix}[1][]{\begin {vmatrix}}{\end {vmatrix}}\)

\(\newenvironment {Vsmallmatrix}[1][]{\begin {Vmatrix}}{\end {Vmatrix}}\)

\(\newcommand {\LWRmultlined }[1][]{\begin {multline*}}\)

\(\newenvironment {multlined}[1][]{\LWRmultlined }{\end {multline*}}\)

\(\let \LWRorigshoveleft \shoveleft \)

\(\renewcommand {\shoveleft }[1][]{\LWRorigshoveleft }\)

\(\let \LWRorigshoveright \shoveright \)

\(\renewcommand {\shoveright }[1][]{\LWRorigshoveright }\)

\(\newenvironment {dcases}{\begin {cases}}{\end {cases}}\)

\(\newenvironment {dcases*}{\begin {cases}}{\end {cases}}\)

\(\newenvironment {rcases}{\begin {cases}}{\end {cases}}\)

\(\newenvironment {rcases*}{\begin {cases}}{\end {cases}}\)

\(\newenvironment {drcases}{\begin {cases}}{\end {cases}}\)

\(\newenvironment {drcases*}{\begin {cases}}{\end {cases}}\)

\(\newenvironment {cases*}{\begin {cases}}{\end {cases}}\)

\(\newcommand {\MoveEqLeft }[1][]{}\)

\(\def \LWRAboxed #1&amp;#2&amp;#3!|!{\fbox {\(#1\)}&amp;\fbox {\(#2\)}} \newcommand {\Aboxed }[1]{\LWRAboxed #1&amp;&amp;!|!} \)

\( \newcommand {\LWRABLines }[1][\Updownarrow ]{#1 \notag \\}\newcommand {\ArrowBetweenLines }{\ifstar \LWRABLines \LWRABLines } \)

\(\newcommand {\shortintertext }[1]{\text {#1}\notag \\}\)

\(\newcommand {\vdotswithin }[1]{\hspace {.5em}\vdots }\)

\(\newcommand {\LWRshortvdotswithinstar }[1]{\vdots \hspace {.5em} &amp; \\}\)

\(\newcommand {\LWRshortvdotswithinnostar }[1]{&amp; \hspace {.5em}\vdots \\}\)

\(\newcommand {\shortvdotswithin }{\ifstar \LWRshortvdotswithinstar \LWRshortvdotswithinnostar }\)

\(\newcommand {\MTFlushSpaceAbove }{}\)

\(\newcommand {\MTFlushSpaceBelow }{\\}\)

\(\newcommand \lparen {(}\)

\(\newcommand \rparen {)}\)

\(\newcommand {\ordinarycolon }{:}\)

\(\newcommand {\vcentcolon }{\mathrel {\mathop \ordinarycolon }}\)

\(\newcommand \dblcolon {\vcentcolon \vcentcolon }\)

\(\newcommand \coloneqq {\vcentcolon =}\)

\(\newcommand \Coloneqq {\dblcolon =}\)

\(\newcommand \coloneq {\vcentcolon {-}}\)

\(\newcommand \Coloneq {\dblcolon {-}}\)

\(\newcommand \eqqcolon {=\vcentcolon }\)

\(\newcommand \Eqqcolon {=\dblcolon }\)

\(\newcommand \eqcolon {\mathrel {-}\vcentcolon }\)

\(\newcommand \Eqcolon {\mathrel {-}\dblcolon }\)

\(\newcommand \colonapprox {\vcentcolon \approx }\)

\(\newcommand \Colonapprox {\dblcolon \approx }\)

\(\newcommand \colonsim {\vcentcolon \sim }\)

\(\newcommand \Colonsim {\dblcolon \sim }\)

\(\newcommand {\nuparrow }{\mathrel {\cancel {\uparrow }}}\)

\(\newcommand {\ndownarrow }{\mathrel {\cancel {\downarrow }}}\)

\(\newcommand {\bigtimes }{\mathop {\Large \times }\limits }\)

\(\newcommand {\prescript }[3]{{}^{#1}_{#2}#3}\)

\(\newenvironment {lgathered}{\begin {gathered}}{\end {gathered}}\)

\(\newenvironment {rgathered}{\begin {gathered}}{\end {gathered}}\)

\(\newcommand {\splitfrac }[2]{{}^{#1}_{#2}}\)

\(\let \splitdfrac \splitfrac \)

\(\newcommand {\LWRoverlaysymbols }[2]{\mathord {\smash {\mathop {#2\strut }\limits ^{\smash {\lower 3ex{#1}}}}\strut }}\)

\(\newcommand{\alphaup}{\unicode{x03B1}}\)

\(\newcommand{\betaup}{\unicode{x03B2}}\)

\(\newcommand{\gammaup}{\unicode{x03B3}}\)

\(\newcommand{\digammaup}{\unicode{x03DD}}\)

\(\newcommand{\deltaup}{\unicode{x03B4}}\)

\(\newcommand{\epsilonup}{\unicode{x03F5}}\)

\(\newcommand{\varepsilonup}{\unicode{x03B5}}\)

\(\newcommand{\zetaup}{\unicode{x03B6}}\)

\(\newcommand{\etaup}{\unicode{x03B7}}\)

\(\newcommand{\thetaup}{\unicode{x03B8}}\)

\(\newcommand{\varthetaup}{\unicode{x03D1}}\)

\(\newcommand{\iotaup}{\unicode{x03B9}}\)

\(\newcommand{\kappaup}{\unicode{x03BA}}\)

\(\newcommand{\varkappaup}{\unicode{x03F0}}\)

\(\newcommand{\lambdaup}{\unicode{x03BB}}\)

\(\newcommand{\muup}{\unicode{x03BC}}\)

\(\newcommand{\nuup}{\unicode{x03BD}}\)

\(\newcommand{\xiup}{\unicode{x03BE}}\)

\(\newcommand{\omicronup}{\unicode{x03BF}}\)

\(\newcommand{\piup}{\unicode{x03C0}}\)

\(\newcommand{\varpiup}{\unicode{x03D6}}\)

\(\newcommand{\rhoup}{\unicode{x03C1}}\)

\(\newcommand{\varrhoup}{\unicode{x03F1}}\)

\(\newcommand{\sigmaup}{\unicode{x03C3}}\)

\(\newcommand{\varsigmaup}{\unicode{x03C2}}\)

\(\newcommand{\tauup}{\unicode{x03C4}}\)

\(\newcommand{\upsilonup}{\unicode{x03C5}}\)

\(\newcommand{\phiup}{\unicode{x03D5}}\)

\(\newcommand{\varphiup}{\unicode{x03C6}}\)

\(\newcommand{\chiup}{\unicode{x03C7}}\)

\(\newcommand{\psiup}{\unicode{x03C8}}\)

\(\newcommand{\omegaup}{\unicode{x03C9}}\)

\(\newcommand{\Alphaup}{\unicode{x0391}}\)

\(\newcommand{\Betaup}{\unicode{x0392}}\)

\(\newcommand{\Gammaup}{\unicode{x0393}}\)

\(\newcommand{\Digammaup}{\unicode{x03DC}}\)

\(\newcommand{\Deltaup}{\unicode{x0394}}\)

\(\newcommand{\Epsilonup}{\unicode{x0395}}\)

\(\newcommand{\Zetaup}{\unicode{x0396}}\)

\(\newcommand{\Etaup}{\unicode{x0397}}\)

\(\newcommand{\Thetaup}{\unicode{x0398}}\)

\(\newcommand{\Varthetaup}{\unicode{x03F4}}\)

\(\newcommand{\Iotaup}{\unicode{x0399}}\)

\(\newcommand{\Kappaup}{\unicode{x039A}}\)

\(\newcommand{\Lambdaup}{\unicode{x039B}}\)

\(\newcommand{\Muup}{\unicode{x039C}}\)

\(\newcommand{\Nuup}{\unicode{x039D}}\)

\(\newcommand{\Xiup}{\unicode{x039E}}\)

\(\newcommand{\Omicronup}{\unicode{x039F}}\)

\(\newcommand{\Piup}{\unicode{x03A0}}\)

\(\newcommand{\Varpiup}{\unicode{x03D6}}\)

\(\newcommand{\Rhoup}{\unicode{x03A1}}\)

\(\newcommand{\Sigmaup}{\unicode{x03A3}}\)

\(\newcommand{\Tauup}{\unicode{x03A4}}\)

\(\newcommand{\Upsilonup}{\unicode{x03A5}}\)

\(\newcommand{\Phiup}{\unicode{x03A6}}\)

\(\newcommand{\Chiup}{\unicode{x03A7}}\)

\(\newcommand{\Psiup}{\unicode{x03A8}}\)

\(\newcommand{\Omegaup}{\unicode{x03A9}}\)

\(\newcommand{\alphait}{\unicode{x1D6FC}}\)

\(\newcommand{\betait}{\unicode{x1D6FD}}\)

\(\newcommand{\gammait}{\unicode{x1D6FE}}\)

\(\newcommand{\digammait}{\mathit{\unicode{x03DD}}}\)

\(\newcommand{\deltait}{\unicode{x1D6FF}}\)

\(\newcommand{\epsilonit}{\unicode{x1D716}}\)

\(\newcommand{\varepsilonit}{\unicode{x1D700}}\)

\(\newcommand{\zetait}{\unicode{x1D701}}\)

\(\newcommand{\etait}{\unicode{x1D702}}\)

\(\newcommand{\thetait}{\unicode{x1D703}}\)

\(\newcommand{\varthetait}{\unicode{x1D717}}\)

\(\newcommand{\iotait}{\unicode{x1D704}}\)

\(\newcommand{\kappait}{\unicode{x1D705}}\)

\(\newcommand{\varkappait}{\unicode{x1D718}}\)

\(\newcommand{\lambdait}{\unicode{x1D706}}\)

\(\newcommand{\muit}{\unicode{x1D707}}\)

\(\newcommand{\nuit}{\unicode{x1D708}}\)

\(\newcommand{\xiit}{\unicode{x1D709}}\)

\(\newcommand{\omicronit}{\unicode{x1D70A}}\)

\(\newcommand{\piit}{\unicode{x1D70B}}\)

\(\newcommand{\varpiit}{\unicode{x1D71B}}\)

\(\newcommand{\rhoit}{\unicode{x1D70C}}\)

\(\newcommand{\varrhoit}{\unicode{x1D71A}}\)

\(\newcommand{\sigmait}{\unicode{x1D70E}}\)

\(\newcommand{\varsigmait}{\unicode{x1D70D}}\)

\(\newcommand{\tauit}{\unicode{x1D70F}}\)

\(\newcommand{\upsilonit}{\unicode{x1D710}}\)

\(\newcommand{\phiit}{\unicode{x1D719}}\)

\(\newcommand{\varphiit}{\unicode{x1D711}}\)

\(\newcommand{\chiit}{\unicode{x1D712}}\)

\(\newcommand{\psiit}{\unicode{x1D713}}\)

\(\newcommand{\omegait}{\unicode{x1D714}}\)

\(\newcommand{\Alphait}{\unicode{x1D6E2}}\)

\(\newcommand{\Betait}{\unicode{x1D6E3}}\)

\(\newcommand{\Gammait}{\unicode{x1D6E4}}\)

\(\newcommand{\Digammait}{\mathit{\unicode{x03DC}}}\)

\(\newcommand{\Deltait}{\unicode{x1D6E5}}\)

\(\newcommand{\Epsilonit}{\unicode{x1D6E6}}\)

\(\newcommand{\Zetait}{\unicode{x1D6E7}}\)

\(\newcommand{\Etait}{\unicode{x1D6E8}}\)

\(\newcommand{\Thetait}{\unicode{x1D6E9}}\)

\(\newcommand{\Varthetait}{\unicode{x1D6F3}}\)

\(\newcommand{\Iotait}{\unicode{x1D6EA}}\)

\(\newcommand{\Kappait}{\unicode{x1D6EB}}\)

\(\newcommand{\Lambdait}{\unicode{x1D6EC}}\)

\(\newcommand{\Muit}{\unicode{x1D6ED}}\)

\(\newcommand{\Nuit}{\unicode{x1D6EE}}\)

\(\newcommand{\Xiit}{\unicode{x1D6EF}}\)

\(\newcommand{\Omicronit}{\unicode{x1D6F0}}\)

\(\newcommand{\Piit}{\unicode{x1D6F1}}\)

\(\newcommand{\Rhoit}{\unicode{x1D6F2}}\)

\(\newcommand{\Sigmait}{\unicode{x1D6F4}}\)

\(\newcommand{\Tauit}{\unicode{x1D6F5}}\)

\(\newcommand{\Upsilonit}{\unicode{x1D6F6}}\)

\(\newcommand{\Phiit}{\unicode{x1D6F7}}\)

\(\newcommand{\Chiit}{\unicode{x1D6F8}}\)

\(\newcommand{\Psiit}{\unicode{x1D6F9}}\)

\(\newcommand{\Omegait}{\unicode{x1D6FA}}\)

\(\let \digammaup \Digammaup \)

\(\renewcommand {\digammait }{\mathit {\digammaup }}\)

\(\newcommand {\smallin }{\unicode {x220A}}\)

\(\newcommand {\smallowns }{\unicode {x220D}}\)

\(\newcommand {\notsmallin }{\LWRoverlaysymbols {/}{\unicode {x220A}}}\)

\(\newcommand {\notsmallowns }{\LWRoverlaysymbols {/}{\unicode {x220D}}}\)

\(\newcommand {\rightangle }{\unicode {x221F}}\)

\(\newcommand {\intclockwise }{\unicode {x2231}}\)

\(\newcommand {\ointclockwise }{\unicode {x2232}}\)

\(\newcommand {\ointctrclockwise }{\unicode {x2233}}\)

\(\newcommand {\oiint }{\unicode {x222F}}\)

\(\newcommand {\oiiint }{\unicode {x2230}}\)

\(\newcommand {\ddag }{\unicode {x2021}}\)

\(\newcommand {\P }{\unicode {x00B6}}\)

\(\newcommand {\copyright }{\unicode {x00A9}}\)

\(\newcommand {\dag }{\unicode {x2020}}\)

\(\newcommand {\pounds }{\unicode {x00A3}}\)

\(\newcommand {\iddots }{\unicode {x22F0}}\)

\(\newcommand {\utimes }{\overline {\times }}\)

\(\newcommand {\dtimes }{\underline {\times }}\)

\(\newcommand {\udtimes }{\overline {\underline {\times }}}\)

\(\newcommand {\leftwave }{\left \{}\)

\(\newcommand {\rightwave }{\right \}}\)

\(\newcommand {\toprule }[1][]{\hline }\)

\(\let \midrule \toprule \)

\(\let \bottomrule \toprule \)

\(\newcommand {\cmidrule }[2][]{}\)

\(\newcommand {\morecmidrules }{}\)

\(\newcommand {\specialrule }[3]{\hline }\)

\(\newcommand {\addlinespace }[1][]{}\)

\(\newcommand {\LWRsubmultirow }[2][]{#2}\)

\(\newcommand {\LWRmultirow }[2][]{\LWRsubmultirow }\)

\(\newcommand {\multirow }[2][]{\LWRmultirow }\)

\(\newcommand {\mrowcell }{}\)

\(\newcommand {\mcolrowcell }{}\)

\(\newcommand {\STneed }[1]{}\)

\( \newcommand {\multicolumn }[3]{#3}\)

\(\newcommand {\tothe }[1]{^{#1}}\)

\(\newcommand {\raiseto }[2]{{#2}^{#1}}\)

\(\newcommand {\ang }[2][]{(\mathrm {#2})\degree }\)

\(\newcommand {\num }[2][]{\mathrm {#2}}\)

\(\newcommand {\si }[2][]{\mathrm {#2}}\)

\(\newcommand {\LWRSI }[2][]{\mathrm {#1\LWRSInumber \,#2}}\)

\(\newcommand {\SI }[2][]{\def \LWRSInumber {#2}\LWRSI }\)

\(\newcommand {\numlist }[2][]{\mathrm {#2}}\)

\(\newcommand {\numrange }[3][]{\mathrm {#2\,\unicode {x2013}\,#3}}\)

\(\newcommand {\SIlist }[3][]{\mathrm {#2\,#3}}\)

\(\newcommand {\SIrange }[4][]{\mathrm {#2\,#4\,\unicode {x2013}\,#3\,#4}}\)

\(\newcommand {\tablenum }[2][]{\mathrm {#2}}\)

\(\newcommand {\ampere }{\mathrm {A}}\)

\(\newcommand {\candela }{\mathrm {cd}}\)

\(\newcommand {\kelvin }{\mathrm {K}}\)

\(\newcommand {\kilogram }{\mathrm {kg}}\)

\(\newcommand {\metre }{\mathrm {m}}\)

\(\newcommand {\mole }{\mathrm {mol}}\)

\(\newcommand {\second }{\mathrm {s}}\)

\(\newcommand {\becquerel }{\mathrm {Bq}}\)

\(\newcommand {\degreeCelsius }{\unicode {x2103}}\)

\(\newcommand {\coulomb }{\mathrm {C}}\)

\(\newcommand {\farad }{\mathrm {F}}\)

\(\newcommand {\gray }{\mathrm {Gy}}\)

\(\newcommand {\hertz }{\mathrm {Hz}}\)

\(\newcommand {\henry }{\mathrm {H}}\)

\(\newcommand {\joule }{\mathrm {J}}\)

\(\newcommand {\katal }{\mathrm {kat}}\)

\(\newcommand {\lumen }{\mathrm {lm}}\)

\(\newcommand {\lux }{\mathrm {lx}}\)

\(\newcommand {\newton }{\mathrm {N}}\)

\(\newcommand {\ohm }{\mathrm {\Omega }}\)

\(\newcommand {\pascal }{\mathrm {Pa}}\)

\(\newcommand {\radian }{\mathrm {rad}}\)

\(\newcommand {\siemens }{\mathrm {S}}\)

\(\newcommand {\sievert }{\mathrm {Sv}}\)

\(\newcommand {\steradian }{\mathrm {sr}}\)

\(\newcommand {\tesla }{\mathrm {T}}\)

\(\newcommand {\volt }{\mathrm {V}}\)

\(\newcommand {\watt }{\mathrm {W}}\)

\(\newcommand {\weber }{\mathrm {Wb}}\)

\(\newcommand {\day }{\mathrm {d}}\)

\(\newcommand {\degree }{\mathrm {^\circ }}\)

\(\newcommand {\hectare }{\mathrm {ha}}\)

\(\newcommand {\hour }{\mathrm {h}}\)

\(\newcommand {\litre }{\mathrm {l}}\)

\(\newcommand {\liter }{\mathrm {L}}\)

\(\newcommand {\arcminute }{^\prime }\)
\(\newcommand {\minute }{\mathrm {min}}\)

\(\newcommand {\arcsecond }{^{\prime \prime }}\)

\(\newcommand {\tonne }{\mathrm {t}}\)

\(\newcommand {\astronomicalunit }{au}\)

\(\newcommand {\atomicmassunit }{u}\)

\(\newcommand {\bohr }{\mathit {a}_0}\)

\(\newcommand {\clight }{\mathit {c}_0}\)

\(\newcommand {\dalton }{\mathrm {D}_\mathrm {a}}\)

\(\newcommand {\electronmass }{\mathit {m}_{\mathrm {e}}}\)

\(\newcommand {\electronvolt }{\mathrm {eV}}\)

\(\newcommand {\elementarycharge }{\mathit {e}}\)

\(\newcommand {\hartree }{\mathit {E}_{\mathrm {h}}}\)

\(\newcommand {\planckbar }{\mathit {\unicode {x210F}}}\)

\(\newcommand {\angstrom }{\mathrm {\unicode {x212B}}}\)

\(\let \LWRorigbar \bar \)

\(\newcommand {\bar }{\mathrm {bar}}\)

\(\newcommand {\barn }{\mathrm {b}}\)

\(\newcommand {\bel }{\mathrm {B}}\)

\(\newcommand {\decibel }{\mathrm {dB}}\)

\(\newcommand {\knot }{\mathrm {kn}}\)

\(\newcommand {\mmHg }{\mathrm {mmHg}}\)

\(\newcommand {\nauticalmile }{\mathrm {M}}\)

\(\newcommand {\neper }{\mathrm {Np}}\)

\(\newcommand {\yocto }{\mathrm {y}}\)

\(\newcommand {\zepto }{\mathrm {z}}\)

\(\newcommand {\atto }{\mathrm {a}}\)

\(\newcommand {\femto }{\mathrm {f}}\)

\(\newcommand {\pico }{\mathrm {p}}\)

\(\newcommand {\nano }{\mathrm {n}}\)

\(\newcommand {\micro }{\mathrm {\unicode {x00B5}}}\)

\(\newcommand {\milli }{\mathrm {m}}\)

\(\newcommand {\centi }{\mathrm {c}}\)

\(\newcommand {\deci }{\mathrm {d}}\)

\(\newcommand {\deca }{\mathrm {da}}\)

\(\newcommand {\hecto }{\mathrm {h}}\)

\(\newcommand {\kilo }{\mathrm {k}}\)

\(\newcommand {\mega }{\mathrm {M}}\)

\(\newcommand {\giga }{\mathrm {G}}\)

\(\newcommand {\tera }{\mathrm {T}}\)

\(\newcommand {\peta }{\mathrm {P}}\)

\(\newcommand {\exa }{\mathrm {E}}\)

\(\newcommand {\zetta }{\mathrm {Z}}\)

\(\newcommand {\yotta }{\mathrm {Y}}\)

\(\newcommand {\percent }{\mathrm {\%}}\)

\(\newcommand {\meter }{\mathrm {m}}\)

\(\newcommand {\metre }{\mathrm {m}}\)

\(\newcommand {\gram }{\mathrm {g}}\)

\(\newcommand {\kg }{\kilo \gram }\)

\(\newcommand {\of }[1]{_{\mathrm {#1}}}\)

\(\newcommand {\squared }{^2}\)

\(\newcommand {\square }[1]{\mathrm {#1}^2}\)

\(\newcommand {\cubed }{^3}\)

\(\newcommand {\cubic }[1]{\mathrm {#1}^3}\)

\(\newcommand {\per }{/}\)

\(\newcommand {\celsius }{\unicode {x2103}}\)

\(\newcommand {\fg }{\femto \gram }\)

\(\newcommand {\pg }{\pico \gram }\)

\(\newcommand {\ng }{\nano \gram }\)

\(\newcommand {\ug }{\micro \gram }\)

\(\newcommand {\mg }{\milli \gram }\)

\(\newcommand {\g }{\gram }\)

\(\newcommand {\kg }{\kilo \gram }\)

\(\newcommand {\amu }{\mathrm {u}}\)

\(\newcommand {\nm }{\nano \metre }\)

\(\newcommand {\um }{\micro \metre }\)

\(\newcommand {\mm }{\milli \metre }\)

\(\newcommand {\cm }{\centi \metre }\)

\(\newcommand {\dm }{\deci \metre }\)

\(\newcommand {\m }{\metre }\)

\(\newcommand {\km }{\kilo \metre }\)

\(\newcommand {\as }{\atto \second }\)

\(\newcommand {\fs }{\femto \second }\)

\(\newcommand {\ps }{\pico \second }\)

\(\newcommand {\ns }{\nano \second }\)

\(\newcommand {\us }{\micro \second }\)

\(\newcommand {\ms }{\milli \second }\)

\(\newcommand {\s }{\second }\)

\(\newcommand {\fmol }{\femto \mol }\)

\(\newcommand {\pmol }{\pico \mol }\)

\(\newcommand {\nmol }{\nano \mol }\)

\(\newcommand {\umol }{\micro \mol }\)

\(\newcommand {\mmol }{\milli \mol }\)

\(\newcommand {\mol }{\mol }\)

\(\newcommand {\kmol }{\kilo \mol }\)

\(\newcommand {\pA }{\pico \ampere }\)

\(\newcommand {\nA }{\nano \ampere }\)

\(\newcommand {\uA }{\micro \ampere }\)

\(\newcommand {\mA }{\milli \ampere }\)

\(\newcommand {\A }{\ampere }\)

\(\newcommand {\kA }{\kilo \ampere }\)

\(\newcommand {\ul }{\micro \litre }\)

\(\newcommand {\ml }{\milli \litre }\)

\(\newcommand {\l }{\litre }\)

\(\newcommand {\hl }{\hecto \litre }\)

\(\newcommand {\uL }{\micro \liter }\)

\(\newcommand {\mL }{\milli \liter }\)

\(\newcommand {\L }{\liter }\)

\(\newcommand {\hL }{\hecto \liter }\)

\(\newcommand {\mHz }{\milli \hertz }\)

\(\newcommand {\Hz }{\hertz }\)

\(\newcommand {\kHz }{\kilo \hertz }\)

\(\newcommand {\MHz }{\mega \hertz }\)

\(\newcommand {\GHz }{\giga \hertz }\)

\(\newcommand {\THz }{\tera \hertz }\)

\(\newcommand {\mN }{\milli \newton }\)

\(\newcommand {\N }{\newton }\)

\(\newcommand {\kN }{\kilo \newton }\)

\(\newcommand {\MN }{\mega \newton }\)

\(\newcommand {\Pa }{\pascal }\)

\(\newcommand {\kPa }{\kilo \pascal }\)

\(\newcommand {\MPa }{\mega \pascal }\)

\(\newcommand {\GPa }{\giga \pascal }\)

\(\newcommand {\mohm }{\milli \ohm }\)

\(\newcommand {\kohm }{\kilo \ohm }\)

\(\newcommand {\Mohm }{\mega \ohm }\)

\(\newcommand {\pV }{\pico \volt }\)

\(\newcommand {\nV }{\nano \volt }\)

\(\newcommand {\uV }{\micro \volt }\)

\(\newcommand {\mV }{\milli \volt }\)

\(\newcommand {\V }{\volt }\)

\(\newcommand {\kV }{\kilo \volt }\)

\(\newcommand {\W }{\watt }\)

\(\newcommand {\uW }{\micro \watt }\)

\(\newcommand {\mW }{\milli \watt }\)

\(\newcommand {\kW }{\kilo \watt }\)

\(\newcommand {\MW }{\mega \watt }\)

\(\newcommand {\GW }{\giga \watt }\)

\(\newcommand {\J }{\joule }\)

\(\newcommand {\uJ }{\micro \joule }\)

\(\newcommand {\mJ }{\milli \joule }\)

\(\newcommand {\kJ }{\kilo \joule }\)

\(\newcommand {\eV }{\electronvolt }\)

\(\newcommand {\meV }{\milli \electronvolt }\)

\(\newcommand {\keV }{\kilo \electronvolt }\)

\(\newcommand {\MeV }{\mega \electronvolt }\)

\(\newcommand {\GeV }{\giga \electronvolt }\)

\(\newcommand {\TeV }{\tera \electronvolt }\)

\(\newcommand {\kWh }{\kilo \watt \hour }\)

\(\newcommand {\F }{\farad }\)

\(\newcommand {\fF }{\femto \farad }\)

\(\newcommand {\pF }{\pico \farad }\)

\(\newcommand {\K }{\mathrm {K}}\)

\(\newcommand {\dB }{\mathrm {dB}}\)

\(\newcommand {\kibi }{\mathrm {Ki}}\)

\(\newcommand {\mebi }{\mathrm {Mi}}\)

\(\newcommand {\gibi }{\mathrm {Gi}}\)

\(\newcommand {\tebi }{\mathrm {Ti}}\)

\(\newcommand {\pebi }{\mathrm {Pi}}\)

\(\newcommand {\exbi }{\mathrm {Ei}}\)

\(\newcommand {\zebi }{\mathrm {Zi}}\)

\(\newcommand {\yobi }{\mathrm {Yi}}\)

\(\require {mhchem}\)

\(\require {cancel}\)

\(\newcommand {\fint }{âĺŊ}\)

\(\newcommand {\hdots }{\cdots }\)

\(\newcommand {\mathnormal }[1]{#1}\)

\(\newcommand {\vecs }[2]{\vec {#1}_{#2}}\)

\(\renewcommand {\O }{\ensuremath {\mathcal {O}}}\)

\(\renewcommand {\P }{\ensuremath {\mathcal {P}}}\)

\(\newcommand {\Abl }{\ensuremath {\text {Abl}}}\)

\(\newcommand {\REG }{\ensuremath {\text {REG}}}\)

\(\newcommand {\CFL }{\ensuremath {\text {CFL}}}\)

\(\newcommand {\DCFL }{\ensuremath {\text {DCFL}}}\)

\(\newcommand {\DEA }{\ensuremath {\text {DEA}}}\)

\(\newcommand {\NEA }{\ensuremath {\text {NEA}}}\)

\(\newcommand {\DTM }{\ensuremath {\text {DTM}}}\)

\(\newcommand {\NTM }{\ensuremath {\text {NTM}}}\)

\(\newcommand {\LBA }{\ensuremath {\text {LBA}}}\)

\(\newcommand {\coLBA }{\ensuremath {\text {co-LBA}}}\)

\(\newcommand {\DLBA }{\ensuremath {\text {DLBA}}}\)

\(\newcommand {\TypNull }{\ensuremath {\text {Typ-0}}}\)

\(\newcommand {\RegExp }{\ensuremath {\text {RegExp}}}\)

\(\newcommand {\Synt }{\ensuremath {\text {Synt}}}\)

\(\newcommand {\dollar }{\ensuremath {\$}}\)

\(\newcommand {\FOR }{\ensuremath {\mathbf {for}\;}}\)

\(\newcommand {\FORALL }{\ensuremath {\mathbf {forall}\;}}\)

\(\newcommand {\REPEAT }{\ensuremath {\mathbf {repeat}\;}}\)

\(\newcommand {\UNTIL }{\ensuremath {\mathbf {until}\;}}\)

\(\newcommand {\OR }{\ensuremath {\mathbf {or}\;}}\)

\(\newcommand {\IF }{\ensuremath {\mathbf {if}\;}}\)

\(\newcommand {\THEN }{\ensuremath {\mathbf {then}\;}}\)

\(\newcommand {\ELSE }{\ensuremath {\mathbf {else}\;}}\)

\(\newcommand {\END }{\ensuremath {\mathbf {end}\;}}\)

\(\newcommand {\TO }{\ensuremath {\mathbf {to}\;}}\)

\(\newcommand {\DO }{\ensuremath {\mathbf {do}\;}}\)

\(\newcommand {\name }[1]{\textsc {#1}}\)

\(\newcommand {\smallpmatrix }[1]{\left (\begin {smallmatrix}#1\end {smallmatrix}\right )}\)

\(\newcommand {\matlab }{{\fontfamily {bch}\scshape \selectfont {}Matlab}}\)

\(\newcommand {\innerproduct }[1]{\left \langle {#1}\right \rangle }\)

\(\newcommand {\norm }[1]{\left \Vert {#1}\right \Vert }\)

\(\renewcommand {\natural }{\mathbb {N}}\)

\(\newcommand {\integer }{\mathbb {Z}}\)

\(\newcommand {\rational }{\mathbb {Q}}\)

\(\newcommand {\real }{\mathbb {R}}\)

\(\newcommand {\complex }{\mathbb {C}}\)

\(\renewcommand {\d }{\mathop {}\!\mathrm {d}}\)

\(\newcommand {\dr }{\d {}r}\)

\(\newcommand {\ds }{\d {}s}\)

\(\newcommand {\dt }{\d {}t}\)

\(\newcommand {\du }{\d {}u}\)

\(\newcommand {\dv }{\d {}v}\)

\(\newcommand {\dw }{\d {}w}\)

\(\newcommand {\dx }{\d {}x}\)

\(\newcommand {\dy }{\d {}y}\)

\(\newcommand {\dz }{\d {}z}\)

\(\newcommand {\dsigma }{\d {}\sigma }\)

\(\newcommand {\dphi }{\d {}\phi }\)

\(\newcommand {\dvarphi }{\d {}\varphi }\)

\(\newcommand {\dtau }{\d {}\tau }\)

\(\newcommand {\dxi }{\d {}\xi }\)

\(\newcommand {\dtheta }{\d {}\theta }\)

\(\newcommand {\tp }{\mathrm {T}}\)

</div>

<style type="text/css">
.lwarp-contents li.list-item-f0::marker {
  font-style:italic;
  content:'(1)\00a0\00a0';
}
.lwarp-contents li.list-item-f1::marker {
  font-style:italic;
  content:'(2)\00a0\00a0';
}
.lwarp-contents li.list-item-f2::marker {
  font-style:italic;
  content:'(3)\00a0\00a0';
}
.lwarp-contents li.list-item-f3::marker {
  font-style:italic;
  content:'(4)\00a0\00a0';
}
.lwarp-contents li.list-item-f4::marker {
  font-style:italic;
  content:'(5)\00a0\00a0';
}
.lwarp-contents li.list-item-f5::marker {
  font-style:italic;
  content:'(1)\00a0\00a0';
}
.lwarp-contents li.list-item-f6::marker {
  font-style:italic;
  content:'(2)\00a0\00a0';
}
.lwarp-contents li.list-item-f7::marker {
  font-style:italic;
  content:'(3)\00a0\00a0';
}
.lwarp-contents li.list-item-f8::marker {
  font-style:italic;
  content:'(1)\00a0\00a0';
}
.lwarp-contents li.list-item-f9::marker {
  font-style:italic;
  content:'(2)\00a0\00a0';
}
.lwarp-contents li.list-item-f10::marker {
  font-style:italic;
  content:'(3)\00a0\00a0';
}
.lwarp-contents li.list-item-f11::marker {
  content:'•\00a0\00a0';
}
.lwarp-contents li.list-item-f12::marker {
  content:'•\00a0\00a0';
}
.lwarp-contents li.list-item-f13::marker {
  content:'•\00a0\00a0';
}
.lwarp-contents li.list-item-f14::marker {
  content:'•\00a0\00a0';
}
.lwarp-contents li.list-item-f15::marker {
  content:'•\00a0\00a0';
}
.lwarp-contents li.list-item-f16::marker {
  content:'•\00a0\00a0';
}
</style>
<p>

</p>


<p>
<em>Bemerkung</em>: Regula&#x0308;re Sprachen sind nu&#x0308;tzlich, aber doch sehr begrenzt (sie haben sozusagen ein „endliches“ Geda&#x0308;chtnis). Geht man zur gro&#x0308;ßeren Klasse der Typ-2- oder kontextfreien
Sprachen u&#x0308;ber, so stehen mehr Mo&#x0308;glichkeiten offen. Allein schon die Sprache \(L = \{a^n b^n \;|\; n \ge 1\}\) ist eine Typ-2-Sprache, die nicht regula&#x0308;r ist (siehe oben). Weitere Beispiele
umfassen Grammatiken fu&#x0308;r arithmetische Ausdru&#x0308;cke oder Programmiersprachen (die Syntax von praktisch jeder Programmiersprache la&#x0308;sst sich mit einer kontextfreien Grammatik beschreiben).<br />
Eine typische Regel wa&#x0308;re \(\langle \text {Anweisung}\rangle ::= \text {Zuweisung} \;|\; \text {Anweisung}\mathbf {;}\; \text {Anweisung} \;|\;\)<br />
\(\mathbf {if}\; \text {bedingung}\; \mathbf {then}\; \text {Anweisung}\; \mathbf {fi} \;|\; \mathbf {while}\; \text {bedingung}\; \mathbf {do}\; \text {Anweisung}\; \mathbf {od}\) (dabei sind
Terminale fett, inklusive dem Semikolon).
</p>



<h2 id="normalformen">Normalformen</h2>

</p>


<p>
<em>Bemerkung</em>: Man will jeder kontextfreien Grammatik eine andere kontextfreie Grammatik zuweisen, die mo&#x0308;glichst „einfach“ aufgebaut ist und die gleiche Sprache erzeugt.<br />
Im Folgenden wird dafu&#x0308;r angenommen, dass es keine \(\varepsilon \)-Regeln gibt (sonst ersetzt man \(L\) durch \(L \setminus \{\varepsilon \}\)).
</p>

<p>
<em>Lemma</em> (<span class="textsl" >Beseitigung von Ringableitungen</span>): Sei \(G\) eine Typ-2-Grammatik.<br />
Dann gibt es eine Typ-2-Grammatik \(G’\) mit \(L(G) = L(G’)\), die keine <em><span class="dashuline" >Ringableitungen</span></em> entha&#x0308;lt (d.&#x202f;h. es gibt keine Variablen \(B_1, \dotsc , B_k\) mit
\(B_1 \rightarrow \dotsb \rightarrow B_k\) und \(B_k = B_1\)).
</p>

<p>
<b>Beweis</b>: Ist \(B_1 \rightarrow \dotsb \rightarrow B_k\) mit \(B_k = B_1\) eine Ringableitung, so ersetzt man in den Regeln alle \(B_i\), \(i = 2, \dotsc , k\) durch \(B_1\). Dabei ko&#x0308;nnen
natu&#x0308;rlich Duplikate auftreten (z.&#x202f;B. bei \(A \rightarrow AB_1\) und \(A \rightarrow AB_2\)), diese la&#x0308;sst man weg (Produktionsmenge ist ja eine Menge). Die Regel \(B_1 \rightarrow B_1\) kann
man ebenfalls weglassen. Die so entstandene Grammatik \(G’\) erzeugt dieselbe Sprache wie die urspru&#x0308;ngliche Grammatik \(G\). &#x2003;&#x2003;
</p>

<p>
<em>Lemma</em> (<span class="textsl" >Beseitigung von Regeln der Form \(A \rightarrow B\)</span>): Sei \(G\) eine Typ-2-Grammatik.<br />
Dann gibt es eine Typ-2-Grammatik \(G’\) mit \(L(G) = L(G’)\), die keine Regeln der Form \(A \rightarrow B\) mit \(A\) und \(B\) Variablen entha&#x0308;lt.
</p>

<p>
<b>Beweis</b>: Zuna&#x0308;chst la&#x0308;sst sich die Variablenmenge \(V\) ordnen, sodass \(V = \{A_1, \dotsc , A_n\}\) mit \(A_i \not = A_j\) fu&#x0308;r \(i \not = j\) und \(A_i \rightarrow A_j\) tritt nur
fu&#x0308;r \(i &lt; j\) auf (d.&#x202f;h. \(\forall _{i=1,\dots ,n} \forall _{j=1,\dotsc ,i}\; A_i \rightarrow A_j \notin P\)).
</p>

<p>
Wieso geht das? Betrachte den gerichteten Graphen mit Knotenmenge \(V = \{C_1, \dotsc , C_n\}\) und Regeln als Kanten (d.&#x202f;h. es gibt eine Kante von \(C_i\) nach \(C_j\) genau dann, falls \(C_i \rightarrow C_j
\in P\)). Dieser Graph ist kreisfrei, da oBdA keine Ringableitungen vorhanden sind (siehe Lemma von eben). Nun gibt es ein \(i\), sodass fu&#x0308;r alle \(j\) gilt, dass \(C_i \rightarrow C_j \notin P\) (andernfalls
ga&#x0308;be es einen Kreis). Man setzt nun \(A_n := C_i\), entfernt \(A_n\) inkl. den eingehenden Kanten aus dem Graphen und wiederholt diese Prozedur. Es kommen also keine Regeln \(A_i \rightarrow A_j \in P\) mit
\(i \ge j\) vor (die z.&#x202f;B. im ersten Schritt entfernten Kanten \(A_i \rightarrow A_n\), \(i = 1, \dotsc , n - 1\) sind ja erlaubt).
</p>

<p>
Nun kann man alle Regeln der Form \(A_i \rightarrow A_j\) eliminieren: Jede Regel \(A_n \rightarrow w\) mit \(w \in (V \cup \Sigma )^+\) hat als rechte Seite \(w \notin V\) keine Variable. Falls es Regeln \(A_i
\rightarrow A_n\) mit \(i &lt; n\) gibt, ersetzt man diese Regeln durch \(A_i \rightarrow w\) fu&#x0308;r jede Regel der Form \(A_n \rightarrow w\). Anschließend gibt es keine Regeln \(A_i \rightarrow A_n\) mit \(i
&lt; n\) mehr. Man wiederholt dies mit \(A_{n-1}\) usw. bis \(A_2\).
</p>

<p>
Die Sprache wird dabei nicht vera&#x0308;ndert und die so entstandene Grammatik \(G’\) entha&#x0308;lt keine Regeln der Form \(A \rightarrow B\) mit \(A\) und \(B\) Variablen. &#x2003;&#x2003;
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b><span class="textsc" >Chomsky</span>-Normalform</b>:&#x2003; Eine Typ-2-Grammatik heißt in <em><span class="dashuline" ><span class="textsc" >Chomsky</span>-Normalform</span></em>, falls alle
Regeln von der Form \(A \rightarrow BC\) oder \(A \rightarrow a\) sind (\(A, B, C\) Variablen und \(a\) Terminal).
</p>

<p>
<em>Bemerkung</em>: Die Ableitungsba&#x0308;ume bekommen damit eine sehr regelma&#x0308;ßige Form, denn sie sind alle bina&#x0308;r. Jede Ableitung eines Worts der La&#x0308;nge \(n\) hat in einer CNF-Grammatik
die La&#x0308;nge von \(2n - 1\) Ableitungsschritten.
</p>

<p>
<span class="uline" ><em>Satz</em> (<span class="textsl" ><span class="textsc" >Chomsky</span>-Normalform</span>):</span> Zu jeder kontextfreien Grammatik \(G\) mit \(\varepsilon \notin L(G)\) gibt es
eine kontextfreie Grammatik \(G’\) in Chomsky-Normalform mit \(L(G) = L(G’)\).
</p>

<p>
<b>Beweis</b>: Zuna&#x0308;chst fu&#x0308;hrt man fu&#x0308;r jedes Terminalzeichen eine sog. <em><span class="dashuline" >Pseudovariable</span></em> ein. Sei also \(\Sigma = \{\sigma _1, \dotsc , \sigma
_k\}\). Fu&#x0308;hre fu&#x0308;r alle \(i = 1, \dotsc , k\) eine Variable \(V_{\sigma _i}\) ein. Ersetze in allen Regeln Terminale grundsa&#x0308;tzlich durch die entsprechenden Pseudoterminale und fu&#x0308;ge die
Regel \(V_{\sigma _i} \rightarrow \sigma _i\) hinzu. Dies vera&#x0308;ndert die Sprache nicht und alle Regeln haben jetzt die Form von entweder \(A \rightarrow a\) oder \(A \rightarrow w\) mit \(w \in V^+\) und
\(|w| \ge 2\) (oBdA nach obigem Lemma).
</p>

<p>
Die Regeln der Form \(A \rightarrow a\) sind okay (kompatibel zur CNF). Die Regeln \(A \rightarrow B_1 \dotsb B_k\) mit \(k \ge 2\) sind fu&#x0308;r \(k = 2\) ebenfalls okay, fu&#x0308;r \(k &gt; 2\)
mu&#x0308;ssen diese umgeformt werden: Diese Regel wird ersetzt durch die Regeln \(A \rightarrow B_1 C_2\), \(C_2 \rightarrow B_2 C_3\) usw. bis \(C_{k-1} \rightarrow B_{k-1} B_k\). Dabei sind \(C_2, \dotsc ,
C_{k-1}\) neue Variablen. Durch diese Anpassung wird die Sprache ebenfalls nicht gea&#x0308;ndert, die entstandene Grammatik \(G’\) ist in Chomsky-Normalform. &#x2003;&#x2003;
</p>

<p>
<em>Bemerkung</em>: Die Vorgehensweise, um eine gegebene kontextfreie Grammatik in ein CNF umzuwandeln, wird aus den konstruktiven Beweisen ersichtlich:
</p>
<ul style="list-style-type:none">

<li class="list-item-f0"><p>  Elimination von Ringableitungen durch Ersetzen aller in der Ringableitung vorkommenden Variablen durch eine einzige Variable
</p>
</li>
<li class="list-item-f1"><p>  Sortierung der Variablen zu einer Menge \(\{A_1, \dotsc , A_n\}\), sodass keine Regeln \(A_i \rightarrow A_j\) mit \(j \le i\) auftreten
</p>
</li>
<li class="list-item-f2"><p>  Elimination der Regeln der Form \(A \rightarrow B\) durch Ersetzen von \(A_i \rightarrow A_j\) fu&#x0308;r \(i = n - 1, \dotsc , 1\)
</p>
</li>
<li class="list-item-f3"><p>  Pseudoterminale einfu&#x0308;hren und Ersetzen aller Terminale in den Regeln
</p>
</li>
<li class="list-item-f4"><p>  Elimination der Regeln mit mehr als zwei Variablen auf der rechten Seite
</p>
</li>
</ul>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b><span class="textsc" >Greibach</span>-Normalform</b>:&#x2003; Eine Typ-2-Grammatik heißt in <em><span class="dashuline" ><span class="textsc" >Greibach</span>-Normalform</span></em>, falls alle
Regeln von der Form \(A \rightarrow a B_1 \dotsc B_k\) fu&#x0308;r \(k \ge 0\) sind (\(A, B_i\) Variablen und \(a\) Terminal).
</p>

<p>
<em>Bemerkung</em>: Mit der Zusatzbedingung \(k \le 1\) erha&#x0308;lt man genau die regula&#x0308;ren Grammatiken.<br />
(Man kann sogar jede kontextfreie Grammatik in Greibach-Normalform bringen, wobei \(k \le 2\).)
</p>

<p>
<span class="uline" ><em>Satz</em> (<span class="textsl" ><span class="textsc" >Greibach</span>-Normalform</span>):</span> Zu jeder kontextfreien Grammatik \(G\) mit \(\varepsilon \notin L(G)\) gibt es
eine kontextfreie Grammatik \(G’\) in Greibach-Normalform mit \(L(G) = L(G’)\).
</p>

<p>
<b>Beweis</b>: Ist \(A\) eine Variable, so werden im Folgenden alle Regeln der Form \(A \rightarrow w\) mit einer beliebigen Satzform \(w\) als <em><span class="dashuline" >\(A\)-Regeln</span></em> bezeichnet.
</p>

<p>
Mithilfe folgender Voru&#x0308;berlegung kann man alle <em><span class="dashuline" >linksrekursiven Regeln</span></em> entfernen:<br />
Fu&#x0308;r jede Variable \(A\) teilt man die \(A\)-Regeln in die linksrekursiven Regeln (d.&#x202f;h. \(A \rightarrow A\alpha \) mit beliebigen \(\alpha \)) und die u&#x0308;brigen Regeln (d.&#x202f;h. \(A
\rightarrow \beta \), wobei \(\beta \) nicht mit \(A\) beginnt) auf.<br />
Entsprechend dieser Aufteilung seien die \(A\)-Regeln \(A \rightarrow A\alpha _1 \;|\; \dotsb \;|\; A\alpha _k \;|\; \beta _1 \;|\; \dotsb \;|\; \beta _\ell \)<br />
(\(k \ge 0\), \(l \ge 1\)). Diese Regeln kann man ersetzen durch die Regeln<br />
\(A \rightarrow \beta _1 \;|\; \dotsb \;|\; \beta _\ell \),&#x2003;&#x2003;\(A \rightarrow \beta _1 B \;|\; \dotsb \;|\; \beta _\ell B\),&#x2003;&#x2003;\(B \rightarrow \alpha _1 \;|\; \dotsb
\;|\; \alpha _k\),&#x2003;&#x2003;\(B \rightarrow \alpha _1 B \;|\; \dotsb \;|\; \alpha _k B\).<br />
Dabei ist \(B\) eine neue Variable. Die erzeugte Sprache wird dadurch nicht vera&#x0308;ndert.<br />
Dann sind also keine linksrekursiven \(A\)-Regeln mehr vorhanden<br />
(\(\beta \) starten nicht mit \(A\) und \(\alpha \) starten nicht mit \(B\), da \(B\) eine neue Variable ist).
</p>

<p>
Ohne Einschra&#x0308;nkung kann man nach obigem Satz von einer kontextfreien Grammatik in<br />
Chomsky-Normalform ausgehen, wobei die Variablen durchnummeriert sind<br />
(\(V = \{A_1, \dotsc , A_m\}\)).
</p>

<p>
Der erste Algorithmus formt die Grammatik so um, dass Regeln der Form \(A_i \rightarrow A_j \beta \) nur mit \(i &lt; j\) vorkommen. Dabei mu&#x0308;ssen ggf. entsprechend der U&#x0308;berlegung wie eben neue
Variablen eingefu&#x0308;hrt werden, um Linksrekursion zu vermeiden.
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--



                                                                         for i := 1 to m do
                                                                               for j := 1 to i − 1 do
                                                                                     forall Ai → A j α ∈ P do
                                                                                           if A j → β1 | · · · | βn then streiche Ai → A j α, neu in P : Ai → β1 α | · · · | βn α
                                                                                     end
                                                                               end
                                                                               forall Ai → Ai α ∈ P : beseitige wie in Vorüberlegung
                                                                         end



-->


<p>

\begin{align*}
&amp;\FOR i := 1 \;\TO m \;\DO \\ &amp;\qquad \FOR j := 1 \;\TO i - 1 \;\DO \\ &amp;\qquad \qquad \FORALL A_i \rightarrow A_j \alpha \in P \;\DO \\ &amp;\qquad \qquad \qquad \IF A_j
\rightarrow \beta _1 \;|\; \dotsb \;|\; \beta _n \;\THEN \text {streiche }A_i \rightarrow A_j \alpha ,\; \text {neu in }P\text {: } A_i \rightarrow \beta _1 \alpha \;|\; \dotsb \;|\; \beta _n
\alpha \\ &amp;\qquad \qquad \END \\ &amp;\qquad \END \\ &amp;\qquad \FORALL A_i \rightarrow A_i \alpha \in P: \text {beseitige wie in Vorüberlegung}\\ &amp;\END
\end{align*}
Es werden also die Ableitungsmo&#x0308;glichkeiten \(A_i \Rightarrow A_j \alpha \Rightarrow \beta _k \alpha \) ersetzt durch \(A_i \Rightarrow \beta _k \alpha \).<br />
Nun gibt es zwei Sorten von Regeln: \(A_i \rightarrow A_j \beta \;|\; \alpha _k\) mit \(i &lt; j\) und \(B \rightarrow \beta _k \;|\; \beta _k B\), wobei die \(\alpha _k\) nicht mit einer Variable und die
\(\beta _k\) nicht mit \(B\) anfangen.
</p>

<p>
Der zweite Algorithmus erreicht, dass die rechten Seiten aller \(A_i\)-Regeln mit Terminalen beginnen. Bei den \(A_m\)-Regeln ist dies schon der Fall (Form \(A_m \rightarrow A_j \beta \;|\; \alpha _k\) mit \(j &gt; m\),
dies ist aber nicht mo&#x0308;glich, daher \(A_m \rightarrow \alpha _k\), wobei die \(\alpha _k\) nicht mit Variablen beginnen).<br />
Die \(A_{m-1}\)-Regeln beginnen entweder mit \(A_m\) oder mit Terminalzeichen. Durch Einsetzen der rechten Seiten aller \(A_m\)-Regeln erha&#x0308;lt man auch in allen \(A_{m-1}\)-Regeln rechte Seiten, die mit Terminalen
beginnen. So verfa&#x0308;hrt man induktiv mit \(A_{m-2}\) usw. bis zu \(A_1\).
</p>

<p>
Nun haben sind alle \(A_i\)-Regeln GNF-konform (die Grammatik war zu Beginn in CNF, d.&#x202f;h. es kommen nur Variablen nach dem beginnenden Terminal). Es gibt nun noch die \(B\)-Regeln, die bei der Entfernung der
linksrekursiven Regeln eingefu&#x0308;hrt wurden. Die rechten Seiten der \(B\)-Regeln beginnen entweder mit \(A_i\) oder mit Terminalen. Da die \(A_i\)-Regeln alle schon mit Terminalen beginnen, kann man einfach einsetzen
(analog zu eben). Die so entstandene Grammatik erzeugt die gleiche Sprache und ist in Greibach-Normalform. &#x2003;&#x2003;
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<em>Beispiel</em>: Gegeben sei die Grammatik in CNF \(A_1 \rightarrow A_1 A_2 \;|\; A_2 A_3 \;|\; a\),&#x2003;\(A_2 \rightarrow A_3 A_1\),&#x2003;\(A_3 \rightarrow b\).<br />
Beim ersten Algorithmus werden zuna&#x0308;chst Regeln der Form \(A_i \rightarrow A_j \beta \) mit \(j \le i\) entfernt. Es ist die linksrekursive Regel \(A_1 \rightarrow A_1 A_2\) vorhanden, die wie in der
Voru&#x0308;berlegung ersetzt wird, sodass die neuen Regeln \(A_1 \rightarrow A_2 A_3 \;|\; a \;|\; A_2 A_3 B \;|\; a B\),&#x2003;\(B \rightarrow A_2 \;|\; A_2 B\),<br />
\(A_2 \rightarrow A_3 A_1\),&#x2003;\(A_3 \rightarrow b\) sind. Fu&#x0308;r \(A_2\) und \(A_3\) ist nichts zu tun.<br />
Beim zweiten Algorithmus ersetzt man alle \(A_i\)-Regeln, sodass auf den rechten Seiten nur noch Terminale vorkommen, d.&#x202f;h. \(A_1 \rightarrow b A_1 A_3 \;|\; a \;|\; b A_1 A_3 B \;|\; a B\),&#x2003;\(B
\rightarrow A_2 \;|\; A_2 B\),<br />
\(A_2 \rightarrow b A_1\),&#x2003;\(A_3 \rightarrow b\). Nun macht man dasselbe fu&#x0308;r die \(B\)-Regeln:<br />
\(A_1 \rightarrow b A_1 A_3 \;|\; a \;|\; b A_1 A_3 B \;|\; a B\),&#x2003;&#x2003;\(A_2 \rightarrow b A_1\),&#x2003;&#x2003;\(A_3 \rightarrow b\),&#x2003;&#x2003;\(B \rightarrow b A_1 \;|\; b
A_1 B\).
</p>



<h2 id="das-pumping-lemma">Das Pumping-Lemma</h2>

</p>


<p>
<em>Bemerkung</em>: Man kann ein Analogon zum Pumping-Lemma fu&#x0308;r regula&#x0308;re Sprachen auch fu&#x0308;r kontextfreie Sprachen aufstellen. Um die beiden Lemmata zu unterscheiden, nennt man das
Pumping-Lemma fu&#x0308;r regula&#x0308;re Sprachen auch <em><span class="dashuline" >\(uvw\)-Theorem</span></em>, wa&#x0308;hrend man das Pumping-Lemma fu&#x0308;r kontextfreie Sprachen <em><span
class="dashuline" >\(uvwxy\)-Theorem</span></em> nennt.
</p>

<p>
<span class="uline" ><em>Satz</em> (<span class="textsl" >Pumping-Lemma</span>):</span> Sei \(L \subset \Sigma ^\ast \) eine kontextfreie Sprache.<br />
Dann gilt \(\exists _{n \in \natural } \forall _{z \in L,\; |z| \ge n} \exists _{u, v, w, x, y \in \Sigma ^\ast ,\; uvwxy = z}\; (1. \land 2. \land 3.)\) mit
</p>
<ul style="list-style-type:none">

<li class="list-item-f5"><p>\(|vx| \ge 1\)
</p>
</li>
<li class="list-item-f6"><p>\(|vwx| \le n\)
</p>
</li>
<li class="list-item-f7"><p>\(\forall _{i \in \natural _0}\; u v^i w x^i y \in L\)
</p>
</li>
</ul>

<p>
<b>Beweis</b>: Da die Sprache \(L\) kontextfrei ist, kann man von einer Grammatik \(G = (V, \Sigma , P, S)\) in Chomsky-Normalform ausgehen, wobei \(L = L(G)\).
</p>

<p>
Wa&#x0308;hle \(n = 2^{|V|}\) und sei \(z \in L\) mit \(|z| \ge n\) beliebig. Ein Ableitungsbaum von \(z\) hat folgende Form: Unter der Wurzel \(S\) befindet sich ein Bina&#x0308;rbaum (Regeln vom Typ \(A
\rightarrow BC\)). Fu&#x0308;r jedes Kind dieses Bina&#x0308;rbaums befindet sich unterhalb vom Bina&#x0308;rbaum noch ein weiterer Kindknoten des Ableitungsbaums (Regeln vom Typ \(A \rightarrow a\)). \(z\) kann
nun an diesen Kindern abgelesen werden, d.&#x202f;h. der Baum hat \(|z| \ge 2^{|V|}\) viele Kinder. Nach dem Lemma (siehe unten) hat der Ableitungsbaum also mindestens einen Pfad der La&#x0308;nge \(\ge |V|\).
</p>

<p>
Nun fixiert man einen la&#x0308;ngsten Pfad im Ableitungsbaum (dieser hat eine La&#x0308;nge \(\ge |V|\)). In diesem Pfad kommen daher \(&gt; |V|\) Variablen vor, es muss sich also mindestens eine Variable wiederholen.
Wa&#x0308;hle von unten kommend die erste wiederholte Variable, diese sei nun \(A\).<br />
Man teilt nun den Baum und \(z\) folgendermaßen ein: Der Teil unter dem (von unten) ersten Vorkommen von \(A\), der Teil unter dem (von unten) zweiten Vorkommen von \(A\) ohne den ersten Teil sowie der Teil unter \(S\)
(also der komplette Baum) ohne die ersten beiden Teile.
</p>

<p>
\(w\) sei das Wort gebildet aus den Kindern des ersten Teils, \(v\) und \(x\) die Wo&#x0308;rter gebildet aus den Kindern des zweiten Teils (durch den ersten Teil zerfallen die Kinder in zwei Abschnitte) sowie \(u\) und \(y\) die
Wo&#x0308;rter gebildet aus den Kindern des dritten Teils (durch die ersten beiden Teile zerfallen die Kinder in zwei Abschnitte).<br />
Dabei gilt \(|vx| \ge 1\) und \(|vwx| \le n\). Das Erste gilt, da die beiden \(A\)’s nicht identisch sind und das zweite \(A\) mindestens ein Kind hat, in dem sich das erste \(A\) nicht befindet (Regel \(A \rightarrow BC\) wird
angewendet). Dieses Kind erzeugt ein nicht-leeres Wort, also ist \(v\) oder \(x\) nicht-leer. Das Zweite gilt, weil der gro&#x0308;ßte Abstand des ersten Vorkommens von \(A\) zu den Bla&#x0308;ttern \(&lt; |V|\) ist. Es kann
also nach dem Lemma (siehe unten) ho&#x0308;chstens \(n = 2^{|V|}\) Bla&#x0308;tter unter diesem \(A\) geben.
</p>

<p>
Außerdem gilt anhand des Ableitungsbaums, dass \(S \Rightarrow ^\ast uAy\), \(A \Rightarrow ^\ast vAx\) und \(A \Rightarrow ^\ast w\).<br />
Daher kann man pumpen, d.&#x202f;h. \(S \Rightarrow ^\ast uAy \Rightarrow ^\ast uvAxy \Rightarrow ^\ast uv^2Ax^2y \Rightarrow ^\ast \dotsb \Rightarrow ^\ast uv^iAx^iy \Rightarrow ^\ast
uv^iwx^iy\) fu&#x0308;r \(i \in \natural _0\). Anschaulich „ha&#x0308;ngt“ man den Baum unter dem zweiten \(A\) (ohne den Baum unter dem ersten \(A\)) so oft wie gewu&#x0308;nscht untereinander, bis man mit dem
Baum unter dem ersten \(A\) terminiert. &#x2003;&#x2003;
</p>

<p>
<em>Bemerkung</em>: Fu&#x0308;r \(u = v = \varepsilon \) erha&#x0308;lt man das Pumping-Lemma fu&#x0308;r regula&#x0308;re Sprachen.
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<em>Bemerkung</em>: Fu&#x0308;r den Beweis wird das folgende Lemma genutzt.
</p>

<p>
<b>Bina&#x0308;rbaum</b>:&#x2003; Ein <em><span class="dashuline" >Bina&#x0308;rbaum</span></em> ist ein Baum, in dem jeder Knoten, der kein Blatt ist, genau zwei Nachfolger hat.
</p>

<p>
<em>Lemma</em> (<span class="textsl" >Pfade im Bina&#x0308;rbaum</span>): Ein Bina&#x0308;rbaum mit mindestens \(2^k\) Bla&#x0308;ttern hat mindestens einen Pfad der La&#x0308;nge \(\ge k\).
</p>

<p>
<b>Beweis</b>: Der Beweis erfolgt mittels vollsta&#x0308;ndiger Induktion u&#x0308;ber \(k \in \natural _0\).
</p>

<p>
Fu&#x0308;r \(k = 0\) ist die Behauptung trivial, denn dann hat der Baum mindestens einen Knoten und somit auch einen Pfad der La&#x0308;nge \(0\).
</p>

<p>
Fu&#x0308;r \(k \to k + 1\) betrachtet man den linken und den rechten Teilbaum der Wurzel des Baums mit mindestens \(2^{k+1}\) Bla&#x0308;ttern. Dann hat einer der beiden Teilba&#x0308;ume mindestens \(\frac
{2^{k+1}}{2} = 2^k\) Bla&#x0308;tter. Nach Induktionsvoraussetzung gibt es in diesem Teilbaum einen Pfad der La&#x0308;nge \(\ge k\). Dieser kann bis zur Wurzel vom „großen“ Baum verla&#x0308;ngert werden und liefert
einen Pfad der La&#x0308;nge \(\ge k + 1\). &#x2003;&#x2003;
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<em>Beispiel</em>: Die Sprache \(L = \{a^n b^n c^n \;|\; n \ge 1\}\) ist nicht kontextfrei. Andernfalls ga&#x0308;be es nach dem Pumping-Lemma ein \(n \in \natural \) mit obigen Eigenschaften. Wa&#x0308;hle \(z =
a^n b^n c^n \in L\), es gilt \(|z| = 3n \ge n\). Dann gibt es \(u, v, w, x, y \in \{a, b, c\}^\ast \) mit \(z = uvwxy\) und \(|vx| \ge 1\), \(|vwx| \le n\) und \(\forall _{i \in \natural _0}\; uv^iwx^iy
\in L\). Aufgrund \(|vwx| \le n\) kann \(vwx\) nicht \(a\)’s, \(b\)’s und \(c\)’s enthalten (also nicht alle drei Buchstaben auf einmal, sondern ho&#x0308;chstens zwei). Daher ist \(uwy \notin L\), denn \(|uwy|_a \not =
|uwy|_b\) oder \(|uwy|_b \not = |uwy|_c\), ein Widerspruch zur dritten Eigenschaft.
</p>

<p>
<em>Beispiel</em>: Die Sprache \(L = \{a^i b^j c^k \;|\; i &gt; j &gt; k,\; k &lt; i - 7\}\) ist nicht kontextfrei. Andernfalls ga&#x0308;be es nach dem Pumping-Lemma ein \(n \in \natural \) mit obigen
Eigenschaften.<br />
Wa&#x0308;hle \(z = a^{n+9} b^{n+8} c^{n+1} \in L\), es gilt \(|z| = 3n + 18 \ge n\). Dann gibt es \(u, v, w, x, y \in \{a, b, c\}^\ast \) mit \(z = uvwxy\) und \(|vx| \ge 1\), \(|vwx| \le n\) und \(\forall
_{i \in \natural _0}\; uv^iwx^iy \in L\). Es gibt nun drei Fa&#x0308;lle:
</p>
<ul style="list-style-type:none">

<li class="list-item-f8"><p>\(vwx\) entha&#x0308;lt \(a\)’s. Dann entha&#x0308;lt \(vwx\) keine \(c\)’s (wegen der zweiten Eigenschaft) und es gilt \(uwy \notin L\), falls \(v\) oder \(x\) \(a\)’s enthalten (dann ist \(|uwy|_c =
|uvwxy|_c = n + 1\), aber \(n + 1 \not &lt; |uwy|_a - 7 &lt; |uvwxy|_a - 7 = n + 2\)).<br />
Falls \(v\) und \(x\) keine \(a\)’s enthalten, so ist \(vwx = a^r b^s\) mit \(v = \varepsilon \), \(w = a^r b^{s_1}\) und \(x = b^{s - s_1}\). Dann muss \(u = a^t\) sowie \(y = b^{s_2} c^{n+1}\) gelten, wobei \(t + r
= n + 9\) und \(s + s_2 = n + 8\).<br />
In diesem Fall ist \(uv^2 wx^2 y = a^{t+r} b^{s_1 + 2(s - s_1) + s_2} c^{n+1} \notin L\), da<br />
\(|uv^2 wx^2 y|_b = s_1 + 2(s - s_1) + s_2 = 2s - s_1 + s_2 = n + 8 + s - s_1 \not &lt; n + 9 = |uv^2 wx^2 y|_a\).
</p>
</li>
<li class="list-item-f9"><p>\(vwx\) entha&#x0308;lt \(c\)’s. Dann entha&#x0308;lt \(vwx\) keine \(a\)’s und es gilt \(uv^9 wx^9 y \notin L\), denn es \(v\) oder \(x\) entha&#x0308;lt ein \(b\) oder ein \(c\). Weil aber keine \(a\)’s
enthalten sind, gilt \(|uv^9 wx^9 y|_a = |uvwxy|_a = n + 9\), aber \(|uv^9 wx^9 y|_b \ge |uvwxy|_b + 8 = n + 16\) oder \(|uv^9 wx^9 y|_c \ge |uvwxy|_c + 8 = n + 9\).
</p>
</li>
<li class="list-item-f10"><p>\(vwx\) entha&#x0308;lt weder \(a\)’s noch \(c\)’s. Dann besteht \(vwx\) nur aus \(b\)’s und es gilt \(uv^2 wx^2 y \notin L\), denn \(|uv^2 wx^2 y|_a = |uvwxy|_a = n + 9\), aber \(|uv^2 wx^2 y|_b &gt;
|uvwxy|_b = n + 8\).
</p>
</li>
</ul>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<em>Beispiel</em>: Dass \(L = \{a^p \;|\; p \text { prim}\}\) nicht kontextfrei ist, kann man wie beim Beweis fu&#x0308;r die Nicht-Regularita&#x0308;t zeigen (siehe oben). Das ist kein Zufall, sondern bei allen Sprachen
u&#x0308;ber einelementigen Alphabeten der Fall: Sei \(L\) kontextfrei und \(z \in L\) mit \(|z| \ge n\). Dann gibt eine Zerlegung \(z = uvwxy\). Aufgrund des einelementigen Alphabets ist \(z = wvxyu = u’v’w’\) mit \(u’
= w\), \(v’ = vx\) und \(w’ = yu\). Es gilt \(|vx| = |v’| \ge 1\), \(|vwx| = |u’v’| \le n\) sowie<br />
\(uv^i wx^i y = u’ (v’)^i w’ \in L\), d.&#x202f;h. man erha&#x0308;lt die gleiche Aussage wie beim \(uvw\)-Theorem. Der folgende Satz fu&#x0308;hrt das genauer aus.
</p>

<p>
<span class="uline" ><em>Satz</em> (<span class="textsl" >kontextfreie Sprachen u&#x0308;ber einelementige Alphabete sind regula&#x0308;r</span>):</span><br />
Sei \(L \subset \Sigma ^\ast \) eine kontextfreie Sprache mit \(|\Sigma | = 1\). Dann ist \(L\) regula&#x0308;r.
</p>

<p>
<b>Beweis</b>: Sei \(L \subset a^\ast \) eine kontextfreie Sprache. Nach dem Pumping-Lemma fu&#x0308;r kontextfreie Sprachen gibt es fu&#x0308;r alle \(z \in L\) mit \(|z| \ge n\) eine Zerlegung \(z = uvwxy =
a^{k_1} a^{\ell _1} a^{k_2} a^{\ell _2} a^{k_3} = a^k a^\ell \) mit \(k = k_1 + k_2 + k_3\) und \(\ell = \ell _1 + \ell _2\). Dabei gilt \(\ell &gt; 0\) und \(a^{k + i\ell } \in L\) fu&#x0308;r alle \(i
\in \natural _0\).
</p>

<p>
Man erha&#x0308;lt also fu&#x0308;r jedes \(z \in L\) mit \(|z| \ge n\) eine Zahl \(\ell \in \{1, \dotsc , n\}\), die <em><span class="dashuline" >Periode</span></em> von \(z\) genannt wird (die Periode von
\(z\) ist evtl. nicht eindeutig).
</p>

<p>
Sei \(q := n!\), dann gilt \(\ell \;|\; q\) fu&#x0308;r alle Perioden \(\ell \). Fu&#x0308;r eine beliebige Zahl \(q’ &gt; q\) wird die Sprache \(L’ := \{x \in L \;|\; |x| &lt; q\} \cup \{a^{r + iq} \;|\; q \le
r \le q’,\; a^r \in L,\; i \in \natural _0\}\) definiert.<br />
\(L’\) ist fu&#x0308;r alle \(q’ &gt; q\) regula&#x0308;r, denn die erste Menge ist endlich und somit regula&#x0308;r. Die zweite Menge ist regula&#x0308;r, da \(\{a^{r + iq} \;|\; i \in \natural _0\}\) fu&#x0308;r
festes \(r, q\) regula&#x0308;r ist (z.&#x202f;B. mit einem entsprechenden DEA) und die zweite Menge eine endliche Vereinigung solcher Mengen ist.<br />
Außerdem gilt \(L’ \subset L\), denn die erste Menge ist eine Teilmenge von \(L\) und bei der zweiten Menge ist \(a^{r + iq} \in L\) fu&#x0308;r \(a^r \in L\), \(r \ge q\) und \(i \ge 0\), da \(a^r\) die Periode \(\ell
\) hat und diese \(q\) teilt.<br />
Falls \(q’\) so gefunden kann, dass \(L \subset L’\) gilt, so gilt \(L = L’\) und der Beweis ist abgeschlossen, da \(L’\) regula&#x0308;r ist.
</p>

<p>
Wa&#x0308;hle zuna&#x0308;chst \(q’ = q + 1\). Falls \(L’ = L\), so ist man fertig.<br />
Falls \(L’ \subsetneqq L\), so wa&#x0308;hle ein ku&#x0308;rzestes Wort \(a^s \in L \setminus L’\). Wird \(q’ &gt; s\) gewa&#x0308;hlt, so ist \(a^{s + iq} \in L’\) fu&#x0308;r \(i \in \natural _0\) (ist in der
zweiten Menge). Somit sind alle \(a^m\) mit \(m \ge s\) und \(m \equiv s \mod q\) in \(L’\).<br />
Dieser Vorgang wird nun iteriert. Es gibt allerdings ho&#x0308;chstens \(q - 1\) Restklassen, sodass die Iteration in endlich vielen Schritten endet. &#x2003;&#x2003;
</p>



<h2 id="abschlusseigenschaften">Abschlusseigenschaften</h2>

</p>


<p>
<span class="uline" ><em>Satz</em> (<span class="textsl" >Abschlusseigenschaften der kontextfreien Sprachen</span>):</span> Die Klasse der kontextfreien Sprachen ist abgeschlossen unter Vereinigung, Produkt und
Stern.
</p>

<p>
<b>Beweis</b>: Abschluss unter Vereinigung: Seien \(L_1 = L(G_1)\) und \(L_2 = L(G_2)\) kontextfreie Sprachen mit \(G_1 = (V_1, \Sigma , P_1, S_1)\) und \(G_2 = (V_2, \Sigma , P_2, S_2)\), wobei \(V_1 \cap
V_2 = \emptyset \) und \(S \notin V_1 \cup V_2\). Dann gilt \(L(G) = L_1 \cup L_2\) mit der kontextfreien Grammatik<br />
\(G = (V_1 \cup V_2 \cup \{S\}, \Sigma , P_1 \cup P_2 \cup \{S \rightarrow S_1 | S_2\}, S)\).<br />
Fu&#x0308;r „\(\supset \)“ nimmt man z.&#x202f;B. ein Wort \(w \in L_1\). Dann ist \(S_1 \Rightarrow _{G_1}^\ast w\) und es gilt \(S \Rightarrow _G S_1 \Rightarrow _G^\ast w\), da \(P_1\) eine Teilmenge der
Regelmenge von \(G\) ist.<br />
Fu&#x0308;r „\(\subset \)“ sei \(w \in L(G)\), also \(S \Rightarrow _G w\). Da \(S\) in keiner anderen Regel außer \(S \rightarrow S_1 | S_2\) vorkommt, muss z.&#x202f;B. \(S \Rightarrow _G S_1 \Rightarrow _G
w\) gelten. Dann gilt allerdings auch \(S_1 \Rightarrow _{G_1}^\ast w\), denn \(S_1\) kann nur nach Variablen in \(V_1\) abgeleitet werden, diese Variablen ko&#x0308;nnen auch nur nach Variablen in \(V_1\) abgeleitet
werden usw. Daraus folgt dann \(w \in L_1\).
</p>

<p>
Abschluss unter Produkt: Seien \(G_1\) und \(G_2\) wie eben. Dann gilt \(L(G) = L_1 L_2\) mit der kontextfreien Grammatik \(G = (V_1 \cup V_2 \cup \{S\}, \Sigma , P_1 \cup P_2 \cup \{S \rightarrow S_1 S_2\},
S)\). Der Beweis la&#x0308;sst sich analog durchfu&#x0308;hren.
</p>

<p>
Abschluss unter Stern: Sei \(L_1 = L(G_1)\) eine kontextfreie Sprache mit \(G_1 = (V_1, \Sigma , P_1, S_1)\), wobei \(S \notin V_1\) und \(S_1\) oBdA auf keiner rechten Seite vorkommt. Dann gilt \(L(G) = (L_1)^\ast
\) mit der kontextfreien Grammatik \(G = (V_1 \cup \{S\}, \Sigma , P, S)\) mit<br />
\(P = (P_1 \setminus \{S_1 \rightarrow \varepsilon \}) \cup \{S \rightarrow \varepsilon | S_1\} \cup \{S_1 \rightarrow S_1 S_1\}\).<br />
Fu&#x0308;r „\(\supset \)“ sei \(w \in (L_1)^\ast \), d.&#x202f;h. \(w = w_1 \dotsb w_n\) mit \(n \in \natural _0\) und \(w_i \in L_1\). Ist \(n = 0\), so gilt \(S \Rightarrow _G \varepsilon = w\).<br />
Ist \(n \ge 1\), so gilt \(S \Rightarrow _G S_1 \Rightarrow _G S_1 S_1 \Rightarrow _G S_1 S_1 S_1 \Rightarrow _G \dotsb \Rightarrow _G (S_1)^n \Rightarrow _G^\ast w_1 \dotsb w_n = w\).<br />
Fu&#x0308;r „\(\subset \)“ ist \(w \in L(G)\), d.&#x202f;h. \(S \Rightarrow _G^\ast w\). Der Fall \(w = \varepsilon \) ist trivial. Da \(S_1\) auf keiner rechten Seite in \(P_1\) vorkommt, kann man oBdA \(S
\Rightarrow _G S_1 \Rightarrow _G S_1 S_1 \Rightarrow _G S_1 S_1 S_1 \Rightarrow _G \dotsb \Rightarrow _G (S_1)^n \Rightarrow _G^\ast w\) schreiben, indem man die Anwendungen der Regel \(S_1
\rightarrow S_1 S_1\) zuerst vornimmt (die Anzahl dieser Anwendungen sei \(n\)). Es gilt \(S_1 \Rightarrow _{G_1} w_i\) fu&#x0308;r \(i = 1, \dotsc , n\) und \(w = w_1 \dotsb w_n\). Somit gilt \(w \in
(L_1)^\ast \), da \(w_i \in L_1\) fu&#x0308;r \(i = 1, \dotsc , n\). &#x2003;&#x2003;
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<span class="uline" ><em>Satz</em> (<span class="textsl" >negative Abschlusseigenschaften der kontextfreien Sprachen</span>):</span> Die Klasse der kontextfreien Sprachen ist nicht abgeschlossen unter Schnitt und
Komplement.
</p>

<p>
<b>Beweis</b>: Nicht-Abgeschlossenheit unter Schnitt: Die Sprachen \(L_1 = \{a^i b^j c^j \;|\; i, j \in \natural \}\) und \(L_2 = \{a^i b^i c^j \;|\; i, j \in \natural \}\) sind kontextfrei, wie man leicht
pru&#x0308;fen kann (z.&#x202f;B. fu&#x0308;r \(L_1\) die Grammatik \(S \rightarrow AB\), \(A \rightarrow Aa \;|\; a\), \(B \rightarrow bBc \;|\; bc\)). Der Schnitt ist die Sprache \(L = \{a^i b^i c^i \;|\;
i \in \natural \}\). Weiter oben wurde gezeigt, dass \(L\) nicht kontextfrei ist.
</p>

<p>
Nicht-Abgeschlossenheit unter Komplement: Angenommen, die Klasse der kontextfreien Sprachen wa&#x0308;re abgeschlossen unter Komplement. Seien \(L_1\) und \(L_2\) kontextfreie Sprachen. Dann ist \(L_1 \cap L_2 =
\Sigma ^\ast \setminus ((\Sigma ^\ast \setminus L_1) \cup (\Sigma ^\ast \setminus L_2))\). Damit wa&#x0308;re dann auch Abgeschlossenheit unter Schnitt vorhanden, ein Widerspruch. &#x2003;&#x2003;
</p>



<h2 id="der-cyk-algorithmus">Der CYK-Algorithmus</h2>

</p>


<p>
<em>Bemerkung</em>: Das Wortproblem ist fu&#x0308;r Typ-1-Sprachen entscheidbar, d.&#x202f;h. es gibt einen Algorithmus, der zu jedem gegebenen Wort \(w \in \Sigma ^\ast \) und einer Typ-1-Grammatik \(G\) in
endlicher Zeit entscheidet, ob \(w \in L(G)\). Der zugeho&#x0308;rige Algorithmus hat allerdings exponentielle Zeitkomplexita&#x0308;t.<br />
Fu&#x0308;r den Spezialfall der Typ-2-Sprachen existiert ein optimierter Algorithmus zur Lo&#x0308;sung des Wortproblems, der ho&#x0308;chstens kubische Zeitkomplexita&#x0308;t besitzt, allerdings die Grammatik in
Chomsky-Normalform voraussetzt.<br />
Der Algorithmus nennt sich <em><span class="dashuline" >CYK-Algorithmus</span></em> (<span class="textsc" >Cocke</span>-<span class="textsc" >Younger</span>-<span class="textsc" >Kasami</span>).
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<em>Bemerkung</em>: Sei also eine CNF-Grammatik \(G\) und ein Wort \(w \in \Sigma ^\ast \) gegeben. Zur Entscheidung der Frage, ob \(w \in L(G)\) gilt, werden die Fa&#x0308;lle \(|w| = 1\) und \(|w| &gt; 1\)
unterschieden.<br />
Fu&#x0308;r \(|w| = 1\) ist \(w \in \Sigma \), also schaut man, ob eine Regel \(S \rightarrow w\) in der Regelmenge \(P\) existiert.<br />
Fu&#x0308;r \(|w| &gt; 1\) (unter der Annahme, dass \(w \in L(G)\)) gilt \(S \Rightarrow _G AB\) mit \(A \Rightarrow _G^\ast x\), \(B \Rightarrow _G^\ast y\) und \(w = xy\), wobei \(|x|, |y| \ge 1\). Diesen
Vorgang kann man fu&#x0308;r \(x\) und \(y\) wiederholen usw. Bei Wo&#x0308;rtern \(x\) der La&#x0308;nge \(|x| = 1\) gilt \(A \Rightarrow ^\ast x\) genau dann, wenn \(A \rightarrow x \in P\).
</p>

<p>
Allgemein definiert man fu&#x0308;r ein Wort \(w = w_1 \dotsb w_n \in \Sigma ^\ast \) Mengen \(T_{i,j} \subset V\) mit \(A \in T_{i,j}\) genau dann, wenn \(A \Rightarrow _G^\ast w_i \dotsb w_{i+j-1}\)
mit \(j \in \{1, \dotsc , n\}\) und \(i \in \{1, \dotsc , n + 1 - j\}\).<br />
Diese Mengen werden induktiv berechnet (mit steigendem \(j\)). Am Ende entscheidet, ob \(S \in T_{1,n}\). Dies ist der Fall genau dann, wenn \(w \in L(G)\).<br />
Wie berechnet man die Mengen \(T_{i,j}\)? Fu&#x0308;r \(j = 1\) ist \(T_{i,1} = \{A \in V \;|\; A \rightarrow w_i \in P\}\). Fu&#x0308;r \(j = 2\) ist \(T_{i,2} = \{A \in V \;|\; \exists _{B, C \in V}\;
A \rightarrow BC \in P,\; B \rightarrow w_i \in P,\; C \rightarrow w_{i+1} \in P\}\). Das kann auch umgeschrieben werden zu \(T_{i,2} = \{A \in V \;|\; \exists _{B \in T_{i,1},\; C \in
T_{i+1,1}}\; A \rightarrow BC \in P\}\) usw.<br />
Allgemein gilt fu&#x0308;r \(j \ge 2\), dass \(T_{i,j} = \{A \in V \;|\; \exists _{k \in \{1, \dotsc , j - 1\}} \exists _{B \in T_{i,k},\; C \in T_{i+k,j-k}}\; A \rightarrow BC \in P\}\).
</p>

<p>
Fu&#x0308;r \(j \ge 2\) kann man dies auch als Vereinigung<br />
\(T_{i,j} = \bigcup _{k=1}^{j-1} \{A \in V \;|\; \exists _{B \in T_{i,k},\; C \in T_{i+k,j-k}}\; A \rightarrow BC \in P\}\) schreiben. Man berechnet die \(T_{i,j}\) zuerst fu&#x0308;r \(j = 1\), dann
fu&#x0308;r \(j = 2\) usw. Um \(T_{i,j}\) zu bestimmen, kann man ausnutzen, dass \(T_{r,s}\) fu&#x0308;r \(s &lt; j\) und beliebige \(r\) schon bekannt ist. Da andere Mengen in der Vereinigung \(T_{i,j}\) nicht
vorkommen, kann man so alle \(T_{i,j}\) algorithmisch bestimmen. Genauer organisiert man die Mengen in einer Tabelle:
</p>

<p>
\[\begin {array}{r|c|c|ccc|c} &amp; w_1 &amp; w_2 &amp; w_3 &amp; \cdots &amp; w_{n-1} &amp; w_n \\\hline \text {Länge } 1 &amp; T_{1,1} &amp; T_{2,1} &amp; T_{3,1} &amp; \cdots &amp;
T_{n-1,1} &amp; T_{n,1} \\\hline \text {Länge } 2 &amp; T_{1,2} &amp; T_{2,2} &amp; T_{3,2} &amp; \cdots &amp; T_{n-1,2} &amp; - \\\hline \vdots \\\hline \text {Länge } n - 1 &amp;
T_{1,n-1} &amp; T_{2,n-1} &amp; - &amp; \cdots &amp; - &amp; - \\\hline \text {Länge } n &amp; T_{1,n} &amp; - &amp; - &amp; \cdots &amp; - &amp; - \end {array}\]
</p>

<p>
Dann ist \(w \in L(G)\) a&#x0308;quivalent zu \(S \in T_{1,n}\).
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<span class="uline" ><em>Satz</em> (<span class="textsl" >CYK-Algorithmus</span>):</span> Sei \(G\) eine kontextfreie Grammatik in Chomsky-Normalform. Dann ermittelt folgender Algorithmus fu&#x0308;r alle \(w =
w_1 \dotsb w_n \in \Sigma ^\ast \), dass \(w \in L(G)\) (Wortproblem):
</p>
<span class="hidden" > \(\seteqnumber{0}{}{0}\)</span>


<!--



                                                                                 for i := 1 to n do
                                                                                       T [i, 1] := {A ∈ V | A → w i ∈ P};
                                                                                 end
                                                                                 for j := 2 to n do
                                                                                       for i := 1 to n + 1 − j do
                                                                                             T [i, j] := ;;
                                                                                             for k := 1 to j − 1 do
                                                                                                   T [i, j] := T [i, j] ∪ {A ∈ V | ∃B∈T [i,k], C∈T [i+k, j−k] A → BC ∈ P};
                                                                                             end
                                                                                       end
                                                                                 end
                                                                                 if S ∈ T [1, n] then output(1) else output(0);



-->


<p>

\begin{align*}
&amp;\FOR i := 1 \;\TO n \;\DO \\ &amp;\qquad T[i, 1] := \{A \in V \;|\; A \rightarrow w_i \in P\};\\ &amp;\END \\ &amp;\FOR j := 2 \;\TO n \;\DO \\ &amp;\qquad \FOR i := 1 \;\TO n + 1 - j
\;\DO \\ &amp;\qquad \qquad T[i, j] := \emptyset ;\\ &amp;\qquad \qquad \FOR k := 1 \;\TO j - 1 \;\DO \\ &amp;\qquad \qquad \qquad T[i, j] := T[i, j] \cup \{A \in V \;|\; \exists _{B \in T[i,
k],\; C \in T[i + k, j - k]}\; A \rightarrow BC \in P\};\\ &amp;\qquad \qquad \END \\ &amp;\qquad \END \\ &amp;\END \\ &amp;\IF S \in T[1, n] \;\THEN \text {output}(1) \;\ELSE \text
{output}(0);
\end{align*}
Der Algorithmus hat die bestmo&#x0308;gliche Zeitkomplexita&#x0308;t \(\O (n^3)\).
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<em>Beispiel</em>: Sei die CNF-Grammatik \(G = (\{S, A, B, X, Y\}, \{a, b\}, P, S)\) gegeben mit<br />
\(P = \{S \rightarrow AX \;|\; YB, A \rightarrow XA \;|\; AB \;|\; a, B \rightarrow XY \;|\; BB, X \rightarrow YA \;|\; a, Y \rightarrow XX \;|\; b\}\).<br />
Gilt \(w = aabbaba \in L(G)\)? Der Algorithmus erzeugt folgende Tabelle:
</p>

<p>
\[\begin {array}{r|c|c|c|c|c|c|c} \text {Länge} &amp; a &amp; a &amp; b &amp; b &amp; a &amp; b &amp; a \\\hline 1 &amp; AX &amp; AX &amp; Y &amp; Y &amp; AX &amp; Y &amp; AX \\\hline 2
&amp; SAY &amp; B &amp; \emptyset &amp; X &amp; B &amp; X &amp; - \\\hline 3 &amp; A &amp; \emptyset &amp; \emptyset &amp; SB &amp; SY &amp; - &amp; - \\\hline 4 &amp; \emptyset &amp;
\emptyset &amp; S &amp; Y &amp; - &amp; - &amp; - \\\hline 5 &amp; S &amp; B &amp; \emptyset &amp; - &amp; - &amp; - &amp; - \\\hline 6 &amp; A &amp; \emptyset &amp; - &amp; - &amp; - &amp; -
&amp; - \\\hline 7 &amp; S &amp; - &amp; - &amp; - &amp; - &amp; - &amp; - \end {array}\]
</p>

<p>
(Dabei bedeutet \(V_1 \dotsb V_n\) die Menge \(\{V_1, \dotsc , V_n\} \subset V\).) Also gilt \(w \in L(G)\).
</p>



<h2 id="kellerautomaten">Kellerautomaten</h2>

</p>


<p>
<em>Bemerkung</em>: Das Modell des nicht-deterministischen endlichen Automaten (NEA) soll so erweitert werden, dass auch kontextfreie Sprachen erkannt werden. Dazu muss ein Speicher eingefu&#x0308;hrt werden,
z.&#x202f;B. bei der Sprache \(\{a^n b^n \;|\; n \in \natural \}\) muss \(n\) gespeichert werden, bei \(\{a_1 \dotsb a_n \dollar a_n \dotsb a_1 \;|\; n \in \natural \}\) muss \(a_1 \dotsb a_n\) gespeichert
werden usw.
</p>

<p>
<em>Bemerkung</em>: Einen Kellerautomat stellt man sich als Maschine vor, die aus Eingabeband, Lesekopf, Zustandskontrolle, Keller und Schreib-/Lesekopf fu&#x0308;r den Keller besteht. In jedem Schritt kann die
Zustandskontrolle ho&#x0308;chstens ein Zeichen lesen, der Lesekopf bewegt sich dabei unwiderruflich nach vorne. Gleichzeitig ist das letzte dem Keller hinzugefu&#x0308;gte Element sichtbar, bei Bedarf kann mehr Information
auf dem Keller gespeichert oder auch bestehende Information des Kellers gelo&#x0308;scht werden. Der Keller ist dabei ein Pushdown-Stack, d.&#x202f;h. die Informationen sind nach ihrem Ablegen absteigend sortiert.
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b>nicht-deterministischer Kellerautomat (PDA)</b>:&#x2003;<br />
Ein <em><span class="dashuline" >nicht-deterministischer Kellerautomat</span></em> oder <em><span class="dashuline" >PDA (pushdown automaton)</span></em> ist ein \(6\)-Tupel \(M = (Z, \Sigma , \Gamma ,
\delta , z_0, \#)\), wobei
</p>
<ul style="list-style-type:none">

<li class="list-item-f11"><p>\(Z\) eine endliche, nicht-leere Menge (die Menge der <em><span class="dashuline" >Zusta&#x0308;nde</span></em>),
</p>
</li>
<li class="list-item-f12"><p>\(\Sigma \) eine endliche, nicht-leere Menge mit \(Z \cap \Sigma = \emptyset \) (das <em><span class="dashuline" >Eingabealphabet</span></em>),
</p>
</li>
<li class="list-item-f13"><p>\(\Gamma \) eine endliche, nicht-leere Menge mit \(Z \cap \Gamma = \emptyset \) (das <em><span class="dashuline" >Kelleralphabet</span></em>),
</p>
</li>
<li class="list-item-f14"><p>\(\delta \colon Z \times (\Sigma \cup \{\varepsilon \}) \times \Gamma \rightarrow \P _E(Z \times \Gamma ^\ast )\) (die <em><span class="dashuline"
>U&#x0308;berfu&#x0308;hrungsfunktion</span></em>),
</p>
</li>
<li class="list-item-f15"><p>\(z_0 \in Z\) (der <em><span class="dashuline" >Startzustand</span></em>) und
</p>
</li>
<li class="list-item-f16"><p>\(\# \in \Gamma \) (das <em><span class="dashuline" >unterste Kellersymbol</span></em>) ist.
</p>
</li>
</ul>

<p>
Dabei ist \(\P _E(A) := \{B \subset A \;|\; B \text { endlich}\}\).
</p>
<p>
<em>Bemerkung</em>: Es gibt zwei Arten von U&#x0308;berga&#x0308;ngen:<br />
Bei <em><span class="dashuline" >normalen U&#x0308;berga&#x0308;ngen</span></em> \((q, B_1 \dotsb B_k) \in \delta (p, a, A)\) wird der Buchstabe \(a\) vom Eingabeband gelesen und der Lesekopf um eins
weitergeru&#x0308;ckt. Gleichzeitig wird der oberste Kellerbuchstabe \(A\) vom Keller gelo&#x0308;scht und durch \(B_1 \dotsb B_k\) mit \(k \in \natural _0\) ersetzt.<br />
Bei <em><span class="dashuline" >\(\varepsilon \)-U&#x0308;berga&#x0308;ngen</span></em> \((q, B_1 \dotsb B_k) \in \delta (p, \varepsilon , A)\) la&#x0308;uft alles analog, außer dass kein
Eingabebuchstabe gelesen wird (d.&#x202f;h. die Position des Lesekopfs bleibt unvera&#x0308;ndert).
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b>Konfiguration</b>:&#x2003;<br />
Eine <em><span class="dashuline" >Konfiguration</span></em> \(k\) des PDA \(M = (Z, \Sigma , \Gamma , \delta , z_0, \#)\) ist ein Element \(k \in Z \times \Sigma ^\ast \times \Gamma ^\ast \).
</p>

<p>
<b>U&#x0308;bergangsrelation</b>:&#x2003; Auf der Menge \(Z \times \Sigma ^\ast \times \Gamma ^\ast \) wird eine Relation \(\vdash \) definiert durch<br />
\((z, a_1 a_2 \dotsb a_n, A_1 A_2 \dotsb A_m) \vdash (z’, a_2 \dotsb a_n, B_1 \dotsb B_k A_2 \dotsb A_m)\) fu&#x0308;r \((z’, B_1 \dotsb B_k) \in \delta (z, a_1, A_1)\) bzw. \((z, a_1 \dotsb a_n,
A_1 A_2 \dotsb A_m) \vdash (z’, a_1 \dotsb a_n, B_1 \dotsb B_k A_2 \dotsb A_m)\) fu&#x0308;r \((z’, B_1 \dotsb B_k) \in \delta (z, \varepsilon , A_1)\) mit \(n \in \natural \) bzw. \(n \in \natural
_0\), \(m \in \natural \) und \(k \in \natural _0\) (<em><span class="dashuline" >U&#x0308;bergangsrelation</span></em>).<br />
\(\vdash ^\ast \) ist der reflexive und transitive Abschluss von \(\vdash \).
</p>

<p>
<b>akzeptierte Sprache</b>:&#x2003; Die von einem PDA \(M = (Z, \Sigma , \Gamma , \delta , z_0, \#)\) <em><span class="dashuline" >akzeptierte Sprache</span></em> ist \(N(M) := \{x \in \Sigma ^\ast
\;|\; \exists _{z \in Z}\; (z_0, x, \#) \vdash ^\ast (z, \varepsilon , \varepsilon )\}\).
</p>

<p>
<em>Bemerkung</em>: Diese Version der Definition heißt akzeptierte Sprache durch leeren Keller, es gibt auch Akzeptierung durch Endzustand. Wenn der Keller leer ist, endet die Berechnung in jedem Fall, denn fu&#x0308;r leeres
Eingabeband ist die Berechnung erfolgreich, andernfalls ist sie nicht erfolgreich (fu&#x0308;r jeden U&#x0308;bergang wird ein Kellerzeichen beno&#x0308;tigt).
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<em>Beispiel</em>: Gesucht wird ein PDA fu&#x0308;r <em><span class="dashuline" >markierte Palindrome</span></em>, d.&#x202f;h. fu&#x0308;r<br />
\(L = \{a_1 \dotsb a_n \dollar a_n \dotsb a_1 \;|\; n \in \natural \}\). Man definiert \(M = (\{z_0, z_1\}, \{a, b, \dollar \}, \{\#, A, B\}, \delta , z_0, \#)\) und die Kurzschreibweise \(zaA
\rightarrow z’x\) fu&#x0308;r \((z’, x) \in \delta (z, a, A)\). Dann setzt man<br />
\(z_0 a \# \rightarrow z_0 A \#\), \(z_0 a A \rightarrow z_0 A A\), \(z_0 a B \rightarrow z_0 A B\) und analog<br />
\(z_0 b \# \rightarrow z_0 B \#\), \(z_0 b A \rightarrow z_0 B A\), \(z_0 b B \rightarrow z_0 B B\). Außerdem ist<br />
\(z_0 \dollar \# \rightarrow z_1 \#\), \(z_0 \dollar A \rightarrow z_1 A\), \(z_0 \dollar B \rightarrow z_1 B\) sowie \(z_1 a A \rightarrow z_1 \varepsilon \), \(z_1 b B \rightarrow z_1 \varepsilon
\), \(z_1 \varepsilon \# \rightarrow z_1 \varepsilon \).<br />
Um zu zeigen, dass \(N(M) = L\) gilt, zeigt man zuna&#x0308;chst \(w \dollar w^R \in N(M)\) fu&#x0308;r alle \(w \in \{a, b\}^\ast \), d.&#x202f;h. \((z_0, w \dollar w^R, \#) \vdash ^\ast (z_i, \varepsilon
, \varepsilon )\) fu&#x0308;r ein \(i \in \{0, 1\}\) (dabei ist \(w^R := w_n \dotsb w_1\) fu&#x0308;r \(w = w_1 \dotsb w_n\)).<br />
Ein mo&#x0308;glicher Zwischenschritt ist dabei die sta&#x0308;rkere Behauptung<br />
\(\forall _{w \in \{a, b\}^+}\; (z_0, w \dollar w^R, \#) \vdash ^\ast (z_0, \dollar w^R, \widehat {w}^R \#) \vdash (z_1, w^R, \widehat {w}^R \#) \vdash ^\ast (z_1, \varepsilon , \varepsilon
)\) mit \(\widehat {w} = \widehat {w}_1 \dotsb \widehat {w}_n\) und \(\widehat {a} = A\), \(\widehat {b} = B\) fu&#x0308;r \(w = w_1 \dotsb w_n\). Die erste Relation \(\vdash ^\ast \) la&#x0308;sst sich
durch Induktion zeigen (\((z_0, v \dollar w^R, y) \vdash ^\ast (z_0, \dollar w^R, \widehat {v}^R y)\) fu&#x0308;r \(v \in \{a, b\}^\ast \) beliebig). Analog zeigt man die andere Richtung<br />
\(\forall _{x \in \{a, b\}^\ast }\; (\exists _{i \in \{0, 1\}}\; (z_0, x, \#) \vdash ^\ast (z_i, \varepsilon , \varepsilon )) \;\Rightarrow \; (\exists _{w \in \{a, b\}^\ast }\; x = w \dollar
w^R)\) (zuna&#x0308;chst stellt man fest, dass nur \(i = 1\) mo&#x0308;glich ist, da von \(z_0\) aus \(\#\) nicht entfernt wird, danach verfa&#x0308;hrt man a&#x0308;hnlich wie eben).
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<span class="uline" ><em>Satz</em> (<span class="textsl" >PDA charakterisieren die kontextfreien Sprachen</span>):</span><br />
Eine Sprache \(L\) ist genau dann kontextfrei, wenn sie von einem PDA erkannt wird.
</p>

<p>
<b>Beweis</b>: Zuna&#x0308;chst sei eine kontextfreie Grammatik \(G = (V, \Sigma , P, S)\) gegeben. Gesucht ist also ein PDA \(M\) mit \(N(M) = L(G)\). Dazu wa&#x0308;hlt man \(M = (\{z\}, \Sigma , V \cup
\Sigma , \delta , z, S)\) und \(\delta \) gegeben durch \((z, \alpha ) \in \delta (z, \varepsilon , X)\) fu&#x0308;r alle Regeln \(X \rightarrow \alpha \in P\) und \((z, \varepsilon ) \in \delta (z, a,
a)\) fu&#x0308;r alle Terminale \(a \in \Sigma \). Anschaulich wird also \(X\) auf dem Keller durch \(\alpha \) ersetzt bzw. passende Terminale, die ganz oben auf dem Keller (also ganz am Anfang der Ableitung) liegen,
einfach weggelesen. Der Kellerinhalt symbolisiert die momentane Ableitung von oben nach unten. Man kann zeigen, dass \(N(M) = L(G)\) gilt.
</p>

<p>
Nun sei ein PDA \(M = (Z, \Sigma , \Gamma , \delta , z_0, \#)\) gegeben. Gesucht ist eine Typ-2-Grammatik \(G\) mit \(N(M) = L(G)\). OBdA vergro&#x0308;ßere \(M\) den Keller bei jedem U&#x0308;bergang um
maximal ein Symbol. Dies kann man immer erreichen, indem man andernfalls mehr Zusta&#x0308;nde einfu&#x0308;hrt, die per \(\varepsilon \)-U&#x0308;berga&#x0308;nge wie in einer Kette miteinander verbunden sind.
Die Grammatik \(G\) sei definiert durch \(G = (V, \Sigma , P, S)\) mit \(V = \{S\} \cup (Z \times \Gamma \times Z)\). Anschaulich bedeutet die Variable \((z_1, A, z_2)\), dass man im Zustand \(z_1\) mit dem
obersten Kellersymbol \(A\) startet und das Ziel hat, im Zustand \(z_2\) zu sein, wenn \(A\) aus dem Keller erstmals entfernt wird. In der Grammatik werden \(\varepsilon \)-Regeln erlaubt (diese kann man oBdA in eine
Grammatik ohne \(\varepsilon \)-Regeln umformen). Dann befinden sich fu&#x0308;r \(a \in \Sigma \cup \{\varepsilon \}\) und \(z \in Z\) die Regeln \(S \rightarrow (z_0, \#, z)\), \((z, A, z’) \rightarrow
a\) (falls \((z’, \varepsilon ) \in \delta (z, a, A)\)), \((z, A, z’) \rightarrow a (z_1, B, z’)\) (falls \((z_1, B) \in \delta (z, a, A)\)) und \((z, A, z’) \rightarrow a (z_1, B, z_2) (z_2, C, z’)\)
(falls \((z_1, BC) \in \delta (z, a, A)\)) in \(P\). Man kann zeigen, dass \(N(M) = L(G)\) gilt. &#x2003;&#x2003;
</p>

<p>
<em>Bemerkung</em>: Im Beweis sieht man: Jede kontextfreie Sprache kann von einem PDA erkannt werden, der nur einen einzigen Zustand besitzt. Zu jeder kontextfreien Sprache (z.&#x202f;B. in Greibach-Normalform gegeben)
gibt es einen PDA, der in Echtzeit arbeitet, d.&#x202f;h. in jedem Schritt wird ein Zeichen eingelesen.
</p>



<h2 id="deterministisch-kontextfreie-sprachen">Deterministisch kontextfreie Sprachen</h2>

</p>


<p>
<em>Bemerkung</em>: Fu&#x0308;r viele Anwendungen sind die kontextfreien Sprachen zu allgemein, wa&#x0308;hrend die regula&#x0308;ren Sprachen zu speziell sind. Man fu&#x0308;hrt daher eine echte Teilmenge bzw.
Obermenge der kontextfreien bzw. regula&#x0308;ren Sprachen ein.
</p>

<p>
<b>deterministischer Kellerautomat (DPDA)</b>:&#x2003;<br />
Ein <em><span class="dashuline" >deterministischer Kellerautomat</span></em> oder <em><span class="dashuline" >DPDA (deterministic pushdown automaton)</span></em> ist ein PDA \(M = (Z, \Sigma , \Gamma ,
\delta , z_0, \#)\) mit einer Endzustandsmenge \(E \subset Z\), sodass<br />
\(\forall _{z \in Z} \forall _{a \in \Sigma } \forall _{A \in \Gamma }\; |\delta (z, a, A)| + |\delta (z, \varepsilon , A)| \le 1\). DPDAs akzeptieren durch Endzustand und nicht durch leeren Keller,
d.&#x202f;h. \(N(M) := \{x \in \Sigma ^\ast \;|\; \exists _{z \in E} \exists _{W \in \Gamma ^\ast }\; (z_0, x, \#) \vdash ^\ast (z, \varepsilon , W)\}\).
</p>

<p>
<em>Beispiel</em>: Anschaulich gibt es in jeder Konfiguration \(k \in Z \times \Sigma ^\ast \times \Gamma ^\ast \) ho&#x0308;chstens eine Folgekonfiguration \(k’ \in Z \times \Sigma ^\ast \times \Gamma ^\ast
\) mit \(k \vdash k’\). Fu&#x0308;r PDAs ist Akzeptierung durch Endzustand und leeren Keller a&#x0308;quivalent. Fu&#x0308;r DPDAs gilt dies nicht mehr, denn ist nach dem Lesen eines Wortes \(w \in \Sigma ^\ast \)
durch den DPDA der Keller leer, so gibt es kein Wort \(ww’\) mit \(w’ \in \Sigma ^+\), das ebenfalls akzeptiert werden wu&#x0308;rde, denn nach dem Lesen von \(w\) befindet sich der Automat immer in demselben Zustand.
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<b>\(\CFL \)</b>:&#x2003;<br />
Die Menge \(\CFL := \{L \subset \Sigma ^\ast \;|\; \exists _{\text {PDA } M}\; N(M) = L\}\) ist die Menge aller kontextfreien Sprachen.
</p>

<p>
<b>\(\DCFL \)</b>:&#x2003; Die Menge \(\DCFL := \{L \subset \Sigma ^\ast \;|\; \exists _{\text {DPDA } M}\; N(M) = L\}\) ist die Menge aller<br />
<em><span class="dashuline" >deterministisch kontextfreien Sprachen</span></em>.
</p>

<p>
<em>Beispiel</em>: Beispiele fu&#x0308;r deterministisch kontextfreie Sprachen sind die markierten Palindrome \(\{w \dollar w^R \;|\; w \in \Sigma ^\ast \}\), \(\{a^n b^n \;|\; n \in \natural \}\), \(L_1 = \{a^n
b^n c^m \;|\; m, n \in \natural \}\), \(L_2 = \{a^m b^n c^n \;|\; m, n \in \natural \}\) und \(\{a^n b^m c^n \;|\; m, n \in \natural \}\).
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<span class="uline" ><em>Satz</em> (<span class="textsl" >Abschlusseigenschaften von \(\DCFL \)</span>):</span><br />
\(\DCFL \) ist abgeschlossen unter Komplement, aber nicht unter Durchschnitt und Vereinigung.
</p>

<p>
<b>Beweis</b>: Fu&#x0308;r das Komplement komplementiert man die Endzustandsmenge des DPDAs. Dies genu&#x0308;gt allerdings noch nicht: Befindet sich der DPDA nach dem Lesen von \(w\) in einem Zustand in \(Z
\setminus E\), heißt das noch nicht, dass \(w \notin N(M)\) gilt, denn man ko&#x0308;nnte noch durch \(\varepsilon \)-U&#x0308;berga&#x0308;nge in einen Endzustand wechseln. Das entstehende Problem ist nicht-trivial,
kann aber bewiesen werden.
</p>

<p>
Die Sprachen \(L_1\) und \(L_2\) aus obigem Beispiel sind in \(\DCFL \), aber der Schnitt \(L_1 \cap L_2\) ist nicht einmal in \(\CFL \), also auch nicht in \(\DCFL \).
</p>

<p>
Die Nicht-Abgeschlossenheit unter Vereinigung ergibt sich aus den Regeln von de Morgan. &#x2003;&#x2003;
</p>

<p>
<em>Bemerkung</em>: \(\DCFL \) ist aufgrund der unterschiedlichen Abschlusseigenschaften echt in \(\CFL \) enthalten. Außerdem ist \(\DCFL \) eine echte Obermenge von \(\REG \), denn auch hier unterscheiden sich die
Abschlusseigenschaften (alternativ sucht man entsprechende Sprachen).
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<span class="uline" ><em>Satz</em> (<span class="textsl" >Abschlusseigenschaften von \(\DCFL \) und \(\CFL \) mit \(\REG \)</span>):</span><br />
Aus \(L \in \DCFL \) und \(L’ \in \REG \) folgt \(L \cap L’ \in \DCFL \).<br />
Aus \(L \in \CFL \) und \(L’ \in \REG \) folgt \(L \cap L’ \in \CFL \).
</p>

<p>
<b>Beweis</b>: Fu&#x0308;r beide Aussagen wa&#x0308;hlt man Akzeptierung durch Endzustand und kombiniert den jeweiligen (D)PDA fu&#x0308;r \(L\) mit dem DEA fu&#x0308;r \(L’\) (Kreuzprodukt).
Endzusta&#x0308;nde des kombinierten (D)PDA sind die Paare, bei denen beiden Komponenten (im (D)PDA und im DEA) Endzusta&#x0308;nde sind. &#x2003;&#x2003;
</p>



<h2 id="entscheidbarkeit-bei-kontextfreien-sprachen">Entscheidbarkeit bei kontextfreien Sprachen</h2>

</p>


<p>
<span class="uline" ><em>Satz</em> (<span class="textsl" >Entscheidbarkeit bei kontextfreien Sprachen</span>):</span> Das Wortproblem, das Leerheitsproblem und das Endlichkeitsproblem sind fu&#x0308;r
kontextfreie Sprachen entscheidbar.
</p>

<p>
<b>Beweis</b>: Das Wortproblem ist sogar <em><span class="dashuline" >effizient entscheidbar</span></em> (durch CYK-Algorithmus bei Grammatik in CNF).
</p>

<p>
Das Leerheitsproblem ist z.&#x202f;B. mit dem Pumping-Lemma fu&#x0308;r kontextfreie Sprachen \(L\) lo&#x0308;sbar. Man wa&#x0308;hlt die Zahl \(n\) aus dem Pumping-Lemma (Anzahl der Variablen der Grammatik) und
pru&#x0308;ft alle Wo&#x0308;rter der La&#x0308;nge \(&lt; n\) auf Mitgliedschaft in \(L\). Dies sind endlich viele, d.&#x202f;h. man kann dies mit einem Algorithmus entscheiden. Falls es ein solches gibt, so ist \(L \not =
\emptyset \). Umgekehrt folgt aus \(L \not = \emptyset \), dass es ein Wort der La&#x0308;nge \(&lt; n\) in \(L\) gibt (ein Wort in \(L\) der La&#x0308;nge \(\ge n\) kann man negativ pumpen und erha&#x0308;lt ein
ku&#x0308;rzeres Wort in \(L\)).<br />
Alternativ kann man einen Markierungsalgorithmus entwickeln, der die Menge der <em><span class="dashuline" >produktiven Variablen</span></em> (die Variablen, die in ein Terminalwort abgeleitet werden ko&#x0308;nnen)
findet (hier ist die Frage, ob \(S\) produktiv ist).
</p>

<p>
Die Endlichkeit geht auch mit dem Pumping-Lemma und analog zu den regula&#x0308;ren Sprachen (gibt es kein \(w \in L\) mit \(n \le |w| &lt; 2n\)?). &#x2003;&#x2003;
</p>

<p>
<span
    class="textcolor"
    style="color:#808080"
>
</span>
</p>

<p>
<span class="uline" ><em>Satz</em> (<span class="textsl" >Entscheidbarkeit bei deterministisch kontextfreien Sprachen</span>):</span> Das Problem „Gleichheit mit regula&#x0308;ren Sprachen“ ist fu&#x0308;r
deterministisch kontextfreie Sprachen entscheidbar, d.&#x202f;h. fu&#x0308;r \(L_1 \in \DCFL \) und \(L_2 \in \REG \) ist die Frage, ob \(L_1 = L_2\) gilt, entscheidbar.
</p>

<p>
<b>Beweis</b>: Es gilt \(L_1 = L_2\) genau dann, wenn \(L_1 \subset L_2\) und \(L_2 \subset L_1\). Dies kann man umschreiben zu \(L_1 \setminus L_2 = \emptyset \) und \(L_2 \setminus L_1 = \emptyset \).<br
/>
Mit Komplementen dargestellt ist dies a&#x0308;quivalent zu \(L_1 \cap (\Sigma ^\ast \setminus L_2) = \emptyset \) und \(L_2 \cap (\Sigma ^\ast \setminus L_1) = \emptyset \). Da \(L_1 \cap (\Sigma ^\ast
\setminus L_2)\) und \(L_2 \cap (\Sigma ^\ast \setminus L_1)\) aufgrund der Abschlusseigenschaften in \(\DCFL \) sind, ist das Gleichheitsproblem mit dem Leerheitsproblem entscheidbar. &#x2003;&#x2003;
</p>

{% endraw %}
</div>
{:/nomarkdown}
