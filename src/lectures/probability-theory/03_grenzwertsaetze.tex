\chapter{%
    Grenzwertsätze der Wahrscheinlichkeitstheorie%
}

\section{%
    Das Null-Eins-Gesetz von \name{Kolmogorov}%
}

\begin{Def}{terminale $\sigma$-Algebra}\\
    Seien $(\Omega, \A)$ ein Messraum und $(\A_n)_{n \in \natural}$ eine Folge von
    $\sigma$-Algebren $\A_n \subset \A$ auf $\Omega$.\\
    Sei $\T_n := \sigma(\bigcup_{k=n}^\infty \A_k)$ für $n \in \natural$
    die von $\A_n, \A_{n+1}, \dotsc$ erzeugte $\sigma$-Algebra.\\
    Dann heißt $\T_\infty := \bigcap_{n=1}^\infty \T_n$ die
    \begriff{terminale $\sigma$-Algebra} von $(\A_n)_{n \in \natural}$.\\
    Jedes Ereignis $A \in \T_\infty$ heißt \begriff{terminales Ereignis} von
    $(\A_n)_{n \in \natural}$.
\end{Def}

\begin{Bsp}
    Seien $(\Omega, \A)$ und $(\Omega', \A')$ zwei Messräume und
    $(X_n)_{n \in \natural}$ eine Folge von Zufallsvariablen
    $X_n\colon \Omega \rightarrow \Omega'$.
    Dann ist die Folge $(\A_n)_{n \in \natural}$ mit $\A_n \subset \A$ definiert durch\\
    $\A_n := \sigma(X_n) := \{X_n^{-1}(A') \;|\; A' \in \A'\}$.\\
    Die terminale $\sigma$-Algebra dieser Folge wird mit
    $\T_\infty((\A_n)_{n \in \natural})$ bezeichnet.
\end{Bsp}

\begin{Satz}{Eigenschaften}
    Seien $(\Omega, \A)$ ein Messraum und $(X_n)_{n \in \natural}$ eine Folge reeller
    Zufallsvariablen $X_n\colon \Omega \rightarrow \real$.
    Dann gilt:
    \begin{enumerate}
        \item
        $\{\omega \in \Omega \;|\; (X_n(\omega))_{n \in \natural} \text{ konv. in } \real\} \in
        \T_\infty((X_n)_{n \in \natural})$

        \item
        $\{\omega \in \Omega \;|\; \limsup_{n \to \infty} X_n(\omega) \le \alpha\} \in
        \T_\infty((X_n)_{n \in \natural})$ für $\alpha \in \real$

        \item
        $\{\omega \in \Omega \;|\; \liminf_{n \to \infty} X_n(\omega) \le \alpha\} \in
        \T_\infty((X_n)_{n \in \natural})$ für $\alpha \in \real$
    \end{enumerate}
\end{Satz}

\linie

\begin{Def}{(stochastisch) unabhängig}
    Seien $(\Omega, \A, P)$ ein W-Raum und
    $(\C_i)_{i \in I}$ eine Familie von Systemen messbarer Mengen $\C_i \subset \A$ mit
    $I \not= \emptyset$.\\
    Dann heißt $(C_i)_{i \in I}$ \begriff{(stochastisch) unabhängig}, falls
    für jede Wahl von Mengen $C_i \in \C_i$ die Familie $(C_i)_{i \in I}$
    stochastisch unabhängig ist.
\end{Def}

\begin{Bsp}
    Seien $(\Omega, \A)$ und $(\Omega', \A')$ zwei Messräume und
    $(X_n)_{n \in \natural}$ eine Folge von Zufallsvariablen
    $X_n\colon \Omega \rightarrow \Omega'$.
    Dann ist die Folge $(\A_n)_{n \in \natural}$ mit $\A_n \subset \A$ definiert durch\\
    $\A_n := \sigma(X_n) := \{X_n^{-1}(A') \;|\; A' \in \A'\}$.\\
    Wenn die $(X_n)_{n \in \natural}$ unabhängig sind, dann auch die Familie
    $(\A_n)_{n \in \natural}$.
\end{Bsp}

\begin{Satz}{Unabhängigkeit erweiterbar}
    Seien $(\Omega, \A, P)$ ein W-Raum und
    $(\H_i)_{i \in I}$ eine Familie von Halbringen $\H_i \subset \A$ mit $I \not= \emptyset$.
    Wenn $(\H_i)_{i \in I}$ stochastisch unabhängig ist, dann auch
    $(\sigma(\H_i))_{i \in I}$.
\end{Satz}

\linie

\begin{Satz}{Null-Eins-Gesetz von \upshape\;\!\name{Kolmogorov}}
    Seien $(\Omega, \A, P)$ ein W-Raum, $(\A_n)_{n \in \natural}$ eine unabhängige Folge
    von $\sigma$-Algebren $\A_n \subset \A$ und $\T_\infty$ die terminale $\sigma$-Algebra von
    $(\A_n)_{n \in \natural}$.\\
    Dann gilt für jedes $A \in \T_\infty$, dass $P(A) \in \{0, 1\}$.
\end{Satz}

\begin{Kor}
    Seien $(\Omega, \A, P)$ ein W-Raum und $(X_n)_{n \in \natural}$ eine Folge
    unabhängiger reeller Zufallsvariablen $X_n\colon \Omega \rightarrow \real$.
    Dann gilt für die folgenden Ereignisse $A \in \A$ immer $P(A) \in \{0, 1\}$:
    \begin{enumerate}
        \item
        $\{\omega \in \Omega \;|\; (X_n(\omega))_{n \in \natural} \text{ konv. in } \real\}$

        \item
        $\{\omega \in \Omega \;|\; \limsup_{n \to \infty} X_n(\omega) \le \alpha\}$
        für $\alpha \in \real$

        \item
        $\{\omega \in \Omega \;|\; \liminf_{n \to \infty} X_n(\omega) \le \alpha\}$
        für $\alpha \in \real$
    \end{enumerate}
\end{Kor}

\pagebreak

\section{%
    Konvergenzbegrif"|fe%
}

\begin{Bem}
    Im Folgenden werden verschiedene Grenzwertsätze
    (mehrere Gesetze der großen Zahlen, zentraler Grenzwertsatz) vorgestellt.
    Dafür werden verschiedene Konvergenzbegrif"|fe benötigt,
    um zu definieren, wann in einem Maßraum $(\Omega, \A, \mu$ eine Folge
    $(X_n)_{n \in \natural}$ von reellen Zufallsvariablen $X_n\colon \Omega \rightarrow \real$
    gegen eine Grenzfunktion $X\colon \Omega \rightarrow \real$ konvergiert.
    Die bekanntesten Konvergenzbegrif"|fe aus der
    Analysis, die gleichmäßige und die punktweise Konvergenz, sind zu stark:
    Die gleichmäßige Konvergenz ist schon von vorneherein ungeeignet, weil sie einen Zusammenhang
    zwischen verschiedenen Punkten von $\Omega$ bzgl. der Konvergenzgeschwindigkeit fordert.

    Auch die punktweise Konvergenz ist schon zu fordernd:
    Seien $X_n$ unabhängige, identisch Ber\-noulli-verteilte reelle Zufallsvariablen
    (d.\,h. die $X_n$ nehmen nur die Werte $0$ und $1$ an und $1$ mit Wahrscheinlichkeit
    $p \in (0, 1)$).
    Wenn für diese Folge $(X_n)_{n \in \natural}$ von Zufallsvariablen das Gesetz der großen
    Zahlen, also $Y_n \xrightarrow{n \to \infty} Y$ mit $Y_n := \frac{1}{n} \sum_{k=1}^n X_k$ mit
    $Y :\equiv \EW(X_n) = p$, gelten soll, dann ist punktweise Konvergenz zu stark,
    denn es wäre ja durchaus möglich, dass alle $X_n$ den Wert $1$ annehmen.
    Anders gesagt gibt es ein $\omega_0 \in \Omega$ mit
    $X_1(\omega_0) = X_2(\omega_0) = \dotsb = 1$, d.\,h. $Y_n(\omega_0) \to 1 \not= p = \EW(X_n)$.
    Somit gilt das Gesetz der großen Zahlen bzgl. punktweiser Konvergenz i.\,A. nicht.

    Daher müssen neue Konvergenzbegrif"|fe eingeführt werden, die die
    Wahrscheinlichkeit von unterschiedlichen Ereignissen nutzen.
\end{Bem}

\linie

\begin{Def}{$P$-fast sichere Konvergenz}
    Seien $(\Omega, \A, P)$ ein W-Raum,
    $(X_n)_{n \in \natural}$ eine Folge reeller Zufallsvariablen
    $X_n\colon \Omega \rightarrow \real$ und
    $X\colon \Omega \rightarrow \real$ eine reelle Zufallsvariable.\\
    $(X_n)_{n \in \natural}$ konvergiert \begriff{$P$-fast sicher} gegen $X$
    ($X_n \xrightarrow{P\text{-f.s.}} X$), falls
    für $X_n(\omega) \to X(\omega)$ für $P$-fast alle $\omega \in \Omega$,
    d.\,h. $P(\{\omega \in \Omega \;|\; \lim_{n \to \infty} X_n(\omega) = X(\omega)\}) = 1$.
\end{Def}

\begin{Satz}{Aussagen über $P$-fast sichere Konvergenz}
    Seien $(\Omega, \A, P)$ ein W-Raum,
    $(X_n)_{n \in \natural}$ eine Folge reeller Zufallsvariablen
    $X_n\colon \Omega \rightarrow \real$ und
    $X, Y\colon \Omega \rightarrow \real$ reelle Zufallsvariablen.
    Dann gilt:
    \begin{enumerate}
        \item
        Wenn $X_n \xrightarrow{P\text{-f.s.}} X$ und $X_n \xrightarrow{P\text{-f.s.}} Y$,
        dann gilt $X \underset{P}{=} Y$.

        \item
        $X_n \xrightarrow{P\text{-f.s.}} X$\\
        $\iff \forall_{\varepsilon > 0}\; \lim_{n \to \infty}
        P(\sup_{m \ge n} |X_m - X| > \varepsilon) = 0$\\
        $\iff \forall_{\varepsilon > 0}\; \lim_{n \to \infty}
        P(\sup_{m \ge n} |X_m - X_n| > \varepsilon) = 0$
        (\begriff{Cauchy-Kriterium})

        \item
        Sei $\exists_{(\varepsilon_n)_{n \in \natural},\; \varepsilon_n > 0}\;
        \lim_{n \to \infty} \varepsilon_n = 0,\;
        \sum_{n=1}^\infty P(|X_n - X| \ge \varepsilon_n) < \infty$.\\
        Dann gilt $X_n \xrightarrow{P\text{-f.s.}} X$.
    \end{enumerate}
\end{Satz}

\linie

\begin{Def}{stochastische Konvergenz}\\
    $(X_n)_{n \in \natural}$ konvergiert \begriff{im Maß $P$}/\begriff{stochastisch} gegen $X$
    ($X_n \xrightarrow{\text{stoch.}} X$), falls\\
    $\forall_{\varepsilon > 0}\; \lim_{n \to \infty} P(|X_n - X| > \varepsilon) = 0$.
\end{Def}

\begin{Satz}{Aussagen über stochastische Konvergenz}
    Unter den gleichen Voraussetzungen gilt:
    \begin{enumerate}
        \item
        Wenn $X_n \xrightarrow{P\text{-f.s.}} X$ gilt, dann auch
        $X_n \xrightarrow{\text{stoch.}} X$.

        \item
        $X_n \xrightarrow{\text{stoch.}} X
        \iff \forall_{(X_{n_k})_{k \in \natural} \text{ Teilfolge von } (X_n)_{n \in \natural}}\;
        \exists_{(X_{n_{k_\ell}})_{l \in \natural} \text{ Teilfolge von }
        (X_{n_k})_{k \in \natural}}\; X_{n_{k_\ell}} \xrightarrow{P\text{-f.s.}} X$

        \item
        Wenn $X_n \xrightarrow{\text{stoch.}} X$ und $X_n \xrightarrow{\text{stoch.}} Y$,
        dann gilt $X \underset{P}{=} Y$.
    \end{enumerate}
\end{Satz}

\linie
\pagebreak

\begin{Def}{$\L^p(P)$-Konvergenz}\\
    $(X_n)_{n \in \natural}$ konvergiert für $p \ge 1$
    \begriff{im $p$-Mittel}/\begriff{in $\L^p(P)$} gegen $X$
    ($X_n \xrightarrow{\L^p(P)} X$), falls\\
    $X_n, X \in \L^p(P)$ und
    $\lim_{n \to \infty} \norm{X_n - X}_p =
    \lim_{n \to \infty} \left(\int_\Omega |X_n - X|^p dP\right)^{1/p} = 0$,\\
    d.\,h. $\lim_{n \to \infty} \EW(|X_n - X|^p) = 0$.
\end{Def}

\begin{Satz}{Aussagen über $\L^p(P)$-Konvergenz}
    Seien $(\Omega, \A, P)$ ein W-Raum, $p > 0$,
    $(X_n)_{n \in \natural}$ eine Folge reeller Zufallsvariablen
    $X_n\colon \Omega \rightarrow \real$ mit $X_n \in \L^p(P)$ und
    $X, Y\colon \Omega \rightarrow \real$ reelle Zufallsvariablen mit $X, Y \in \L^p(P)$.
    Dann gilt:
    \begin{enumerate}
        \item
        Wenn $X_n \xrightarrow{\L^p(P)} X$ gilt, dann auch
        $X_n \xrightarrow{\text{stoch.}} X$.

        \item
        Wenn $X_n \xrightarrow{\L^p(P)} X$ und $X_n \xrightarrow{\L^p(P)} Y$,
        dann gilt $X \underset{P}{=} Y$.

        \item
        $\L^p(P)$ ist bzgl. der Halbnorm $\norm{\cdot}_p$ vollständig, d.\,h.\\
        $X_n \xrightarrow{\L^p(P)} X
        \iff \forall_{\varepsilon > 0} \exists_{n_0 \in \natural} \forall_{n, m \in n_0}\;
        \norm{X_n - X_m}_p < \varepsilon$
        (\begriff{Satz von \name{Riesz}-\name{Fischer}}).

        \item
        Für $0 < q < p$ gilt:
        Wenn $X_n \xrightarrow{\L^p(P)} X$ gilt, dann auch
        $X_n \xrightarrow{\L^q(P)} X$.
    \end{enumerate}
\end{Satz}

\linie

\begin{Def}{Konvergenz in Verteilung}\\
    $(X_n)_{n \in \natural}$ konvergiert \begriff{in Verteilung} gegen $X$
    ($X_n \xrightarrow{\text{(d)}} X$), falls\\
    $\lim_{n \to \infty} \int_\real f dP_{X_n} = \int_\real f dP_X$ für jede
    stetige beschränkte Funktion $f\colon \real \rightarrow \real$,\\
    d.\,h. $\lim_{n \to \infty} \int_\Omega (f \circ X_n) dP = \int_\Omega (f \circ X) dP$
    (die Folge $(P_{X_n})_{n \in \natural}$ der Verteilungen von $X_n$ konvergiert
    \begriff{schwach} gegen die Verteilung $P_X$ von $X$).
\end{Def}

\begin{Satz}{Aussagen über Konvergenz in Verteilung}
    Seien $(\Omega, \A, P)$ ein W-Raum,
    $(X_n)_{n \in \natural}$ eine Folge reeller Zufallsvariablen
    $X_n\colon \Omega \rightarrow \real$ und
    $X, Y\colon \Omega \rightarrow \real$ reelle Zufallsvariablen.
    Für eine reelle Zufallsvariable $Z$ sei $P_Z$ ihre Verteilung und $F_Z$ die
    Verteilungsfunktion.
    Dann gilt:
    \begin{enumerate}
        \item
        Wenn $X_n \xrightarrow{\text{stoch.}} X$ gilt, dann auch
        $X_n \xrightarrow{\text{(d)}} X$.

        \item
        Wenn $X_n \xrightarrow{\text{(d)}} X$ und $X_n \xrightarrow{\text{(d)}} Y$,
        dann gilt $P_X = P_Y$ (d.\,h. $X$ und $Y$ sind identisch verteilt).

        \item
        $X_n \xrightarrow{\text{(d)}} X
        \iff \forall_{x \in \real,\; F_X \text{ stetig in } x}\;
        \lim_{n \to \infty} F_{X_n}(x) = F_X(x)$
    \end{enumerate}
\end{Satz}

\linie

\begin{Bem}
    Es gelten also folgende Beziehungen:
    \begin{align*}
        \begin{xy}
            \xymatrix{
                & & \L^p(P)\text{-Konv.} \ar@{=>}[d]^{\;q < p}\\
                P\text{-f.s. Konv.} \ar@{=>}[dr] & & \L^q(P)\text{-Konv.} \ar@{=>}[dl]\\
                & \text{stoch. Konv.} \ar@{=>}[d] &\\
                & \text{Konv. in Vert.}
            }
        \end{xy}
    \end{align*}
\end{Bem}

\pagebreak

\section{%
    Gesetze der großen Zahlen%
}

\begin{Bem}
    Man kann die Wahrscheinlichkeitstheorie durch zwei verschiedene unterschiedliche Sichtweisen
    begründen.
    Einmal kann man Wahrscheinlichkeit eines Ereignisses $A$
    bei einem Laplace-Experiment mit $n$ gleichwahrscheinlichen Versuchsausgängen
    als Quotient der Anzahlen der Ergebnisse, bei denen $A$ eintrifft, durch $n$ betrachten.
    Daraus wurde ganz am Anfang die axiomatische Definition des Wahrscheinlichkeitsraums
    nach Kolmogorov gewonnen.

    Andererseits kann man allerdings Wahrscheinlichkeit als Grenzwert relativer Häufigkeiten
    betrachten.
    Man führt das Experiment unendlich oft durch und bezeichnet mit $k_A(n)$ die Anzahl der
    Ergebnisse unter den ersten $n$, bei denen $A$ eingetreten ist.
    Dann ist die Wahrscheinlichkeit nach Monte-Carlo der Grenzwert
    $p(A) = \lim_{n \to \infty} \frac{k_A(n)}{n}$.

    Mit dem Gesetz der großen Zahlen lassen sich diese beiden Sichtweise vereinen,
    denn ausgehend von der axiomatischen Definition des Wahrscheinlichkeitsraums kann man mit ihnen
    die statistische Stabilität der relativen Häufigkeiten von Ereignissen beweisen.

    Dazu sei $(\Omega, \A, P)$ ein W-Raum, bei dem man sich vorstellt, dass er
    die abzählbar unendlich häufige, unabhängige Wiederholung eines Einzelexperiments modelliert,
    und $A$ ein Ereignis zu diesem Einzelexperiment.
    Für $k \in \natural$ sei $X_k\colon \Omega \rightarrow \real$ die Funktion, sodass
    $X_k(\omega) = 1$ für $A$ in $\omega \in \Omega$ eingetreten und $X_k(\omega) = 0$ sonst.
    Seien diese $X_k$ messbar und sogar $X_k \in \L^1(P)$
    (d.\,h. die $X_k$ sind integrierbare, reelle Zufallsvariablen).

    Weil die Einzelexperimente voneinander unabhängig und gleichartig sind,
    sind die $X_k$ unabhängige Zufallsvariablen mit identischer Verteilung sowie
    $\EW(X_k)$ ist die Wahrscheinlichkeit, dass $A$ im Einzelexperiment eintritt.
    $k_A(n) := \sum_{k=1}^n X_k(\omega)$ sei nun die Häufigkeit von $A$ unter den ersten
    $n$ Experimenten in der Realisierung $\omega \in \Omega$.
    Wenn nun die relative Häufigkeit von $A$ gegen die Wahrscheinlichkeit konvergieren soll,
    muss $\frac{1}{n} \sum_{k=1}^n X_k(\omega) \xrightarrow{n \to \infty} \EW(X_1)$ gelten.
    Äquivalent dazu ist $\frac{1}{n} \sum_{k=1}^n (X_k - \EW(X_k)) \xrightarrow{n \to \infty} 0$.
    Das ist die Formulierung des Gesetzes der großen Zahlen.
\end{Bem}

\linie

\begin{Def}{Gesetz der großen Zahlen}
    Seien $(\Omega, \A, P)$ ein W-Raum und $(X_n)_{n \in \natural}$ eine Folge von reellen
    Zufallsvariablen mit $X_n \in \L^1(P)$.
    \begin{enumerate}
        \item
        $(X_n)_{n \in \natural}$ \begriff{genügt dem Gesetz der großen Zahlen bzgl. eines
        bestimmten Konvergenzbegriffs}, falls
        $\frac{1}{n} \sum_{k=1}^n (X_k - \EW(X_k)) \xrightarrow{n \to \infty} 0$
        bzgl. dieses Konvergenzbegriffs.

        \item
        $(X_n)_{n \in \natural}$ \begriff{genügt dem schwachen/starken Gesetz der großen Zahlen},
        falls $(X_n)_{n \in \natural}$ dem Gesetz der großen Zahlen bzgl.
        stoch./$P$-fast sicherer Konvergenz genügt.
    \end{enumerate}
\end{Def}

\begin{Satz}{schwaches Gesetz der großen Zahlen}
    Seien $(\Omega, \A, P)$ ein W-Raum und $(X_n)_{n \in \natural}$ eine Folge von
    reellen Zufallsvariablen $X_n\colon \Omega \rightarrow \real$ mit $X_n \in \L^2(P)$,
    die paarweise unkorreliert sind (d.\,h. $\EW(X_k \cdot X_\ell) = \EW(X_k) \cdot \EW(X_\ell)$
    für $k \not= \ell$).
    Außerdem gelte $\lim_{n \to \infty} \frac{1}{n^2} \sum_{k=1}^n \Var(X_k) = 0$.\\
    Dann genügt $(X_n)_{n \in \natural}$ dem Gesetz der großen Zahlen bzgl. $\L^2(P)$-Konvergenz,
    d.\,h. insbesondere dem schwachen Gesetz der großen Zahlen.\\
    Bzgl. der Konvergenzgeschwindigkeit gilt für $n \in \natural$, dass\\
    $\norm{\frac{1}{n} \sum_{k=1}^n (X_k - \EW(X_k))}_2 \le
    \frac{1}{n} \sqrt{\sum_{k=1}^n \Var(X_k)}$.
\end{Satz}

\linie

\begin{Satz}{starkes Gesetz der großen Zahlen mit $\L^2$-Integrierbarkeit}
    Seien $(\Omega, \A, P)$ ein\\
    W-Raum und $(X_n)_{n \in \natural}$
    eine Folge von paarweise unabhängigen, identisch verteilten, reellen Zufallsvariablen
    $X_n \in \L^2(P)$.
    Dann genügt $(X_n)_{n \in \natural}$ dem starken Gesetz der großen Zahlen.
\end{Satz}

\begin{Satz}{starkes Gesetz der großen Zahlen von \upshape\,\!\name{Etemadi}}
    Seien $(\Omega, \A, P)$ ein\\
    W-Raum und $(X_n)_{n \in \natural}$
    eine Folge von paarweise unabhängigen, identisch verteilten, reellen Zufallsvariablen
    $X_n \in \L^1(P)$.
    Dann genügt $(X_n)_{n \in \natural}$ dem starken Gesetz der großen Zahlen.
\end{Satz}

\linie
\pagebreak

\begin{Bem}
    Beim Beweis des starken Gesetzes der großen Zahlen von Etemadi muss man mit
    abgeschnittenen Zufallsvariablen rechnen.
\end{Bem}

\begin{Lemma}{abgeschnittene Zufallsvariablen}
    Seien $(\Omega, \A, P)$ ein W-Raum und $(X_n)_{n \in \natural}$
    eine Folge von identisch verteilten, reellen Zufallsvariablen $X_n \in \L^1(P)$.
    Für $n \in \natural$ sei\\
    $\widehat{X}_n := X_n \cdot \1_{\{|X_n| \le n\}}\colon \Omega \rightarrow \real$,
    $\omega \mapsto X_n(\omega)$ für $X_n(\omega) \le n$ und $\omega \mapsto 0$ sonst\\
    die \begriff{abgeschnittene Zufallsvariable}.
    \begin{enumerate}
        \item
        Es gilt $\widehat{X}_n \in \L^2(P)$.

        \item
        Wenn für die Folge $(\widehat{X}_n)_{n \in \natural}$ von Zufallsvariablen
        die Beziehung $\frac{1}{n} \sum_{k=1}^n \widehat{X}_k \xrightarrow{P\text{-f.s.}} \EW(X_1)$
        gilt, so genügt $(X_n)_{n \in \natural}$ dem starken Gesetz der großen Zahlen.

        \item
        Es gilt $\sum_{n=1}^\infty \frac{\EW(\widehat{X}_n)}{n^2} \le 4 \EW(|X_1|)$.
    \end{enumerate}
\end{Lemma}

\linie

\begin{Bem}
    Eine \begriff{Monte-Carlo-Methode} ist ein randomisierter Algorithmus,
    der durch Zufallszahlen versucht, ein exaktes Ergebnis anzunähern.
    Monte-Carlo-Methoden gibt es zum Beispiel bei der numerischen Quadratur,
    also bei der näherungsweisen Berechnung eines eindimensionalen Integrals.

    Sei dazu $f\colon [0, 1] \rightarrow [0, 1]$ ein integrierbare Funktion
    (ansonsten transformiert man um).
    Man kann zwei verschiedene Integrationsmethoden betrachten:
    \begin{enumerate}
        \item
        Seien $X$ und $Y$ zwei unabhängige, auf $[0, 1]$ kontinuierlich gleichverteilte
        Zufallsvariablen.
        Definiere $Z := \1_{\{f(X) \ge Y\}}$.
        Weil $Z$ nur die Werte $0$ und $1$ annehmen kann, gilt\\
        $\EW(Z) = P(Z = 1) = P(f(X) \ge Y) = \int_\Omega \1_{\{f(X) \ge Y\}} dP
        = \int_{[0, 1]^1} \1_{\{f(x) \ge y\}} d\lambda^2(x, y)$\\
        $= \int_0^1 \int_0^{f(x)} 1 \dy\dx = \int_0^1 f(x)\dx$
        (wegen $X$ und $Y$ unabhängig besitzt die $[0, 1]^2$-wertige Zufallsvariable
        $(X, y)$ die Verteilung $\lambda_{[0, 1]} \otimes \lambda_{[0, 1]} = \lambda_{[0, 1]^2}$).

        Ist $(Z_n)_{n \in \natural}$ eine Folge von unabhängigen, auf diese Weise konstruierten
        Zufallsvariablen, so gilt daher nach dem starken Gesetz der großen Zahlen
        $\frac{1}{n} \sum_{k=1}^n Z_k \xrightarrow{\lambda_{[0,1]^2}\text{-f.s.}} \int_0^1 f(x)\dx$.

        \item
        Sei $X$ eine auf $[0, 1]$ gleichverteilte Zufallsvariable und $Y := f \circ X$.
        Dann ist auch $Y$ integrierbar und es gilt
        $\EW(Y) = \EW(f \circ X) = \int_\Omega (f \circ X)dP =
        \int_{[0, 1]} fd\lambda = \int_0^1 f(x)\dx$.

        Ist $(Y_n)_{Y \in \natural}$ eine Folge von unabhängigen, auf diese Weise konstruierten
        Zufallsvariablen, so gilt daher nach dem starken Gesetz der großen Zahlen
        $\frac{1}{n} \sum_{k=1}^n Y_k \xrightarrow{\lambda_{[0,1]^2}\text{-f.s.}} \int_0^1 f(x)\dx$.
    \end{enumerate}
    In der Praxis realisiert man die näherungsweise Berechnung von $\int_0^1 f(x)\dx$ mit\\
    (Pseudo-)Zufallszahlen.
\end{Bem}

\pagebreak

\section{%
    Der zentrale Grenzwertsatz%
}

\begin{Bem}
    Sei $(X_n)_{n \in \natural}$ eine Folge von paarweise unabhängigen,
    identisch verteilten, reellen Zufallsvariablen $X_n \in \L^2(P)$ gegeben.
    Nach dem starken Gesetz der großen Zahlen gilt
    $\frac{1}{n} \sum_{k=1}^n X_k \xrightarrow{P\text{-f.s.}} \mu := \EW(X_1)$.
    Nun soll untersucht werden, wie der Mittelwert um den Grenzwert schwankt.
    Dazu definiert man $Y_n := \frac{1}{n} \sum_{k=1}^n X_k - \mu$.
    Aufgrund $\Var(Y_n) \to 0$ für $n \to \infty$ nomriert man die $Y_n$ noch,
    d.\,h. man geht zur Folge $(Z_n)_{n \in \natural}$ mit
    $Z_n := \frac{Y_n}{\sqrt{\Var(Z_n)}} = \frac{\sum_{k=1}^n X_k - n \mu}
    {\sqrt{n \sigma^2}}$ mit $\sigma^2 := \Var(X_1)$ über
    (wobei momentan $\sigma^2 \not= 0$ vorausgesetzt wird).

    Wenn die $X_n$ Bernoulli-verteilt sind, so kann man durch Rechnung mithilfe der Stirling-Formel
    zeigen, dass die $Z_n$ in Verteilung gegen eine Zufallsvariable $Z$ konvergieren,
    die standard-normalverteilt ist ($Z \sim \N(0, 1)$).
    Diese Aussage ist der \begriff{Satz von \name{Moivre}-\name{Laplace}}.

    In Wirklichkeit stimmt diese Aussage aber immer, unabhängig von der gemeinsamen Verteilung
    der $X_n$.
    Damit erhält man den zentralen Grenzwertsatz.
\end{Bem}

\linie

\begin{Satz}{zentraler Grenzwertsatz}\\
    Seien $(\Omega, \A, P)$ ein W-Raum und $(X_n)_{n \in \natural}$
    eine Folge von paarweise unabhängigen, identisch verteilten,
    reellen Zufallsvariablen $X_n \in \L^2(P)$ mit $\mu := \EW(X_1)$ und
    $\sigma^2 := \Var(X_1) > 0$.\\
    Dann gilt $Z_n \xrightarrow{\text{(d)}} Z$ mit $Z ~ \N(0, 1)$ und
    $Z_n := \frac{1}{\sqrt{n \sigma^2}} \sum_{k=1}^n (X_k - \mu)$.
\end{Satz}

\begin{Bem}
    Für $\sigma^2 = 0$ sind die $X_k$ alle $P$-f.ü. gleich $\mu$.
    Daher konvergiert $\frac{1}{n} \sum_{k=1}^n (X_k - \mu)$ $P$-f.s., d.\,h.
    insbesondere in Verteilung, gegen $0$,
    also gegen eine Dirac-verteilte Zufallsvariable (z.\,B. $\delta_{\{0\}}$).\\
    Mit folgendem Korollar kann man die Schwankungsbreite der Konvergenz abschätzen.
\end{Bem}

\begin{Kor}\\
    Seien $(\Omega, \A, P)$ ein W-Raum und $(X_n)_{n \in \natural}$
    eine Folge von paarweise unabhängigen, identisch verteilten,
    reellen Zufallsvariablen $X_n \in \L^2(P)$ mit $\mu := \EW(X_1)$ und
    $\sigma^2 := \Var(X_1) > 0$.\\
    Außerdem seien $\alpha, \beta \in \extreal$ mit $\alpha < \beta$.\\
    Dann gilt $\lim_{n \to \infty}
    P(\{\alpha < \frac{1}{\sqrt{n\sigma^2}} \sum_{k=1}^n (X_k - \mu) < \beta\}) =
    \frac{1}{\sqrt{2\pi}} \int_\alpha^\beta e^{-t^2/2} \dt$.
    Die Gleichung behält auch durch Ersetzen von "`$<$"' mit "`$\le$"' an einer oder beiden
    Stellen ihre Gültigkeit.
\end{Kor}

\linie

\begin{Bsp}
    Wenn man eine physikalische Größe messen will,
    kann man $n$ voneinander unabhängige Messungen durchführen und den Mittelwert bilden.
    Der Erwartungswert jeder Messung sei der tatsächliche Wert $\mu$ und
    die Varianz $\sigma^2 > 0$ sei positiv (d.\,h. eine gewisse Messungenauigkeit ist vorhanden).
    Wie viele Messungen müssen durchgeführt werden, damit man mit einer Wahrscheinlichkeit von
    mindestens $p$ ausschließen kann, dass die Abweichung des Ergebnisses vom tatsächlichen
    Wert $\mu$ größer als $\varepsilon$ ist?

    Seien $X_1, \dotsc, X_n$ die $n$ Messungen in Form von Zufallsvariablen
    (paarweise unabhängig, identisch verteilt, $\mu := \EW(X_1)$ und $\sigma^2 := \Var(X_1) > 0$).
    Es gilt $P(\{-\varepsilon < \frac{1}{n} \sum_{k=1}^n X_k - \mu < \varepsilon\}) =
    P(\{(-\varepsilon\sqrt{\frac{n}{\sigma^2}} <
    \frac{1}{\sqrt{n\sigma^2}} \sum_{k=1}^n (X_k - \mu) <
    \varepsilon\sqrt{\frac{n}{\sigma^2}}\})$.
    Nach obigem Korollar ist dies für große $n$ ungefähr gleich
    $\frac{1}{\sqrt{2\pi}} \int_{-\varepsilon\sqrt{n/\sigma^2}}^{\varepsilon\sqrt{n/\sigma^2}}
    e^{-t^2/2} \dt = \frac{2}{2\pi}
    \int_{-\infty}^{\varepsilon\sqrt{n/\sigma^2}} e^{-t^2/2} \dt - 1$.
    Um zu bestimmen, wann das größer als $p$ ist, kann man in Quantiltabellen für die
    Standard-Normalverteilung den Wert der Verteilungsfunktion nachschlagen.

    Für $\sigma^2 = 4$, $\varepsilon = \frac{1}{2}$ und $p = \frac{19}{20}$ erhält man z.\,B.
    $n > 61{,}47$.
\end{Bsp}

\linie
\pagebreak

\begin{Bem}
    Wenn zusätzlich zu den Voraussetzungen vom zentralen Grenzwertsatz $X_n \in \L^3(P)$ gilt,
    dann ist die Konvergenz im zentralen Grenzwertsatz gleichmäßig und die
    Konvergenzgeschwindigkeit ist mindestens $\O(\frac{1}{\sqrt{n}})$, wie der folgende
    Satz zeigt.
\end{Bem}

\begin{Satz}{Satz von \name{Berry}-\name{Esseen}}
    Seien $(\Omega, \A, P)$ ein W-Raum und $(X_n)_{n \in \natural}$
    eine Folge von paarweise unabhängigen, identisch verteilten,
    reellen Zufallsvariablen $X_n \in \L^3(P)$ mit $\mu := \EW(X_1)$ und
    $\sigma^2 := \Var(X_1) > 0$.\\
    Seien außerdem $F_n(x) := P(\{Z_n \le x\})$ und
    $F(x) := \frac{1}{\sqrt{2\pi}} \int_{-\infty}^x e^{-t^2/2} \dt$
    die Verteilungsfunktionen von $Z_n$ und der Standard-Normalverteilung $\N(0, 1)$.\\
    Dann gilt $\sup_{x \in \real} |F_n(x) - F(x)| \le
    \frac{4 \EW(|X_1|^3)}{5 \sigma^3} \cdot \frac{1}{\sqrt{n}}$.
\end{Satz}

\pagebreak
